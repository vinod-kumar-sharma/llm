{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d44d3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20481\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "317aebf1-58cc-4673-98a1-343a0f1b0258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his', 'painting', ',', 'married', 'a', 'rich', 'widow', ',', 'and', 'established', 'himself', 'in', 'a', 'villa', 'on', 'the', 'Riviera', '.', '(', 'Though', 'I', 'rather', 'thought', 'it', 'would', 'have', 'been', 'Rome', 'or', 'Florence', '.', ')', '\"', 'The', 'height', 'of', 'his', 'glory', '\"', '--', 'that', 'was', 'what', 'the', 'women', 'called', 'it', '.', 'I', 'can', 'hear', 'Mrs', '.', 'Gideon', 'Thwing', '--', 'his', 'last', 'Chicago', 'sitter', '--', 'deploring', 'his', 'unaccountable', 'abdication', '.', '\"', 'Of', 'course', 'it', \"'\", 's', 'going', 'to', 'send', 'the', 'value', 'of', 'my', 'picture', \"'\", 'way', 'up', ';', 'but', 'I', 'don', \"'\", 't', 'think', 'of', 'that', ',', 'Mr', '.', 'Rickham', '--', 'the', 'loss', 'to', 'Arrt', 'is', 'all', 'I', 'think', 'of', '.', '\"', 'The', 'word', ',', 'on', 'Mrs', '.', 'Thwing', \"'\", 's', 'lips', ',', 'multiplied', 'its', '_', 'rs', '_', 'as', 'though', 'they', 'were', 'reflected', 'in', 'an', 'endless', 'vista', 'of', 'mirrors', '.', 'And', 'it', 'was', 'not', 'only', 'the', 'Mrs', '.', 'Thwings', 'who', 'mourned', '.', 'Had', 'not', 'the', 'exquisite', 'Hermia', 'Croft', ',', 'at', 'the', 'last', 'Grafton', 'Gallery', 'show', ',', 'stopped', 'me', 'before', 'Gisburn', \"'\", 's', '\"', 'Moon-dancers', '\"', 'to', 'say', ',', 'with', 'tears', 'in', 'her', 'eyes', ':', '\"', 'We', 'shall', 'not', 'look', 'upon', 'its', 'like', 'again', '\"', '?', 'Well', '!', '--', 'even', 'through', 'the', 'prism', 'of', 'Hermia', \"'\", 's', 'tears', 'I', 'felt', 'able', 'to', 'face', 'the', 'fact', 'with', 'equanimity', '.', 'Poor', 'Jack', 'Gisburn', '!', 'The', 'women', 'had', 'made', 'him', '--', 'it', 'was', 'fitting', 'that', 'they', 'should', 'mourn', 'him', '.', 'Among', 'his', 'own', 'sex', 'fewer', 'regrets', 'were', 'heard', ',', 'and', 'in', 'his', 'own', 'trade', 'hardly', 'a', 'murmur', '.', 'Professional', 'jealousy', '?', 'Perhaps', '.', 'If', 'it', 'were', ',', 'the', 'honour', 'of', 'the', 'craft', 'was', 'vindicated', 'by', 'little', 'Claude', 'Nutley', ',', 'who', ',', 'in', 'all', 'good', 'faith', ',', 'brought', 'out', 'in', 'the', 'Burlington', 'a', 'very', 'handsome', '\"', 'obituary', '\"', 'on', 'Jack', '--', 'one', 'of', 'those', 'showy', 'articles', 'stocked', 'with', 'random', 'technicalities', 'that', 'I', 'have', 'heard', '(', 'I', 'won', \"'\", 't', 'say', 'by', 'whom', ')', 'compared', 'to', 'Gisburn', \"'\", 's', 'painting', '.', 'And', 'so', '--', 'his', 'resolve', 'being', 'apparently', 'irrevocable', '--', 'the', 'discussion', 'gradually', 'died', 'out', ',', 'and', ',', 'as', 'Mrs', '.', 'Thwing', 'had', 'predicted', ',', 'the', 'price', 'of', '\"', 'Gisburns', '\"', 'went', 'up', '.', 'It', 'was', 'not', 'till', 'three', 'years', 'later', 'that', ',', 'in', 'the', 'course', 'of', 'a', 'few', 'weeks', \"'\", 'idling', 'on', 'the', 'Riviera', ',', 'it', 'suddenly', 'occurred', 'to', 'me', 'to', 'wonder', 'why', 'Gisburn', 'had', 'given', 'up', 'his', 'painting', '.', 'On', 'reflection', ',', 'it', 'really', 'was', 'a', 'tempting', 'problem', '.', 'To', 'accuse', 'his', 'wife', 'would', 'have', 'been', 'too', 'easy', '--', 'his', 'fair', 'sitters', 'had', 'been', 'denied', 'the', 'solace', 'of', 'saying', 'that', 'Mrs', '.', 'Gisburn', 'had', '\"', 'dragged', 'him', 'down', '.', '\"', 'For', 'Mrs', '.', 'Gisburn', '--', 'as', 'such', '--', 'had', 'not', 'existed', 'till', 'nearly', 'a', 'year', 'after', 'Jack', \"'\", 's', 'resolve', 'had', 'been', 'taken', '.', 'It', 'might', 'be', 'that', 'he', 'had', 'married', 'her', '--', 'since', 'he', 'liked', 'his', 'ease', '--', 'because', 'he', 'didn', \"'\", 't', 'want', 'to', 'go', 'on', 'painting', ';', 'but', 'it', 'would', 'have', 'been', 'hard', 'to', 'prove', 'that', 'he', 'had', 'given', 'up', 'his', 'painting', 'because', 'he', 'had', 'married', 'her', '.', 'Of', 'course', ',', 'if', 'she', 'had', 'not', 'dragged', 'him', 'down', ',', 'she', 'had', 'equally', ',', 'as', 'Miss', 'Croft', 'contended', ',', 'failed', 'to', '\"', 'lift', 'him', 'up', '\"', '--', 'she', 'had', 'not', 'led', 'him', 'back', 'to', 'the', 'easel', '.', 'To', 'put', 'the', 'brush', 'into', 'his', 'hand', 'again', '--', 'what', 'a', 'vocation', 'for', 'a', 'wife', '!', 'But', 'Mrs', '.', 'Gisburn', 'appeared', 'to', 'have', 'disdained', 'it', '--', 'and', 'I', 'felt', 'it', 'might', 'be', 'interesting', 'to', 'find', 'out', 'why', '.', 'The', 'desultory', 'life', 'of', 'the', 'Riviera', 'lends', 'itself', 'to', 'such', 'purely', 'academic', 'speculations', ';', 'and', 'having', ',', 'on', 'my', 'way', 'to', 'Monte', 'Carlo', ',', 'caught', 'a', 'glimpse', 'of', 'Jack', \"'\", 's', 'balustraded', 'terraces', 'between', 'the', 'pines', ',', 'I', 'had', 'myself', 'borne', 'thither', 'the', 'next', 'day', '.', 'I', 'found', 'the', 'couple', 'at', 'tea', 'beneath', 'their', 'palm-trees', ';', 'and', 'Mrs', '.', 'Gisburn', \"'\", 's', 'welcome', 'was', 'so', 'genial', 'that', ',', 'in', 'the', 'ensuing', 'weeks', ',', 'I', 'claimed', 'it', 'frequently', '.', 'It', 'was', 'not', 'that', 'my', 'hostess', 'was', '\"', 'interesting', '\"', ':', 'on', 'that', 'point', 'I', 'could', 'have', 'given', 'Miss', 'Croft', 'the', 'fullest', 'reassurance', '.', 'It', 'was', 'just', 'because', 'she', 'was', '_', 'not', '_', 'interesting', '--', 'if', 'I', 'may', 'be', 'pardoned', 'the', 'bull', '--', 'that', 'I', 'found', 'her', 'so', '.', 'For', 'Jack', ',', 'all', 'his', 'life', ',', 'had', 'been', 'surrounded', 'by', 'interesting', 'women', ':', 'they', 'had', 'fostered', 'his', 'art', ',', 'it', 'had', 'been', 'reared', 'in', 'the', 'hot-house', 'of', 'their', 'adulation', '.', 'And', 'it', 'was', 'therefore', 'instructive', 'to', 'note', 'what', 'effect', 'the', '\"', 'deadening', 'atmosphere', 'of', 'mediocrity', '\"', '(', 'I', 'quote', 'Miss', 'Croft', ')', 'was', 'having', 'on', 'him', '.', 'I', 'have', 'mentioned', 'that', 'Mrs', '.', 'Gisburn', 'was', 'rich', ';', 'and', 'it', 'was', 'immediately', 'perceptible', 'that', 'her', 'husband', 'was', 'extracting', 'from', 'this', 'circumstance', 'a', 'delicate', 'but', 'substantial', 'satisfaction', '.', 'It', 'is', ',', 'as', 'a', 'rule', ',', 'the', 'people', 'who', 'scorn', 'money', 'who', 'get', 'most', 'out', 'of', 'it', ';', 'and', 'Jack', \"'\", 's', 'elegant', 'disdain', 'of', 'his', 'wife', \"'\", 's', 'big', 'balance', 'enabled', 'him', ',', 'with', 'an', 'appearance', 'of', 'perfect', 'good-breeding', ',', 'to', 'transmute', 'it', 'into', 'objects', 'of', 'art', 'and', 'luxury', '.', 'To', 'the', 'latter', ',', 'I', 'must', 'add', ',', 'he', 'remained', 'relatively', 'indifferent', ';', 'but', 'he', 'was', 'buying', 'Renaissance', 'bronzes', 'and', 'eighteenth-century', 'pictures', 'with', 'a', 'discrimination', 'that', 'bespoke', 'the', 'amplest', 'resources', '.', '\"', 'Money', \"'\", 's', 'only', 'excuse', 'is', 'to', 'put', 'beauty', 'into', 'circulation', ',', '\"', 'was', 'one', 'of', 'the', 'axioms', 'he', 'laid', 'down', 'across', 'the', 'Sevres', 'and', 'silver', 'of', 'an', 'exquisitely', 'appointed', 'luncheon-table', ',', 'when', ',', 'on', 'a', 'later', 'day', ',', 'I', 'had', 'again', 'run', 'over', 'from', 'Monte', 'Carlo', ';', 'and', 'Mrs', '.', 'Gisburn', ',', 'beaming', 'on', 'him', ',', 'added', 'for', 'my', 'enlightenment', ':', '\"', 'Jack', 'is', 'so', 'morbidly', 'sensitive', 'to', 'every', 'form', 'of', 'beauty', '.', '\"', 'Poor', 'Jack', '!', 'It', 'had', 'always', 'been', 'his', 'fate', 'to', 'have', 'women', 'say', 'such', 'things', 'of', 'him', ':', 'the', 'fact', 'should', 'be', 'set', 'down', 'in', 'extenuation', '.', 'What', 'struck', 'me', 'now', 'was', 'that', ',', 'for', 'the', 'first', 'time', ',', 'he', 'resented', 'the', 'tone', '.', 'I', 'had', 'seen', 'him', ',', 'so', 'often', ',', 'basking', 'under', 'similar', 'tributes', '--', 'was', 'it', 'the', 'conjugal', 'note', 'that', 'robbed', 'them', 'of', 'their', 'savour', '?', 'No', '--', 'for', ',', 'oddly', 'enough', ',', 'it', 'became', 'apparent', 'that', 'he', 'was', 'fond', 'of', 'Mrs', '.', 'Gisburn', '--', 'fond', 'enough', 'not', 'to', 'see', 'her', 'absurdity', '.', 'It', 'was', 'his', 'own', 'absurdity', 'he', 'seemed', 'to', 'be', 'wincing', 'under', '--', 'his', 'own', 'attitude', 'as', 'an', 'object', 'for', 'garlands', 'and', 'incense', '.', '\"', 'My', 'dear', ',', 'since', 'I', \"'\", 've', 'chucked', 'painting', 'people', 'don', \"'\", 't', 'say', 'that', 'stuff', 'about', 'me', '--', 'they', 'say', 'it', 'about', 'Victor', 'Grindle', ',', '\"', 'was', 'his', 'only', 'protest', ',', 'as', 'he', 'rose', 'from', 'the', 'table', 'and', 'strolled', 'out', 'onto', 'the', 'sunlit', 'terrace', '.', 'I', 'glanced', 'after', 'him', ',', 'struck', 'by', 'his', 'last', 'word', '.', 'Victor', 'Grindle', 'was', ',', 'in', 'fact', ',', 'becoming', 'the', 'man', 'of', 'the', 'moment', '--', 'as', 'Jack', 'himself', ',', 'one', 'might', 'put', 'it', ',', 'had', 'been', 'the', 'man', 'of', 'the', 'hour', '.', 'The', 'younger', 'artist', 'was', 'said', 'to', 'have', 'formed', 'himself', 'at', 'my', 'friend', \"'\", 's', 'feet', ',', 'and', 'I', 'wondered', 'if', 'a', 'tinge', 'of', 'jealousy', 'underlay', 'the', 'latter', \"'\", 's', 'mysterious', 'abdication', '.', 'But', 'no', '--', 'for', 'it', 'was', 'not', 'till', 'after', 'that', 'event', 'that', 'the', '_', 'rose', 'Dubarry', '_', 'drawing-rooms', 'had', 'begun', 'to', 'display', 'their', '\"', 'Grindles', '.', '\"', 'I', 'turned', 'to', 'Mrs', '.', 'Gisburn', ',', 'who', 'had', 'lingered', 'to', 'give', 'a', 'lump', 'of', 'sugar', 'to', 'her', 'spaniel', 'in', 'the', 'dining-room', '.', '\"', 'Why', '_', 'has', '_', 'he', 'chucked', 'painting', '?', '\"', 'I', 'asked', 'abruptly', '.', 'She', 'raised', 'her', 'eyebrows', 'with', 'a', 'hint', 'of', 'good-humoured', 'surprise', '.', '\"', 'Oh', ',', 'he', 'doesn', \"'\", 't', '_', 'have', '_', 'to', 'now', ',', 'you', 'know', ';', 'and', 'I', 'want', 'him', 'to', 'enjoy', 'himself', ',', '\"', 'she', 'said', 'quite', 'simply', '.', 'I', 'looked', 'about', 'the', 'spacious', 'white-panelled', 'room', ',', 'with', 'its', '_', 'famille-verte', '_', 'vases', 'repeating', 'the', 'tones', 'of', 'the', 'pale', 'damask', 'curtains', ',', 'and', 'its', 'eighteenth-century', 'pastels', 'in', 'delicate', 'faded', 'frames', '.', '\"', 'Has', 'he', 'chucked', 'his', 'pictures', 'too', '?', 'I', 'haven', \"'\", 't', 'seen', 'a', 'single', 'one', 'in', 'the', 'house', '.', '\"', 'A', 'slight', 'shade', 'of', 'constraint', 'crossed', 'Mrs', '.', 'Gisburn', \"'\", 's', 'open', 'countenance', '.', '\"', 'It', \"'\", 's', 'his', 'ridiculous', 'modesty', ',', 'you', 'know', '.', 'He', 'says', 'they', \"'\", 're', 'not', 'fit', 'to', 'have', 'about', ';', 'he', \"'\", 's', 'sent', 'them', 'all', 'away', 'except', 'one', '--', 'my', 'portrait', '--', 'and', 'that', 'I', 'have', 'to', 'keep', 'upstairs', '.', '\"', 'His', 'ridiculous', 'modesty', '--', 'Jack', \"'\", 's', 'modesty', 'about', 'his', 'pictures', '?', 'My', 'curiosity', 'was', 'growing', 'like', 'the', 'bean-stalk', '.', 'I', 'said', 'persuasively', 'to', 'my', 'hostess', ':', '\"', 'I', 'must', 'really', 'see', 'your', 'portrait', ',', 'you', 'know', '.', '\"', 'She', 'glanced', 'out', 'almost', 'timorously', 'at', 'the', 'terrace', 'where', 'her', 'husband', ',', 'lounging', 'in', 'a', 'hooded', 'chair', ',', 'had', 'lit', 'a', 'cigar', 'and', 'drawn', 'the', 'Russian', 'deerhound', \"'\", 's', 'head', 'between', 'his', 'knees', '.', '\"', 'Well', ',', 'come', 'while', 'he', \"'\", 's', 'not', 'looking', ',', '\"', 'she', 'said', ',', 'with', 'a', 'laugh', 'that', 'tried', 'to', 'hide', 'her', 'nervousness', ';', 'and', 'I', 'followed', 'her', 'between', 'the', 'marble', 'Emperors', 'of', 'the', 'hall', ',', 'and', 'up', 'the', 'wide', 'stairs', 'with', 'terra-cotta', 'nymphs', 'poised', 'among', 'flowers', 'at', 'each', 'landing', '.', 'In', 'the', 'dimmest', 'corner', 'of', 'her', 'boudoir', ',', 'amid', 'a', 'profusion', 'of', 'delicate', 'and', 'distinguished', 'objects', ',', 'hung', 'one', 'of', 'the', 'familiar', 'oval', 'canvases', ',', 'in', 'the', 'inevitable', 'garlanded', 'frame', '.', 'The', 'mere', 'outline', 'of', 'the', 'frame', 'called', 'up', 'all', 'Gisburn', \"'\", 's', 'past', '!', 'Mrs', '.', 'Gisburn', 'drew', 'back', 'the', 'window-curtains', ',', 'moved', 'aside', 'a', '_', 'jardiniere', '_', 'full', 'of', 'pink', 'azaleas', ',', 'pushed', 'an', 'arm-chair', 'away', ',', 'and', 'said', ':', '\"', 'If', 'you', 'stand', 'here', 'you', 'can', 'just', 'manage', 'to', 'see', 'it', '.', 'I', 'had', 'it', 'over', 'the', 'mantel-piece', ',', 'but', 'he', 'wouldn', \"'\", 't', 'let', 'it', 'stay', '.', '\"', 'Yes', '--', 'I', 'could', 'just', 'manage', 'to', 'see', 'it', '--', 'the', 'first', 'portrait', 'of', 'Jack', \"'\", 's', 'I', 'had', 'ever', 'had', 'to', 'strain', 'my', 'eyes', 'over', '!', 'Usually', 'they', 'had', 'the', 'place', 'of', 'honour', '--', 'say', 'the', 'central', 'panel', 'in', 'a', 'pale', 'yellow', 'or', '_', 'rose', 'Dubarry', '_', 'drawing-room', ',', 'or', 'a', 'monumental', 'easel', 'placed', 'so', 'that', 'it', 'took', 'the', 'light', 'through', 'curtains', 'of', 'old', 'Venetian', 'point', '.', 'The', 'more', 'modest', 'place', 'became', 'the', 'picture', 'better', ';', 'yet', ',', 'as', 'my', 'eyes', 'grew', 'accustomed', 'to', 'the', 'half-light', ',', 'all', 'the', 'characteristic', 'qualities', 'came', 'out', '--', 'all', 'the', 'hesitations', 'disguised', 'as', 'audacities', ',', 'the', 'tricks', 'of', 'prestidigitation', 'by', 'which', ',', 'with', 'such', 'consummate', 'skill', ',', 'he', 'managed', 'to', 'divert', 'attention', 'from', 'the', 'real', 'business', 'of', 'the', 'picture', 'to', 'some', 'pretty', 'irrelevance', 'of', 'detail', '.', 'Mrs', '.', 'Gisburn', ',', 'presenting', 'a', 'neutral', 'surface', 'to', 'work', 'on', '--', 'forming', ',', 'as', 'it', 'were', ',', 'so', 'inevitably', 'the', 'background', 'of', 'her', 'own', 'picture', '--', 'had', 'lent', 'herself', 'in', 'an', 'unusual', 'degree', 'to', 'the', 'display', 'of', 'this', 'false', 'virtuosity', '.', 'The', 'picture', 'was', 'one', 'of', 'Jack', \"'\", 's', '\"', 'strongest', ',', '\"', 'as', 'his', 'admirers', 'would', 'have', 'put', 'it', '--', 'it', 'represented', ',', 'on', 'his', 'part', ',', 'a', 'swelling', 'of', 'muscles', ',', 'a', 'congesting', 'of', 'veins', ',', 'a', 'balancing', ',', 'straddling', 'and', 'straining', ',', 'that', 'reminded', 'one', 'of', 'the', 'circus-clown', \"'\", 's', 'ironic', 'efforts', 'to', 'lift', 'a', 'feather', '.', 'It', 'met', ',', 'in', 'short', ',', 'at', 'every', 'point', 'the', 'demand', 'of', 'lovely', 'woman', 'to', 'be', 'painted', '\"', 'strongly', '\"', 'because', 'she', 'was', 'tired', 'of', 'being', 'painted', '\"', 'sweetly', '\"', '--', 'and', 'yet', 'not', 'to', 'lose', 'an', 'atom', 'of', 'the', 'sweetness', '.', '\"', 'It', \"'\", 's', 'the', 'last', 'he', 'painted', ',', 'you', 'know', ',', '\"', 'Mrs', '.', 'Gisburn', 'said', 'with', 'pardonable', 'pride', '.', '\"', 'The', 'last', 'but', 'one', ',', '\"', 'she', 'corrected', 'herself', '--', '\"', 'but', 'the', 'other', 'doesn', \"'\", 't', 'count', ',', 'because', 'he', 'destroyed', 'it', '.', '\"', '\"', 'Destroyed', 'it', '?', '\"', 'I', 'was', 'about', 'to', 'follow', 'up', 'this', 'clue', 'when', 'I', 'heard', 'a', 'footstep', 'and', 'saw', 'Jack', 'himself', 'on', 'the', 'threshold', '.', 'As', 'he', 'stood', 'there', ',', 'his', 'hands', 'in', 'the', 'pockets', 'of', 'his', 'velveteen', 'coat', ',', 'the', 'thin', 'brown', 'waves', 'of', 'hair', 'pushed', 'back', 'from', 'his', 'white', 'forehead', ',', 'his', 'lean', 'sunburnt', 'cheeks', 'furrowed', 'by', 'a', 'smile', 'that', 'lifted', 'the', 'tips', 'of', 'a', 'self-confident', 'moustache', ',', 'I', 'felt', 'to', 'what', 'a', 'degree', 'he', 'had', 'the', 'same', 'quality', 'as', 'his', 'pictures', '--', 'the', 'quality', 'of', 'looking', 'cleverer', 'than', 'he', 'was', '.', 'His', 'wife', 'glanced', 'at', 'him', 'deprecatingly', ',', 'but', 'his', 'eyes', 'travelled', 'past', 'her', 'to', 'the', 'portrait', '.', '\"', 'Mr', '.', 'Rickham', 'wanted', 'to', 'see', 'it', ',', '\"', 'she', 'began', ',', 'as', 'if', 'excusing', 'herself', '.', 'He', 'shrugged', 'his', 'shoulders', ',', 'still', 'smiling', '.', '\"', 'Oh', ',', 'Rickham', 'found', 'me', 'out', 'long', 'ago', ',', '\"', 'he', 'said', 'lightly', ';', 'then', ',', 'passing', 'his', 'arm', 'through', 'mine', ':', '\"', 'Come', 'and', 'see', 'the', 'rest', 'of', 'the', 'house', '.', '\"', 'He', 'showed', 'it', 'to', 'me', 'with', 'a', 'kind', 'of', 'naive', 'suburban', 'pride', ':', 'the', 'bath-rooms', ',', 'the', 'speaking-tubes', ',', 'the', 'dress-closets', ',', 'the', 'trouser-presses', '--', 'all', 'the', 'complex', 'simplifications', 'of', 'the', 'millionaire', \"'\", 's', 'domestic', 'economy', '.', 'And', 'whenever', 'my', 'wonder', 'paid', 'the', 'expected', 'tribute', 'he', 'said', ',', 'throwing', 'out', 'his', 'chest', 'a', 'little', ':', '\"', 'Yes', ',', 'I', 'really', 'don', \"'\", 't', 'see', 'how', 'people', 'manage', 'to', 'live', 'without', 'that', '.', '\"', 'Well', '--', 'it', 'was', 'just', 'the', 'end', 'one', 'might', 'have', 'foreseen', 'for', 'him', '.', 'Only', 'he', 'was', ',', 'through', 'it', 'all', 'and', 'in', 'spite', 'of', 'it', 'all', '--', 'as', 'he', 'had', 'been', 'through', ',', 'and', 'in', 'spite', 'of', ',', 'his', 'pictures', '--', 'so', 'handsome', ',', 'so', 'charming', ',', 'so', 'disarming', ',', 'that', 'one', 'longed', 'to', 'cry', 'out', ':', '\"', 'Be', 'dissatisfied', 'with', 'your', 'leisure', '!', '\"', 'as', 'once', 'one', 'had', 'longed', 'to', 'say', ':', '\"', 'Be', 'dissatisfied', 'with', 'your', 'work', '!', '\"', 'But', ',', 'with', 'the', 'cry', 'on', 'my', 'lips', ',', 'my', 'diagnosis', 'suffered', 'an', 'unexpected', 'check', '.', '\"', 'This', 'is', 'my', 'own', 'lair', ',', '\"', 'he', 'said', ',', 'leading', 'me', 'into', 'a', 'dark', 'plain', 'room', 'at', 'the', 'end', 'of', 'the', 'florid', 'vista', '.', 'It', 'was', 'square', 'and', 'brown', 'and', 'leathery', ':', 'no', '\"', 'effects', '\"', ';', 'no', 'bric-a-brac', ',', 'none', 'of', 'the', 'air', 'of', 'posing', 'for', 'reproduction', 'in', 'a', 'picture', 'weekly', '--', 'above', 'all', ',', 'no', 'least', 'sign', 'of', 'ever', 'having', 'been', 'used', 'as', 'a', 'studio', '.', 'The', 'fact', 'brought', 'home', 'to', 'me', 'the', 'absolute', 'finality', 'of', 'Jack', \"'\", 's', 'break', 'with', 'his', 'old', 'life', '.', '\"', 'Don', \"'\", 't', 'you', 'ever', 'dabble', 'with', 'paint', 'any', 'more', '?', '\"', 'I', 'asked', ',', 'still', 'looking', 'about', 'for', 'a', 'trace', 'of', 'such', 'activity', '.', '\"', 'Never', ',', '\"', 'he', 'said', 'briefly', '.', '\"', 'Or', 'water-colour', '--', 'or', 'etching', '?', '\"', 'His', 'confident', 'eyes', 'grew', 'dim', ',', 'and', 'his', 'cheeks', 'paled', 'a', 'little', 'under', 'their', 'handsome', 'sunburn', '.', '\"', 'Never', 'think', 'of', 'it', ',', 'my', 'dear', 'fellow', '--', 'any', 'more', 'than', 'if', 'I', \"'\", 'd', 'never', 'touched', 'a', 'brush', '.', '\"', 'And', 'his', 'tone', 'told', 'me', 'in', 'a', 'flash', 'that', 'he', 'never', 'thought', 'of', 'anything', 'else', '.', 'I', 'moved', 'away', ',', 'instinctively', 'embarrassed', 'by', 'my', 'unexpected', 'discovery', ';', 'and', 'as', 'I', 'turned', ',', 'my', 'eye', 'fell', 'on', 'a', 'small', 'picture', 'above', 'the', 'mantel-piece', '--', 'the', 'only', 'object', 'breaking', 'the', 'plain', 'oak', 'panelling', 'of', 'the', 'room', '.', '\"', 'Oh', ',', 'by', 'Jove', '!', '\"', 'I', 'said', '.', 'It', 'was', 'a', 'sketch', 'of', 'a', 'donkey', '--', 'an', 'old', 'tired', 'donkey', ',', 'standing', 'in', 'the', 'rain', 'under', 'a', 'wall', '.', '\"', 'By', 'Jove', '--', 'a', 'Stroud', '!', '\"', 'I', 'cried', '.', 'He', 'was', 'silent', ';', 'but', 'I', 'felt', 'him', 'close', 'behind', 'me', ',', 'breathing', 'a', 'little', 'quickly', '.', '\"', 'What', 'a', 'wonder', '!', 'Made', 'with', 'a', 'dozen', 'lines', '--', 'but', 'on', 'everlasting', 'foundations', '.', 'You', 'lucky', 'chap', ',', 'where', 'did', 'you', 'get', 'it', '?', '\"', 'He', 'answered', 'slowly', ':', '\"', 'Mrs', '.', 'Stroud', 'gave', 'it', 'to', 'me', '.', '\"', '\"', 'Ah', '--', 'I', 'didn', \"'\", 't', 'know', 'you', 'even', 'knew', 'the', 'Strouds', '.', 'He', 'was', 'such', 'an', 'inflexible', 'hermit', '.', '\"', '\"', 'I', 'didn', \"'\", 't', '--', 'till', 'after', '.', '.', '.', '.', 'She', 'sent', 'for', 'me', 'to', 'paint', 'him', 'when', 'he', 'was', 'dead', '.', '\"', '\"', 'When', 'he', 'was', 'dead', '?', 'You', '?', '\"', 'I', 'must', 'have', 'let', 'a', 'little', 'too', 'much', 'amazement', 'escape', 'through', 'my', 'surprise', ',', 'for', 'he', 'answered', 'with', 'a', 'deprecating', 'laugh', ':', '\"', 'Yes', '--', 'she', \"'\", 's', 'an', 'awful', 'simpleton', ',', 'you', 'know', ',', 'Mrs', '.', 'Stroud', '.', 'Her', 'only', 'idea', 'was', 'to', 'have', 'him', 'done', 'by', 'a', 'fashionable', 'painter', '--', 'ah', ',', 'poor', 'Stroud', '!', 'She', 'thought', 'it', 'the', 'surest', 'way', 'of', 'proclaiming', 'his', 'greatness', '--', 'of', 'forcing', 'it', 'on', 'a', 'purblind', 'public', '.', 'And', 'at', 'the', 'moment', 'I', 'was', '_', 'the', '_', 'fashionable', 'painter', '.', '\"', '\"', 'Ah', ',', 'poor', 'Stroud', '--', 'as', 'you', 'say', '.', 'Was', '_', 'that', '_', 'his', 'history', '?', '\"', '\"', 'That', 'was', 'his', 'history', '.', 'She', 'believed', 'in', 'him', ',', 'gloried', 'in', 'him', '--', 'or', 'thought', 'she', 'did', '.', 'But', 'she', 'couldn', \"'\", 't', 'bear', 'not', 'to', 'have', 'all', 'the', 'drawing-rooms', 'with', 'her', '.', 'She', 'couldn', \"'\", 't', 'bear', 'the', 'fact', 'that', ',', 'on', 'varnishing', 'days', ',', 'one', 'could', 'always', 'get', 'near', 'enough', 'to', 'see', 'his', 'pictures', '.', 'Poor', 'woman', '!', 'She', \"'\", 's', 'just', 'a', 'fragment', 'groping', 'for', 'other', 'fragments', '.', 'Stroud', 'is', 'the', 'only', 'whole', 'I', 'ever', 'knew', '.', '\"', '\"', 'You', 'ever', 'knew', '?', 'But', 'you', 'just', 'said', '--', '\"', 'Gisburn', 'had', 'a', 'curious', 'smile', 'in', 'his', 'eyes', '.', '\"', 'Oh', ',', 'I', 'knew', 'him', ',', 'and', 'he', 'knew', 'me', '--', 'only', 'it', 'happened', 'after', 'he', 'was', 'dead', '.', '\"', 'I', 'dropped', 'my', 'voice', 'instinctively', '.', '\"', 'When', 'she', 'sent', 'for', 'you', '?', '\"', '\"', 'Yes', '--', 'quite', 'insensible', 'to', 'the', 'irony', '.', 'She', 'wanted', 'him', 'vindicated', '--', 'and', 'by', 'me', '!', '\"', 'He', 'laughed', 'again', ',', 'and', 'threw', 'back', 'his', 'head', 'to', 'look', 'up', 'at', 'the', 'sketch', 'of', 'the', 'donkey', '.', '\"', 'There', 'were', 'days', 'when', 'I', 'couldn', \"'\", 't', 'look', 'at', 'that', 'thing', '--', 'couldn', \"'\", 't', 'face', 'it', '.', 'But', 'I', 'forced', 'myself', 'to', 'put', 'it', 'here', ';', 'and', 'now', 'it', \"'\", 's', 'cured', 'me', '--', 'cured', 'me', '.', 'That', \"'\", 's', 'the', 'reason', 'why', 'I', 'don', \"'\", 't', 'dabble', 'any', 'more', ',', 'my', 'dear', 'Rickham', ';', 'or', 'rather', 'Stroud', 'himself', 'is', 'the', 'reason', '.', '\"', 'For', 'the', 'first', 'time', 'my', 'idle', 'curiosity', 'about', 'my', 'companion', 'turned', 'into', 'a', 'serious', 'desire', 'to', 'understand', 'him', 'better', '.', '\"', 'I', 'wish', 'you', \"'\", 'd', 'tell', 'me', 'how', 'it', 'happened', ',', '\"', 'I', 'said', '.', 'He', 'stood', 'looking', 'up', 'at', 'the', 'sketch', ',', 'and', 'twirling', 'between', 'his', 'fingers', 'a', 'cigarette', 'he', 'had', 'forgotten', 'to', 'light', '.', 'Suddenly', 'he', 'turned', 'toward', 'me', '.', '\"', 'I', \"'\", 'd', 'rather', 'like', 'to', 'tell', 'you', '--', 'because', 'I', \"'\", 've', 'always', 'suspected', 'you', 'of', 'loathing', 'my', 'work', '.', '\"', 'I', 'made', 'a', 'deprecating', 'gesture', ',', 'which', 'he', 'negatived', 'with', 'a', 'good-humoured', 'shrug', '.', '\"', 'Oh', ',', 'I', 'didn', \"'\", 't', 'care', 'a', 'straw', 'when', 'I', 'believed', 'in', 'myself', '--', 'and', 'now', 'it', \"'\", 's', 'an', 'added', 'tie', 'between', 'us', '!', '\"', 'He', 'laughed', 'slightly', ',', 'without', 'bitterness', ',', 'and', 'pushed', 'one', 'of', 'the', 'deep', 'arm-chairs', 'forward', '.', '\"', 'There', ':', 'make', 'yourself', 'comfortable', '--', 'and', 'here', 'are', 'the', 'cigars', 'you', 'like', '.', '\"', 'He', 'placed', 'them', 'at', 'my', 'elbow', 'and', 'continued', 'to', 'wander', 'up', 'and', 'down', 'the', 'room', ',', 'stopping', 'now', 'and', 'then', 'beneath', 'the', 'picture', '.', '\"', 'How', 'it', 'happened', '?', 'I', 'can', 'tell', 'you', 'in', 'five', 'minutes', '--', 'and', 'it', 'didn', \"'\", 't', 'take', 'much', 'longer', 'to', 'happen', '.', '.', '.', '.', 'I', 'can', 'remember', 'now', 'how', 'surprised', 'and', 'pleased', 'I', 'was', 'when', 'I', 'got', 'Mrs', '.', 'Stroud', \"'\", 's', 'note', '.', 'Of', 'course', ',', 'deep', 'down', ',', 'I', 'had', 'always', '_', 'felt', '_', 'there', 'was', 'no', 'one', 'like', 'him', '--', 'only', 'I', 'had', 'gone', 'with', 'the', 'stream', ',', 'echoed', 'the', 'usual', 'platitudes', 'about', 'him', ',', 'till', 'I', 'half', 'got', 'to', 'think', 'he', 'was', 'a', 'failure', ',', 'one', 'of', 'the', 'kind', 'that', 'are', 'left', 'behind', '.', 'By', 'Jove', ',', 'and', 'he', '_', 'was', '_', 'left', 'behind', '--', 'because', 'he', 'had', 'come', 'to', 'stay', '!', 'The', 'rest', 'of', 'us', 'had', 'to', 'let', 'ourselves', 'be', 'swept', 'along', 'or', 'go', 'under', ',', 'but', 'he', 'was', 'high', 'above', 'the', 'current', '--', 'on', 'everlasting', 'foundations', ',', 'as', 'you', 'say', '.', '\"', 'Well', ',', 'I', 'went', 'off', 'to', 'the', 'house', 'in', 'my', 'most', 'egregious', 'mood', '--', 'rather', 'moved', ',', 'Lord', 'forgive', 'me', ',', 'at', 'the', 'pathos', 'of', 'poor', 'Stroud', \"'\", 's', 'career', 'of', 'failure', 'being', 'crowned', 'by', 'the', 'glory', 'of', 'my', 'painting', 'him', '!', 'Of', 'course', 'I', 'meant', 'to', 'do', 'the', 'picture', 'for', 'nothing', '--', 'I', 'told', 'Mrs', '.', 'Stroud', 'so', 'when', 'she', 'began', 'to', 'stammer', 'something', 'about', 'her', 'poverty', '.', 'I', 'remember', 'getting', 'off', 'a', 'prodigious', 'phrase', 'about', 'the', 'honour', 'being', '_', 'mine', '_', '--', 'oh', ',', 'I', 'was', 'princely', ',', 'my', 'dear', 'Rickham', '!', 'I', 'was', 'posing', 'to', 'myself', 'like', 'one', 'of', 'my', 'own', 'sitters', '.', '\"', 'Then', 'I', 'was', 'taken', 'up', 'and', 'left', 'alone', 'with', 'him', '.', 'I', 'had', 'sent', 'all', 'my', 'traps', 'in', 'advance', ',', 'and', 'I', 'had', 'only', 'to', 'set', 'up', 'the', 'easel', 'and', 'get', 'to', 'work', '.', 'He', 'had', 'been', 'dead', 'only', 'twenty-four', 'hours', ',', 'and', 'he', 'died', 'suddenly', ',', 'of', 'heart', 'disease', ',', 'so', 'that', 'there', 'had', 'been', 'no', 'preliminary', 'work', 'of', 'destruction', '--', 'his', 'face', 'was', 'clear', 'and', 'untouched', '.', 'I', 'had', 'met', 'him', 'once', 'or', 'twice', ',', 'years', 'before', ',', 'and', 'thought', 'him', 'insignificant', 'and', 'dingy', '.', 'Now', 'I', 'saw', 'that', 'he', 'was', 'superb', '.', '\"', 'I', 'was', 'glad', 'at', 'first', ',', 'with', 'a', 'merely', 'aesthetic', 'satisfaction', ':', 'glad', 'to', 'have', 'my', 'hand', 'on', 'such', 'a', \"'\", 'subject', '.', \"'\", 'Then', 'his', 'strange', 'life-likeness', 'began', 'to', 'affect', 'me', 'queerly', '--', 'as', 'I', 'blocked', 'the', 'head', 'in', 'I', 'felt', 'as', 'if', 'he', 'were', 'watching', 'me', 'do', 'it', '.', 'The', 'sensation', 'was', 'followed', 'by', 'the', 'thought', ':', 'if', 'he', '_', 'were', '_', 'watching', 'me', ',', 'what', 'would', 'he', 'say', 'to', 'my', 'way', 'of', 'working', '?', 'My', 'strokes', 'began', 'to', 'go', 'a', 'little', 'wild', '--', 'I', 'felt', 'nervous', 'and', 'uncertain', '.', '\"', 'Once', ',', 'when', 'I', 'looked', 'up', ',', 'I', 'seemed', 'to', 'see', 'a', 'smile', 'behind', 'his', 'close', 'grayish', 'beard', '--', 'as', 'if', 'he', 'had', 'the', 'secret', ',', 'and', 'were', 'amusing', 'himself', 'by', 'holding', 'it', 'back', 'from', 'me', '.', 'That', 'exasperated', 'me', 'still', 'more', '.', 'The', 'secret', '?', 'Why', ',', 'I', 'had', 'a', 'secret', 'worth', 'twenty', 'of', 'his', '!', 'I', 'dashed', 'at', 'the', 'canvas', 'furiously', ',', 'and', 'tried', 'some', 'of', 'my', 'bravura', 'tricks', '.', 'But', 'they', 'failed', 'me', ',', 'they', 'crumbled', '.', 'I', 'saw', 'that', 'he', 'wasn', \"'\", 't', 'watching', 'the', 'showy', 'bits', '--', 'I', 'couldn', \"'\", 't', 'distract', 'his', 'attention', ';', 'he', 'just', 'kept', 'his', 'eyes', 'on', 'the', 'hard', 'passages', 'between', '.', 'Those', 'were', 'the', 'ones', 'I', 'had', 'always', 'shirked', ',', 'or', 'covered', 'up', 'with', 'some', 'lying', 'paint', '.', 'And', 'how', 'he', 'saw', 'through', 'my', 'lies', '!', '\"', 'I', 'looked', 'up', 'again', ',', 'and', 'caught', 'sight', 'of', 'that', 'sketch', 'of', 'the', 'donkey', 'hanging', 'on', 'the', 'wall', 'near', 'his', 'bed', '.', 'His', 'wife', 'told', 'me', 'afterward', 'it', 'was', 'the', 'last', 'thing', 'he', 'had', 'done', '--', 'just', 'a', 'note', 'taken', 'with', 'a', 'shaking', 'hand', ',', 'when', 'he', 'was', 'down', 'in', 'Devonshire', 'recovering', 'from', 'a', 'previous', 'heart', 'attack', '.', 'Just', 'a', 'note', '!', 'But', 'it', 'tells', 'his', 'whole', 'history', '.', 'There', 'are', 'years', 'of', 'patient', 'scornful', 'persistence', 'in', 'every', 'line', '.', 'A', 'man', 'who', 'had', 'swum', 'with', 'the', 'current', 'could', 'never', 'have', 'learned', 'that', 'mighty', 'up-stream', 'stroke', '.', '.', '.', '.', '\"', 'I', 'turned', 'back', 'to', 'my', 'work', ',', 'and', 'went', 'on', 'groping', 'and', 'muddling', ';', 'then', 'I', 'looked', 'at', 'the', 'donkey', 'again', '.', 'I', 'saw', 'that', ',', 'when', 'Stroud', 'laid', 'in', 'the', 'first', 'stroke', ',', 'he', 'knew', 'just', 'what', 'the', 'end', 'would', 'be', '.', 'He', 'had', 'possessed', 'his', 'subject', ',', 'absorbed', 'it', ',', 'recreated', 'it', '.', 'When', 'had', 'I', 'done', 'that', 'with', 'any', 'of', 'my', 'things', '?', 'They', 'hadn', \"'\", 't', 'been', 'born', 'of', 'me', '--', 'I', 'had', 'just', 'adopted', 'them', '.', '.', '.', '.', '\"', 'Hang', 'it', ',', 'Rickham', ',', 'with', 'that', 'face', 'watching', 'me', 'I', 'couldn', \"'\", 't', 'do', 'another', 'stroke', '.', 'The', 'plain', 'truth', 'was', ',', 'I', 'didn', \"'\", 't', 'know', 'where', 'to', 'put', 'it', '--', '_', 'I', 'had', 'never', 'known', '_', '.', 'Only', ',', 'with', 'my', 'sitters', 'and', 'my', 'public', ',', 'a', 'showy', 'splash', 'of', 'colour', 'covered', 'up', 'the', 'fact', '--', 'I', 'just', 'threw', 'paint', 'into', 'their', 'faces', '.', '.', '.', '.', 'Well', ',', 'paint', 'was', 'the', 'one', 'medium', 'those', 'dead', 'eyes', 'could', 'see', 'through', '--', 'see', 'straight', 'to', 'the', 'tottering', 'foundations', 'underneath', '.', 'Don', \"'\", 't', 'you', 'know', 'how', ',', 'in', 'talking', 'a', 'foreign', 'language', ',', 'even', 'fluently', ',', 'one', 'says', 'half', 'the', 'time', 'not', 'what', 'one', 'wants', 'to', 'but', 'what', 'one', 'can', '?', 'Well', '--', 'that', 'was', 'the', 'way', 'I', 'painted', ';', 'and', 'as', 'he', 'lay', 'there', 'and', 'watched', 'me', ',', 'the', 'thing', 'they', 'called', 'my', \"'\", 'technique', \"'\", 'collapsed', 'like', 'a', 'house', 'of', 'cards', '.', 'He', 'didn', \"'\", 't', 'sneer', ',', 'you', 'understand', ',', 'poor', 'Stroud', '--', 'he', 'just', 'lay', 'there', 'quietly', 'watching', ',', 'and', 'on', 'his', 'lips', ',', 'through', 'the', 'gray', 'beard', ',', 'I', 'seemed', 'to', 'hear', 'the', 'question', ':', \"'\", 'Are', 'you', 'sure', 'you', 'know', 'where', 'you', \"'\", 're', 'coming', 'out', '?', \"'\", '\"', 'If', 'I', 'could', 'have', 'painted', 'that', 'face', ',', 'with', 'that', 'question', 'on', 'it', ',', 'I', 'should', 'have', 'done', 'a', 'great', 'thing', '.', 'The', 'next', 'greatest', 'thing', 'was', 'to', 'see', 'that', 'I', 'couldn', \"'\", 't', '--', 'and', 'that', 'grace', 'was', 'given', 'me', '.', 'But', ',', 'oh', ',', 'at', 'that', 'minute', ',', 'Rickham', ',', 'was', 'there', 'anything', 'on', 'earth', 'I', 'wouldn', \"'\", 't', 'have', 'given', 'to', 'have', 'Stroud', 'alive', 'before', 'me', ',', 'and', 'to', 'hear', 'him', 'say', ':', \"'\", 'It', \"'\", 's', 'not', 'too', 'late', '--', 'I', \"'\", 'll', 'show', 'you', 'how', \"'\", '?', '\"', 'It', '_', 'was', '_', 'too', 'late', '--', 'it', 'would', 'have', 'been', ',', 'even', 'if', 'he', \"'\", 'd', 'been', 'alive', '.', 'I', 'packed', 'up', 'my', 'traps', ',', 'and', 'went', 'down', 'and', 'told', 'Mrs', '.', 'Stroud', '.', 'Of', 'course', 'I', 'didn', \"'\", 't', 'tell', 'her', '_', 'that', '_', '--', 'it', 'would', 'have', 'been', 'Greek', 'to', 'her', '.', 'I', 'simply', 'said', 'I', 'couldn', \"'\", 't', 'paint', 'him', ',', 'that', 'I', 'was', 'too', 'moved', '.', 'She', 'rather', 'liked', 'the', 'idea', '--', 'she', \"'\", 's', 'so', 'romantic', '!', 'It', 'was', 'that', 'that', 'made', 'her', 'give', 'me', 'the', 'donkey', '.', 'But', 'she', 'was', 'terribly', 'upset', 'at', 'not', 'getting', 'the', 'portrait', '--', 'she', 'did', 'so', 'want', 'him', \"'\", 'done', \"'\", 'by', 'some', 'one', 'showy', '!', 'At', 'first', 'I', 'was', 'afraid', 'she', 'wouldn', \"'\", 't', 'let', 'me', 'off', '--', 'and', 'at', 'my', 'wits', \"'\", 'end', 'I', 'suggested', 'Grindle', '.', 'Yes', ',', 'it', 'was', 'I', 'who', 'started', 'Grindle', ':', 'I', 'told', 'Mrs', '.', 'Stroud', 'he', 'was', 'the', \"'\", 'coming', \"'\", 'man', ',', 'and', 'she', 'told', 'somebody', 'else', ',', 'and', 'so', 'it', 'got', 'to', 'be', 'true', '.', '.', '.', '.', 'And', 'he', 'painted', 'Stroud', 'without', 'wincing', ';', 'and', 'she', 'hung', 'the', 'picture', 'among', 'her', 'husband', \"'\", 's', 'things', '.', '.', '.', '.', '\"', 'He', 'flung', 'himself', 'down', 'in', 'the', 'arm-chair', 'near', 'mine', ',', 'laid', 'back', 'his', 'head', ',', 'and', 'clasping', 'his', 'arms', 'beneath', 'it', ',', 'looked', 'up', 'at', 'the', 'picture', 'above', 'the', 'chimney-piece', '.', '\"', 'I', 'like', 'to', 'fancy', 'that', 'Stroud', 'himself', 'would', 'have', 'given', 'it', 'to', 'me', ',', 'if', 'he', \"'\", 'd', 'been', 'able', 'to', 'say', 'what', 'he', 'thought', 'that', 'day', '.', '\"', 'And', ',', 'in', 'answer', 'to', 'a', 'question', 'I', 'put', 'half-mechanically', '--', '\"', 'Begin', 'again', '?', '\"', 'he', 'flashed', 'out', '.', '\"', 'When', 'the', 'one', 'thing', 'that', 'brings', 'me', 'anywhere', 'near', 'him', 'is', 'that', 'I', 'knew', 'enough', 'to', 'leave', 'off', '?', '\"', 'He', 'stood', 'up', 'and', 'laid', 'his', 'hand', 'on', 'my', 'shoulder', 'with', 'a', 'laugh', '.', '\"', 'Only', 'the', 'irony', 'of', 'it', 'is', 'that', 'I', '_', 'am', '_', 'still', 'painting', '--', 'since', 'Grindle', \"'\", 's', 'doing', 'it', 'for', 'me', '!', 'The', 'Strouds', 'stand', 'alone', ',', 'and', 'happen', 'once', '--', 'but', 'there', \"'\", 's', 'no', 'exterminating', 'our', 'kind', 'of', 'art', '.', '\"']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "tokens = [t for t in re.split(r'([,.:;?_!\"()\\']|--|\\s+)', raw_text) if t and not t.isspace()]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14f81f92-2ede-4345-9658-8790f20d6942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(tokens))\n",
    "vocab_size = len(all_words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1c12915-0f8d-4e40-8ad8-64be44a9513a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "source": [
    "all_words.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "print(len(all_words))\n",
    "vocab = {token:integer for integer, token in enumerate(all_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49075ca6-4597-44f5-b037-d7f11b22038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!': 0, '\"': 1, \"'\": 2, '(': 3, ')': 4, ',': 5, '--': 6, '.': 7, ':': 8, ';': 9, '?': 10, 'A': 11, 'Ah': 12, 'Among': 13, 'And': 14, 'Are': 15, 'Arrt': 16, 'As': 17, 'At': 18, 'Be': 19, 'Begin': 20, 'Burlington': 21, 'But': 22, 'By': 23, 'Carlo': 24, 'Chicago': 25, 'Claude': 26, 'Come': 27, 'Croft': 28, 'Destroyed': 29, 'Devonshire': 30, 'Don': 31, 'Dubarry': 32, 'Emperors': 33, 'Florence': 34, 'For': 35, 'Gallery': 36, 'Gideon': 37, 'Gisburn': 38, 'Gisburns': 39, 'Grafton': 40, 'Greek': 41, 'Grindle': 42, 'Grindles': 43, 'HAD': 44, 'Had': 45, 'Hang': 46, 'Has': 47, 'He': 48, 'Her': 49, 'Hermia': 50, 'His': 51, 'How': 52, 'I': 53, 'If': 54, 'In': 55, 'It': 56, 'Jack': 57, 'Jove': 58, 'Just': 59, 'Lord': 60, 'Made': 61, 'Miss': 62, 'Money': 63, 'Monte': 64, 'Moon-dancers': 65, 'Mr': 66, 'Mrs': 67, 'My': 68, 'Never': 69, 'No': 70, 'Now': 71, 'Nutley': 72, 'Of': 73, 'Oh': 74, 'On': 75, 'Once': 76, 'Only': 77, 'Or': 78, 'Perhaps': 79, 'Poor': 80, 'Professional': 81, 'Renaissance': 82, 'Rickham': 83, 'Riviera': 84, 'Rome': 85, 'Russian': 86, 'Sevres': 87, 'She': 88, 'Stroud': 89, 'Strouds': 90, 'Suddenly': 91, 'That': 92, 'The': 93, 'Then': 94, 'There': 95, 'They': 96, 'This': 97, 'Those': 98, 'Though': 99, 'Thwing': 100, 'Thwings': 101, 'To': 102, 'Usually': 103, 'Venetian': 104, 'Victor': 105, 'Was': 106, 'We': 107, 'Well': 108, 'What': 109, 'When': 110, 'Why': 111, 'Yes': 112, 'You': 113, '_': 114, 'a': 115, 'abdication': 116, 'able': 117, 'about': 118, 'above': 119, 'abruptly': 120, 'absolute': 121, 'absorbed': 122, 'absurdity': 123, 'academic': 124, 'accuse': 125, 'accustomed': 126, 'across': 127, 'activity': 128, 'add': 129, 'added': 130, 'admirers': 131, 'adopted': 132, 'adulation': 133, 'advance': 134, 'aesthetic': 135, 'affect': 136, 'afraid': 137, 'after': 138, 'afterward': 139, 'again': 140, 'ago': 141, 'ah': 142, 'air': 143, 'alive': 144, 'all': 145, 'almost': 146, 'alone': 147, 'along': 148, 'always': 149, 'am': 150, 'amazement': 151, 'amid': 152, 'among': 153, 'amplest': 154, 'amusing': 155, 'an': 156, 'and': 157, 'another': 158, 'answer': 159, 'answered': 160, 'any': 161, 'anything': 162, 'anywhere': 163, 'apparent': 164, 'apparently': 165, 'appearance': 166, 'appeared': 167, 'appointed': 168, 'are': 169, 'arm': 170, 'arm-chair': 171, 'arm-chairs': 172, 'arms': 173, 'art': 174, 'articles': 175, 'artist': 176, 'as': 177, 'aside': 178, 'asked': 179, 'at': 180, 'atmosphere': 181, 'atom': 182, 'attack': 183, 'attention': 184, 'attitude': 185, 'audacities': 186, 'away': 187, 'awful': 188, 'axioms': 189, 'azaleas': 190, 'back': 191, 'background': 192, 'balance': 193, 'balancing': 194, 'balustraded': 195, 'basking': 196, 'bath-rooms': 197, 'be': 198, 'beaming': 199, 'bean-stalk': 200, 'bear': 201, 'beard': 202, 'beauty': 203, 'became': 204, 'because': 205, 'becoming': 206, 'bed': 207, 'been': 208, 'before': 209, 'began': 210, 'begun': 211, 'behind': 212, 'being': 213, 'believed': 214, 'beneath': 215, 'bespoke': 216, 'better': 217, 'between': 218, 'big': 219, 'bits': 220, 'bitterness': 221, 'blocked': 222, 'born': 223, 'borne': 224, 'boudoir': 225, 'bravura': 226, 'break': 227, 'breaking': 228, 'breathing': 229, 'bric-a-brac': 230, 'briefly': 231, 'brings': 232, 'bronzes': 233, 'brought': 234, 'brown': 235, 'brush': 236, 'bull': 237, 'business': 238, 'but': 239, 'buying': 240, 'by': 241, 'called': 242, 'came': 243, 'can': 244, 'canvas': 245, 'canvases': 246, 'cards': 247, 'care': 248, 'career': 249, 'caught': 250, 'central': 251, 'chair': 252, 'chap': 253, 'characteristic': 254, 'charming': 255, 'cheap': 256, 'check': 257, 'cheeks': 258, 'chest': 259, 'chimney-piece': 260, 'chucked': 261, 'cigar': 262, 'cigarette': 263, 'cigars': 264, 'circulation': 265, 'circumstance': 266, 'circus-clown': 267, 'claimed': 268, 'clasping': 269, 'clear': 270, 'cleverer': 271, 'close': 272, 'clue': 273, 'coat': 274, 'collapsed': 275, 'colour': 276, 'come': 277, 'comfortable': 278, 'coming': 279, 'companion': 280, 'compared': 281, 'complex': 282, 'confident': 283, 'congesting': 284, 'conjugal': 285, 'constraint': 286, 'consummate': 287, 'contended': 288, 'continued': 289, 'corner': 290, 'corrected': 291, 'could': 292, 'couldn': 293, 'count': 294, 'countenance': 295, 'couple': 296, 'course': 297, 'covered': 298, 'craft': 299, 'cried': 300, 'crossed': 301, 'crowned': 302, 'crumbled': 303, 'cry': 304, 'cured': 305, 'curiosity': 306, 'curious': 307, 'current': 308, 'curtains': 309, 'd': 310, 'dabble': 311, 'damask': 312, 'dark': 313, 'dashed': 314, 'day': 315, 'days': 316, 'dead': 317, 'deadening': 318, 'dear': 319, 'deep': 320, 'deerhound': 321, 'degree': 322, 'delicate': 323, 'demand': 324, 'denied': 325, 'deploring': 326, 'deprecating': 327, 'deprecatingly': 328, 'desire': 329, 'destroyed': 330, 'destruction': 331, 'desultory': 332, 'detail': 333, 'diagnosis': 334, 'did': 335, 'didn': 336, 'died': 337, 'dim': 338, 'dimmest': 339, 'dingy': 340, 'dining-room': 341, 'disarming': 342, 'discovery': 343, 'discrimination': 344, 'discussion': 345, 'disdain': 346, 'disdained': 347, 'disease': 348, 'disguised': 349, 'display': 350, 'dissatisfied': 351, 'distinguished': 352, 'distract': 353, 'divert': 354, 'do': 355, 'doesn': 356, 'doing': 357, 'domestic': 358, 'don': 359, 'done': 360, 'donkey': 361, 'down': 362, 'dozen': 363, 'dragged': 364, 'drawing-room': 365, 'drawing-rooms': 366, 'drawn': 367, 'dress-closets': 368, 'drew': 369, 'dropped': 370, 'each': 371, 'earth': 372, 'ease': 373, 'easel': 374, 'easy': 375, 'echoed': 376, 'economy': 377, 'effect': 378, 'effects': 379, 'efforts': 380, 'egregious': 381, 'eighteenth-century': 382, 'elbow': 383, 'elegant': 384, 'else': 385, 'embarrassed': 386, 'enabled': 387, 'end': 388, 'endless': 389, 'enjoy': 390, 'enlightenment': 391, 'enough': 392, 'ensuing': 393, 'equally': 394, 'equanimity': 395, 'escape': 396, 'established': 397, 'etching': 398, 'even': 399, 'event': 400, 'ever': 401, 'everlasting': 402, 'every': 403, 'exasperated': 404, 'except': 405, 'excuse': 406, 'excusing': 407, 'existed': 408, 'expected': 409, 'exquisite': 410, 'exquisitely': 411, 'extenuation': 412, 'exterminating': 413, 'extracting': 414, 'eye': 415, 'eyebrows': 416, 'eyes': 417, 'face': 418, 'faces': 419, 'fact': 420, 'faded': 421, 'failed': 422, 'failure': 423, 'fair': 424, 'faith': 425, 'false': 426, 'familiar': 427, 'famille-verte': 428, 'fancy': 429, 'fashionable': 430, 'fate': 431, 'feather': 432, 'feet': 433, 'fell': 434, 'fellow': 435, 'felt': 436, 'few': 437, 'fewer': 438, 'finality': 439, 'find': 440, 'fingers': 441, 'first': 442, 'fit': 443, 'fitting': 444, 'five': 445, 'flash': 446, 'flashed': 447, 'florid': 448, 'flowers': 449, 'fluently': 450, 'flung': 451, 'follow': 452, 'followed': 453, 'fond': 454, 'footstep': 455, 'for': 456, 'forced': 457, 'forcing': 458, 'forehead': 459, 'foreign': 460, 'foreseen': 461, 'forgive': 462, 'forgotten': 463, 'form': 464, 'formed': 465, 'forming': 466, 'forward': 467, 'fostered': 468, 'found': 469, 'foundations': 470, 'fragment': 471, 'fragments': 472, 'frame': 473, 'frames': 474, 'frequently': 475, 'friend': 476, 'from': 477, 'full': 478, 'fullest': 479, 'furiously': 480, 'furrowed': 481, 'garlanded': 482, 'garlands': 483, 'gave': 484, 'genial': 485, 'genius': 486, 'gesture': 487, 'get': 488, 'getting': 489, 'give': 490, 'given': 491, 'glad': 492, 'glanced': 493, 'glimpse': 494, 'gloried': 495, 'glory': 496, 'go': 497, 'going': 498, 'gone': 499, 'good': 500, 'good-breeding': 501, 'good-humoured': 502, 'got': 503, 'grace': 504, 'gradually': 505, 'gray': 506, 'grayish': 507, 'great': 508, 'greatest': 509, 'greatness': 510, 'grew': 511, 'groping': 512, 'growing': 513, 'had': 514, 'hadn': 515, 'hair': 516, 'half': 517, 'half-light': 518, 'half-mechanically': 519, 'hall': 520, 'hand': 521, 'hands': 522, 'handsome': 523, 'hanging': 524, 'happen': 525, 'happened': 526, 'hard': 527, 'hardly': 528, 'has': 529, 'have': 530, 'haven': 531, 'having': 532, 'he': 533, 'head': 534, 'hear': 535, 'heard': 536, 'heart': 537, 'height': 538, 'her': 539, 'here': 540, 'hermit': 541, 'herself': 542, 'hesitations': 543, 'hide': 544, 'high': 545, 'him': 546, 'himself': 547, 'hint': 548, 'his': 549, 'history': 550, 'holding': 551, 'home': 552, 'honour': 553, 'hooded': 554, 'hostess': 555, 'hot-house': 556, 'hour': 557, 'hours': 558, 'house': 559, 'how': 560, 'hung': 561, 'husband': 562, 'idea': 563, 'idle': 564, 'idling': 565, 'if': 566, 'immediately': 567, 'in': 568, 'incense': 569, 'indifferent': 570, 'inevitable': 571, 'inevitably': 572, 'inflexible': 573, 'insensible': 574, 'insignificant': 575, 'instinctively': 576, 'instructive': 577, 'interesting': 578, 'into': 579, 'ironic': 580, 'irony': 581, 'irrelevance': 582, 'irrevocable': 583, 'is': 584, 'it': 585, 'its': 586, 'itself': 587, 'jardiniere': 588, 'jealousy': 589, 'just': 590, 'keep': 591, 'kept': 592, 'kind': 593, 'knees': 594, 'knew': 595, 'know': 596, 'known': 597, 'laid': 598, 'lair': 599, 'landing': 600, 'language': 601, 'last': 602, 'late': 603, 'later': 604, 'latter': 605, 'laugh': 606, 'laughed': 607, 'lay': 608, 'leading': 609, 'lean': 610, 'learned': 611, 'least': 612, 'leathery': 613, 'leave': 614, 'led': 615, 'left': 616, 'leisure': 617, 'lends': 618, 'lent': 619, 'let': 620, 'lies': 621, 'life': 622, 'life-likeness': 623, 'lift': 624, 'lifted': 625, 'light': 626, 'lightly': 627, 'like': 628, 'liked': 629, 'line': 630, 'lines': 631, 'lingered': 632, 'lips': 633, 'lit': 634, 'little': 635, 'live': 636, 'll': 637, 'loathing': 638, 'long': 639, 'longed': 640, 'longer': 641, 'look': 642, 'looked': 643, 'looking': 644, 'lose': 645, 'loss': 646, 'lounging': 647, 'lovely': 648, 'lucky': 649, 'lump': 650, 'luncheon-table': 651, 'luxury': 652, 'lying': 653, 'made': 654, 'make': 655, 'man': 656, 'manage': 657, 'managed': 658, 'mantel-piece': 659, 'marble': 660, 'married': 661, 'may': 662, 'me': 663, 'meant': 664, 'mediocrity': 665, 'medium': 666, 'mentioned': 667, 'mere': 668, 'merely': 669, 'met': 670, 'might': 671, 'mighty': 672, 'millionaire': 673, 'mine': 674, 'minute': 675, 'minutes': 676, 'mirrors': 677, 'modest': 678, 'modesty': 679, 'moment': 680, 'money': 681, 'monumental': 682, 'mood': 683, 'morbidly': 684, 'more': 685, 'most': 686, 'mourn': 687, 'mourned': 688, 'moustache': 689, 'moved': 690, 'much': 691, 'muddling': 692, 'multiplied': 693, 'murmur': 694, 'muscles': 695, 'must': 696, 'my': 697, 'myself': 698, 'mysterious': 699, 'naive': 700, 'near': 701, 'nearly': 702, 'negatived': 703, 'nervous': 704, 'nervousness': 705, 'neutral': 706, 'never': 707, 'next': 708, 'no': 709, 'none': 710, 'not': 711, 'note': 712, 'nothing': 713, 'now': 714, 'nymphs': 715, 'oak': 716, 'obituary': 717, 'object': 718, 'objects': 719, 'occurred': 720, 'oddly': 721, 'of': 722, 'off': 723, 'often': 724, 'oh': 725, 'old': 726, 'on': 727, 'once': 728, 'one': 729, 'ones': 730, 'only': 731, 'onto': 732, 'open': 733, 'or': 734, 'other': 735, 'our': 736, 'ourselves': 737, 'out': 738, 'outline': 739, 'oval': 740, 'over': 741, 'own': 742, 'packed': 743, 'paid': 744, 'paint': 745, 'painted': 746, 'painter': 747, 'painting': 748, 'pale': 749, 'paled': 750, 'palm-trees': 751, 'panel': 752, 'panelling': 753, 'pardonable': 754, 'pardoned': 755, 'part': 756, 'passages': 757, 'passing': 758, 'past': 759, 'pastels': 760, 'pathos': 761, 'patient': 762, 'people': 763, 'perceptible': 764, 'perfect': 765, 'persistence': 766, 'persuasively': 767, 'phrase': 768, 'picture': 769, 'pictures': 770, 'pines': 771, 'pink': 772, 'place': 773, 'placed': 774, 'plain': 775, 'platitudes': 776, 'pleased': 777, 'pockets': 778, 'point': 779, 'poised': 780, 'poor': 781, 'portrait': 782, 'posing': 783, 'possessed': 784, 'poverty': 785, 'predicted': 786, 'preliminary': 787, 'presenting': 788, 'prestidigitation': 789, 'pretty': 790, 'previous': 791, 'price': 792, 'pride': 793, 'princely': 794, 'prism': 795, 'problem': 796, 'proclaiming': 797, 'prodigious': 798, 'profusion': 799, 'protest': 800, 'prove': 801, 'public': 802, 'purblind': 803, 'purely': 804, 'pushed': 805, 'put': 806, 'qualities': 807, 'quality': 808, 'queerly': 809, 'question': 810, 'quickly': 811, 'quietly': 812, 'quite': 813, 'quote': 814, 'rain': 815, 'raised': 816, 'random': 817, 'rather': 818, 're': 819, 'real': 820, 'really': 821, 'reared': 822, 'reason': 823, 'reassurance': 824, 'recovering': 825, 'recreated': 826, 'reflected': 827, 'reflection': 828, 'regrets': 829, 'relatively': 830, 'remained': 831, 'remember': 832, 'reminded': 833, 'repeating': 834, 'represented': 835, 'reproduction': 836, 'resented': 837, 'resolve': 838, 'resources': 839, 'rest': 840, 'rich': 841, 'ridiculous': 842, 'robbed': 843, 'romantic': 844, 'room': 845, 'rose': 846, 'rs': 847, 'rule': 848, 'run': 849, 's': 850, 'said': 851, 'same': 852, 'satisfaction': 853, 'savour': 854, 'saw': 855, 'say': 856, 'saying': 857, 'says': 858, 'scorn': 859, 'scornful': 860, 'secret': 861, 'see': 862, 'seemed': 863, 'seen': 864, 'self-confident': 865, 'send': 866, 'sensation': 867, 'sensitive': 868, 'sent': 869, 'serious': 870, 'set': 871, 'sex': 872, 'shade': 873, 'shaking': 874, 'shall': 875, 'she': 876, 'shirked': 877, 'short': 878, 'should': 879, 'shoulder': 880, 'shoulders': 881, 'show': 882, 'showed': 883, 'showy': 884, 'shrug': 885, 'shrugged': 886, 'sight': 887, 'sign': 888, 'silent': 889, 'silver': 890, 'similar': 891, 'simpleton': 892, 'simplifications': 893, 'simply': 894, 'since': 895, 'single': 896, 'sitter': 897, 'sitters': 898, 'sketch': 899, 'skill': 900, 'slight': 901, 'slightly': 902, 'slowly': 903, 'small': 904, 'smile': 905, 'smiling': 906, 'sneer': 907, 'so': 908, 'solace': 909, 'some': 910, 'somebody': 911, 'something': 912, 'spacious': 913, 'spaniel': 914, 'speaking-tubes': 915, 'speculations': 916, 'spite': 917, 'splash': 918, 'square': 919, 'stairs': 920, 'stammer': 921, 'stand': 922, 'standing': 923, 'started': 924, 'stay': 925, 'still': 926, 'stocked': 927, 'stood': 928, 'stopped': 929, 'stopping': 930, 'straddling': 931, 'straight': 932, 'strain': 933, 'straining': 934, 'strange': 935, 'straw': 936, 'stream': 937, 'stroke': 938, 'strokes': 939, 'strolled': 940, 'strongest': 941, 'strongly': 942, 'struck': 943, 'studio': 944, 'stuff': 945, 'subject': 946, 'substantial': 947, 'suburban': 948, 'such': 949, 'suddenly': 950, 'suffered': 951, 'sugar': 952, 'suggested': 953, 'sunburn': 954, 'sunburnt': 955, 'sunlit': 956, 'superb': 957, 'sure': 958, 'surest': 959, 'surface': 960, 'surprise': 961, 'surprised': 962, 'surrounded': 963, 'suspected': 964, 'sweetly': 965, 'sweetness': 966, 'swelling': 967, 'swept': 968, 'swum': 969, 't': 970, 'table': 971, 'take': 972, 'taken': 973, 'talking': 974, 'tea': 975, 'tears': 976, 'technicalities': 977, 'technique': 978, 'tell': 979, 'tells': 980, 'tempting': 981, 'terra-cotta': 982, 'terrace': 983, 'terraces': 984, 'terribly': 985, 'than': 986, 'that': 987, 'the': 988, 'their': 989, 'them': 990, 'then': 991, 'there': 992, 'therefore': 993, 'they': 994, 'thin': 995, 'thing': 996, 'things': 997, 'think': 998, 'this': 999, 'thither': 1000, 'those': 1001, 'though': 1002, 'thought': 1003, 'three': 1004, 'threshold': 1005, 'threw': 1006, 'through': 1007, 'throwing': 1008, 'tie': 1009, 'till': 1010, 'time': 1011, 'timorously': 1012, 'tinge': 1013, 'tips': 1014, 'tired': 1015, 'to': 1016, 'told': 1017, 'tone': 1018, 'tones': 1019, 'too': 1020, 'took': 1021, 'tottering': 1022, 'touched': 1023, 'toward': 1024, 'trace': 1025, 'trade': 1026, 'transmute': 1027, 'traps': 1028, 'travelled': 1029, 'tribute': 1030, 'tributes': 1031, 'tricks': 1032, 'tried': 1033, 'trouser-presses': 1034, 'true': 1035, 'truth': 1036, 'turned': 1037, 'twenty': 1038, 'twenty-four': 1039, 'twice': 1040, 'twirling': 1041, 'unaccountable': 1042, 'uncertain': 1043, 'under': 1044, 'underlay': 1045, 'underneath': 1046, 'understand': 1047, 'unexpected': 1048, 'untouched': 1049, 'unusual': 1050, 'up': 1051, 'up-stream': 1052, 'upon': 1053, 'upset': 1054, 'upstairs': 1055, 'us': 1056, 'used': 1057, 'usual': 1058, 'value': 1059, 'varnishing': 1060, 'vases': 1061, 've': 1062, 'veins': 1063, 'velveteen': 1064, 'very': 1065, 'villa': 1066, 'vindicated': 1067, 'virtuosity': 1068, 'vista': 1069, 'vocation': 1070, 'voice': 1071, 'wall': 1072, 'wander': 1073, 'want': 1074, 'wanted': 1075, 'wants': 1076, 'was': 1077, 'wasn': 1078, 'watched': 1079, 'watching': 1080, 'water-colour': 1081, 'waves': 1082, 'way': 1083, 'weekly': 1084, 'weeks': 1085, 'welcome': 1086, 'went': 1087, 'were': 1088, 'what': 1089, 'when': 1090, 'whenever': 1091, 'where': 1092, 'which': 1093, 'while': 1094, 'white': 1095, 'white-panelled': 1096, 'who': 1097, 'whole': 1098, 'whom': 1099, 'why': 1100, 'wide': 1101, 'widow': 1102, 'wife': 1103, 'wild': 1104, 'wincing': 1105, 'window-curtains': 1106, 'wish': 1107, 'with': 1108, 'without': 1109, 'wits': 1110, 'woman': 1111, 'women': 1112, 'won': 1113, 'wonder': 1114, 'wondered': 1115, 'word': 1116, 'work': 1117, 'working': 1118, 'worth': 1119, 'would': 1120, 'wouldn': 1121, 'year': 1122, 'years': 1123, 'yellow': 1124, 'yet': 1125, 'you': 1126, 'younger': 1127, 'your': 1128, 'yourself': 1129, '<|endoftext|>': 1130, '<|unk|>': 1131}\n",
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n",
      "('Burlington', 21)\n",
      "('But', 22)\n",
      "('By', 23)\n",
      "('Carlo', 24)\n",
      "('Chicago', 25)\n",
      "('Claude', 26)\n",
      "('Come', 27)\n",
      "('Croft', 28)\n",
      "('Destroyed', 29)\n",
      "('Devonshire', 30)\n",
      "('Don', 31)\n",
      "('Dubarry', 32)\n",
      "('Emperors', 33)\n",
      "('Florence', 34)\n",
      "('For', 35)\n",
      "('Gallery', 36)\n",
      "('Gideon', 37)\n",
      "('Gisburn', 38)\n",
      "('Gisburns', 39)\n",
      "('Grafton', 40)\n",
      "('Greek', 41)\n",
      "('Grindle', 42)\n",
      "('Grindles', 43)\n",
      "('HAD', 44)\n",
      "('Had', 45)\n",
      "('Hang', 46)\n",
      "('Has', 47)\n",
      "('He', 48)\n",
      "('Her', 49)\n",
      "('Hermia', 50)\n",
      "('His', 51)\n",
      "('How', 52)\n",
      "('I', 53)\n",
      "('If', 54)\n",
      "('In', 55)\n",
      "('It', 56)\n",
      "('Jack', 57)\n",
      "('Jove', 58)\n",
      "('Just', 59)\n",
      "('Lord', 60)\n",
      "('Made', 61)\n",
      "('Miss', 62)\n",
      "('Money', 63)\n",
      "('Monte', 64)\n",
      "('Moon-dancers', 65)\n",
      "('Mr', 66)\n",
      "('Mrs', 67)\n",
      "('My', 68)\n",
      "('Never', 69)\n",
      "('No', 70)\n",
      "('Now', 71)\n",
      "('Nutley', 72)\n",
      "('Of', 73)\n",
      "('Oh', 74)\n",
      "('On', 75)\n",
      "('Once', 76)\n",
      "('Only', 77)\n",
      "('Or', 78)\n",
      "('Perhaps', 79)\n",
      "('Poor', 80)\n",
      "('Professional', 81)\n",
      "('Renaissance', 82)\n",
      "('Rickham', 83)\n",
      "('Riviera', 84)\n",
      "('Rome', 85)\n",
      "('Russian', 86)\n",
      "('Sevres', 87)\n",
      "('She', 88)\n",
      "('Stroud', 89)\n",
      "('Strouds', 90)\n",
      "('Suddenly', 91)\n",
      "('That', 92)\n",
      "('The', 93)\n",
      "('Then', 94)\n",
      "('There', 95)\n",
      "('They', 96)\n",
      "('This', 97)\n",
      "('Those', 98)\n",
      "('Though', 99)\n",
      "('Thwing', 100)\n",
      "('Thwings', 101)\n",
      "('To', 102)\n",
      "('Usually', 103)\n",
      "('Venetian', 104)\n",
      "('Victor', 105)\n",
      "('Was', 106)\n",
      "('We', 107)\n",
      "('Well', 108)\n",
      "('What', 109)\n",
      "('When', 110)\n",
      "('Why', 111)\n",
      "('Yes', 112)\n",
      "('You', 113)\n",
      "('_', 114)\n",
      "('a', 115)\n",
      "('abdication', 116)\n",
      "('able', 117)\n",
      "('about', 118)\n",
      "('above', 119)\n",
      "('abruptly', 120)\n",
      "('absolute', 121)\n",
      "('absorbed', 122)\n",
      "('absurdity', 123)\n",
      "('academic', 124)\n",
      "('accuse', 125)\n",
      "('accustomed', 126)\n",
      "('across', 127)\n",
      "('activity', 128)\n",
      "('add', 129)\n",
      "('added', 130)\n",
      "('admirers', 131)\n",
      "('adopted', 132)\n",
      "('adulation', 133)\n",
      "('advance', 134)\n",
      "('aesthetic', 135)\n",
      "('affect', 136)\n",
      "('afraid', 137)\n",
      "('after', 138)\n",
      "('afterward', 139)\n",
      "('again', 140)\n",
      "('ago', 141)\n",
      "('ah', 142)\n",
      "('air', 143)\n",
      "('alive', 144)\n",
      "('all', 145)\n",
      "('almost', 146)\n",
      "('alone', 147)\n",
      "('along', 148)\n",
      "('always', 149)\n",
      "('am', 150)\n",
      "('amazement', 151)\n",
      "('amid', 152)\n",
      "('among', 153)\n",
      "('amplest', 154)\n",
      "('amusing', 155)\n",
      "('an', 156)\n",
      "('and', 157)\n",
      "('another', 158)\n",
      "('answer', 159)\n",
      "('answered', 160)\n",
      "('any', 161)\n",
      "('anything', 162)\n",
      "('anywhere', 163)\n",
      "('apparent', 164)\n",
      "('apparently', 165)\n",
      "('appearance', 166)\n",
      "('appeared', 167)\n",
      "('appointed', 168)\n",
      "('are', 169)\n",
      "('arm', 170)\n",
      "('arm-chair', 171)\n",
      "('arm-chairs', 172)\n",
      "('arms', 173)\n",
      "('art', 174)\n",
      "('articles', 175)\n",
      "('artist', 176)\n",
      "('as', 177)\n",
      "('aside', 178)\n",
      "('asked', 179)\n",
      "('at', 180)\n",
      "('atmosphere', 181)\n",
      "('atom', 182)\n",
      "('attack', 183)\n",
      "('attention', 184)\n",
      "('attitude', 185)\n",
      "('audacities', 186)\n",
      "('away', 187)\n",
      "('awful', 188)\n",
      "('axioms', 189)\n",
      "('azaleas', 190)\n",
      "('back', 191)\n",
      "('background', 192)\n",
      "('balance', 193)\n",
      "('balancing', 194)\n",
      "('balustraded', 195)\n",
      "('basking', 196)\n",
      "('bath-rooms', 197)\n",
      "('be', 198)\n",
      "('beaming', 199)\n",
      "('bean-stalk', 200)\n",
      "('bear', 201)\n",
      "('beard', 202)\n",
      "('beauty', 203)\n",
      "('became', 204)\n",
      "('because', 205)\n",
      "('becoming', 206)\n",
      "('bed', 207)\n",
      "('been', 208)\n",
      "('before', 209)\n",
      "('began', 210)\n",
      "('begun', 211)\n",
      "('behind', 212)\n",
      "('being', 213)\n",
      "('believed', 214)\n",
      "('beneath', 215)\n",
      "('bespoke', 216)\n",
      "('better', 217)\n",
      "('between', 218)\n",
      "('big', 219)\n",
      "('bits', 220)\n",
      "('bitterness', 221)\n",
      "('blocked', 222)\n",
      "('born', 223)\n",
      "('borne', 224)\n",
      "('boudoir', 225)\n",
      "('bravura', 226)\n",
      "('break', 227)\n",
      "('breaking', 228)\n",
      "('breathing', 229)\n",
      "('bric-a-brac', 230)\n",
      "('briefly', 231)\n",
      "('brings', 232)\n",
      "('bronzes', 233)\n",
      "('brought', 234)\n",
      "('brown', 235)\n",
      "('brush', 236)\n",
      "('bull', 237)\n",
      "('business', 238)\n",
      "('but', 239)\n",
      "('buying', 240)\n",
      "('by', 241)\n",
      "('called', 242)\n",
      "('came', 243)\n",
      "('can', 244)\n",
      "('canvas', 245)\n",
      "('canvases', 246)\n",
      "('cards', 247)\n",
      "('care', 248)\n",
      "('career', 249)\n",
      "('caught', 250)\n",
      "('central', 251)\n",
      "('chair', 252)\n",
      "('chap', 253)\n",
      "('characteristic', 254)\n",
      "('charming', 255)\n",
      "('cheap', 256)\n",
      "('check', 257)\n",
      "('cheeks', 258)\n",
      "('chest', 259)\n",
      "('chimney-piece', 260)\n",
      "('chucked', 261)\n",
      "('cigar', 262)\n",
      "('cigarette', 263)\n",
      "('cigars', 264)\n",
      "('circulation', 265)\n",
      "('circumstance', 266)\n",
      "('circus-clown', 267)\n",
      "('claimed', 268)\n",
      "('clasping', 269)\n",
      "('clear', 270)\n",
      "('cleverer', 271)\n",
      "('close', 272)\n",
      "('clue', 273)\n",
      "('coat', 274)\n",
      "('collapsed', 275)\n",
      "('colour', 276)\n",
      "('come', 277)\n",
      "('comfortable', 278)\n",
      "('coming', 279)\n",
      "('companion', 280)\n",
      "('compared', 281)\n",
      "('complex', 282)\n",
      "('confident', 283)\n",
      "('congesting', 284)\n",
      "('conjugal', 285)\n",
      "('constraint', 286)\n",
      "('consummate', 287)\n",
      "('contended', 288)\n",
      "('continued', 289)\n",
      "('corner', 290)\n",
      "('corrected', 291)\n",
      "('could', 292)\n",
      "('couldn', 293)\n",
      "('count', 294)\n",
      "('countenance', 295)\n",
      "('couple', 296)\n",
      "('course', 297)\n",
      "('covered', 298)\n",
      "('craft', 299)\n",
      "('cried', 300)\n",
      "('crossed', 301)\n",
      "('crowned', 302)\n",
      "('crumbled', 303)\n",
      "('cry', 304)\n",
      "('cured', 305)\n",
      "('curiosity', 306)\n",
      "('curious', 307)\n",
      "('current', 308)\n",
      "('curtains', 309)\n",
      "('d', 310)\n",
      "('dabble', 311)\n",
      "('damask', 312)\n",
      "('dark', 313)\n",
      "('dashed', 314)\n",
      "('day', 315)\n",
      "('days', 316)\n",
      "('dead', 317)\n",
      "('deadening', 318)\n",
      "('dear', 319)\n",
      "('deep', 320)\n",
      "('deerhound', 321)\n",
      "('degree', 322)\n",
      "('delicate', 323)\n",
      "('demand', 324)\n",
      "('denied', 325)\n",
      "('deploring', 326)\n",
      "('deprecating', 327)\n",
      "('deprecatingly', 328)\n",
      "('desire', 329)\n",
      "('destroyed', 330)\n",
      "('destruction', 331)\n",
      "('desultory', 332)\n",
      "('detail', 333)\n",
      "('diagnosis', 334)\n",
      "('did', 335)\n",
      "('didn', 336)\n",
      "('died', 337)\n",
      "('dim', 338)\n",
      "('dimmest', 339)\n",
      "('dingy', 340)\n",
      "('dining-room', 341)\n",
      "('disarming', 342)\n",
      "('discovery', 343)\n",
      "('discrimination', 344)\n",
      "('discussion', 345)\n",
      "('disdain', 346)\n",
      "('disdained', 347)\n",
      "('disease', 348)\n",
      "('disguised', 349)\n",
      "('display', 350)\n",
      "('dissatisfied', 351)\n",
      "('distinguished', 352)\n",
      "('distract', 353)\n",
      "('divert', 354)\n",
      "('do', 355)\n",
      "('doesn', 356)\n",
      "('doing', 357)\n",
      "('domestic', 358)\n",
      "('don', 359)\n",
      "('done', 360)\n",
      "('donkey', 361)\n",
      "('down', 362)\n",
      "('dozen', 363)\n",
      "('dragged', 364)\n",
      "('drawing-room', 365)\n",
      "('drawing-rooms', 366)\n",
      "('drawn', 367)\n",
      "('dress-closets', 368)\n",
      "('drew', 369)\n",
      "('dropped', 370)\n",
      "('each', 371)\n",
      "('earth', 372)\n",
      "('ease', 373)\n",
      "('easel', 374)\n",
      "('easy', 375)\n",
      "('echoed', 376)\n",
      "('economy', 377)\n",
      "('effect', 378)\n",
      "('effects', 379)\n",
      "('efforts', 380)\n",
      "('egregious', 381)\n",
      "('eighteenth-century', 382)\n",
      "('elbow', 383)\n",
      "('elegant', 384)\n",
      "('else', 385)\n",
      "('embarrassed', 386)\n",
      "('enabled', 387)\n",
      "('end', 388)\n",
      "('endless', 389)\n",
      "('enjoy', 390)\n",
      "('enlightenment', 391)\n",
      "('enough', 392)\n",
      "('ensuing', 393)\n",
      "('equally', 394)\n",
      "('equanimity', 395)\n",
      "('escape', 396)\n",
      "('established', 397)\n",
      "('etching', 398)\n",
      "('even', 399)\n",
      "('event', 400)\n",
      "('ever', 401)\n",
      "('everlasting', 402)\n",
      "('every', 403)\n",
      "('exasperated', 404)\n",
      "('except', 405)\n",
      "('excuse', 406)\n",
      "('excusing', 407)\n",
      "('existed', 408)\n",
      "('expected', 409)\n",
      "('exquisite', 410)\n",
      "('exquisitely', 411)\n",
      "('extenuation', 412)\n",
      "('exterminating', 413)\n",
      "('extracting', 414)\n",
      "('eye', 415)\n",
      "('eyebrows', 416)\n",
      "('eyes', 417)\n",
      "('face', 418)\n",
      "('faces', 419)\n",
      "('fact', 420)\n",
      "('faded', 421)\n",
      "('failed', 422)\n",
      "('failure', 423)\n",
      "('fair', 424)\n",
      "('faith', 425)\n",
      "('false', 426)\n",
      "('familiar', 427)\n",
      "('famille-verte', 428)\n",
      "('fancy', 429)\n",
      "('fashionable', 430)\n",
      "('fate', 431)\n",
      "('feather', 432)\n",
      "('feet', 433)\n",
      "('fell', 434)\n",
      "('fellow', 435)\n",
      "('felt', 436)\n",
      "('few', 437)\n",
      "('fewer', 438)\n",
      "('finality', 439)\n",
      "('find', 440)\n",
      "('fingers', 441)\n",
      "('first', 442)\n",
      "('fit', 443)\n",
      "('fitting', 444)\n",
      "('five', 445)\n",
      "('flash', 446)\n",
      "('flashed', 447)\n",
      "('florid', 448)\n",
      "('flowers', 449)\n",
      "('fluently', 450)\n",
      "('flung', 451)\n",
      "('follow', 452)\n",
      "('followed', 453)\n",
      "('fond', 454)\n",
      "('footstep', 455)\n",
      "('for', 456)\n",
      "('forced', 457)\n",
      "('forcing', 458)\n",
      "('forehead', 459)\n",
      "('foreign', 460)\n",
      "('foreseen', 461)\n",
      "('forgive', 462)\n",
      "('forgotten', 463)\n",
      "('form', 464)\n",
      "('formed', 465)\n",
      "('forming', 466)\n",
      "('forward', 467)\n",
      "('fostered', 468)\n",
      "('found', 469)\n",
      "('foundations', 470)\n",
      "('fragment', 471)\n",
      "('fragments', 472)\n",
      "('frame', 473)\n",
      "('frames', 474)\n",
      "('frequently', 475)\n",
      "('friend', 476)\n",
      "('from', 477)\n",
      "('full', 478)\n",
      "('fullest', 479)\n",
      "('furiously', 480)\n",
      "('furrowed', 481)\n",
      "('garlanded', 482)\n",
      "('garlands', 483)\n",
      "('gave', 484)\n",
      "('genial', 485)\n",
      "('genius', 486)\n",
      "('gesture', 487)\n",
      "('get', 488)\n",
      "('getting', 489)\n",
      "('give', 490)\n",
      "('given', 491)\n",
      "('glad', 492)\n",
      "('glanced', 493)\n",
      "('glimpse', 494)\n",
      "('gloried', 495)\n",
      "('glory', 496)\n",
      "('go', 497)\n",
      "('going', 498)\n",
      "('gone', 499)\n",
      "('good', 500)\n",
      "('good-breeding', 501)\n",
      "('good-humoured', 502)\n",
      "('got', 503)\n",
      "('grace', 504)\n",
      "('gradually', 505)\n",
      "('gray', 506)\n",
      "('grayish', 507)\n",
      "('great', 508)\n",
      "('greatest', 509)\n",
      "('greatness', 510)\n",
      "('grew', 511)\n",
      "('groping', 512)\n",
      "('growing', 513)\n",
      "('had', 514)\n",
      "('hadn', 515)\n",
      "('hair', 516)\n",
      "('half', 517)\n",
      "('half-light', 518)\n",
      "('half-mechanically', 519)\n",
      "('hall', 520)\n",
      "('hand', 521)\n",
      "('hands', 522)\n",
      "('handsome', 523)\n",
      "('hanging', 524)\n",
      "('happen', 525)\n",
      "('happened', 526)\n",
      "('hard', 527)\n",
      "('hardly', 528)\n",
      "('has', 529)\n",
      "('have', 530)\n",
      "('haven', 531)\n",
      "('having', 532)\n",
      "('he', 533)\n",
      "('head', 534)\n",
      "('hear', 535)\n",
      "('heard', 536)\n",
      "('heart', 537)\n",
      "('height', 538)\n",
      "('her', 539)\n",
      "('here', 540)\n",
      "('hermit', 541)\n",
      "('herself', 542)\n",
      "('hesitations', 543)\n",
      "('hide', 544)\n",
      "('high', 545)\n",
      "('him', 546)\n",
      "('himself', 547)\n",
      "('hint', 548)\n",
      "('his', 549)\n",
      "('history', 550)\n",
      "('holding', 551)\n",
      "('home', 552)\n",
      "('honour', 553)\n",
      "('hooded', 554)\n",
      "('hostess', 555)\n",
      "('hot-house', 556)\n",
      "('hour', 557)\n",
      "('hours', 558)\n",
      "('house', 559)\n",
      "('how', 560)\n",
      "('hung', 561)\n",
      "('husband', 562)\n",
      "('idea', 563)\n",
      "('idle', 564)\n",
      "('idling', 565)\n",
      "('if', 566)\n",
      "('immediately', 567)\n",
      "('in', 568)\n",
      "('incense', 569)\n",
      "('indifferent', 570)\n",
      "('inevitable', 571)\n",
      "('inevitably', 572)\n",
      "('inflexible', 573)\n",
      "('insensible', 574)\n",
      "('insignificant', 575)\n",
      "('instinctively', 576)\n",
      "('instructive', 577)\n",
      "('interesting', 578)\n",
      "('into', 579)\n",
      "('ironic', 580)\n",
      "('irony', 581)\n",
      "('irrelevance', 582)\n",
      "('irrevocable', 583)\n",
      "('is', 584)\n",
      "('it', 585)\n",
      "('its', 586)\n",
      "('itself', 587)\n",
      "('jardiniere', 588)\n",
      "('jealousy', 589)\n",
      "('just', 590)\n",
      "('keep', 591)\n",
      "('kept', 592)\n",
      "('kind', 593)\n",
      "('knees', 594)\n",
      "('knew', 595)\n",
      "('know', 596)\n",
      "('known', 597)\n",
      "('laid', 598)\n",
      "('lair', 599)\n",
      "('landing', 600)\n",
      "('language', 601)\n",
      "('last', 602)\n",
      "('late', 603)\n",
      "('later', 604)\n",
      "('latter', 605)\n",
      "('laugh', 606)\n",
      "('laughed', 607)\n",
      "('lay', 608)\n",
      "('leading', 609)\n",
      "('lean', 610)\n",
      "('learned', 611)\n",
      "('least', 612)\n",
      "('leathery', 613)\n",
      "('leave', 614)\n",
      "('led', 615)\n",
      "('left', 616)\n",
      "('leisure', 617)\n",
      "('lends', 618)\n",
      "('lent', 619)\n",
      "('let', 620)\n",
      "('lies', 621)\n",
      "('life', 622)\n",
      "('life-likeness', 623)\n",
      "('lift', 624)\n",
      "('lifted', 625)\n",
      "('light', 626)\n",
      "('lightly', 627)\n",
      "('like', 628)\n",
      "('liked', 629)\n",
      "('line', 630)\n",
      "('lines', 631)\n",
      "('lingered', 632)\n",
      "('lips', 633)\n",
      "('lit', 634)\n",
      "('little', 635)\n",
      "('live', 636)\n",
      "('ll', 637)\n",
      "('loathing', 638)\n",
      "('long', 639)\n",
      "('longed', 640)\n",
      "('longer', 641)\n",
      "('look', 642)\n",
      "('looked', 643)\n",
      "('looking', 644)\n",
      "('lose', 645)\n",
      "('loss', 646)\n",
      "('lounging', 647)\n",
      "('lovely', 648)\n",
      "('lucky', 649)\n",
      "('lump', 650)\n",
      "('luncheon-table', 651)\n",
      "('luxury', 652)\n",
      "('lying', 653)\n",
      "('made', 654)\n",
      "('make', 655)\n",
      "('man', 656)\n",
      "('manage', 657)\n",
      "('managed', 658)\n",
      "('mantel-piece', 659)\n",
      "('marble', 660)\n",
      "('married', 661)\n",
      "('may', 662)\n",
      "('me', 663)\n",
      "('meant', 664)\n",
      "('mediocrity', 665)\n",
      "('medium', 666)\n",
      "('mentioned', 667)\n",
      "('mere', 668)\n",
      "('merely', 669)\n",
      "('met', 670)\n",
      "('might', 671)\n",
      "('mighty', 672)\n",
      "('millionaire', 673)\n",
      "('mine', 674)\n",
      "('minute', 675)\n",
      "('minutes', 676)\n",
      "('mirrors', 677)\n",
      "('modest', 678)\n",
      "('modesty', 679)\n",
      "('moment', 680)\n",
      "('money', 681)\n",
      "('monumental', 682)\n",
      "('mood', 683)\n",
      "('morbidly', 684)\n",
      "('more', 685)\n",
      "('most', 686)\n",
      "('mourn', 687)\n",
      "('mourned', 688)\n",
      "('moustache', 689)\n",
      "('moved', 690)\n",
      "('much', 691)\n",
      "('muddling', 692)\n",
      "('multiplied', 693)\n",
      "('murmur', 694)\n",
      "('muscles', 695)\n",
      "('must', 696)\n",
      "('my', 697)\n",
      "('myself', 698)\n",
      "('mysterious', 699)\n",
      "('naive', 700)\n",
      "('near', 701)\n",
      "('nearly', 702)\n",
      "('negatived', 703)\n",
      "('nervous', 704)\n",
      "('nervousness', 705)\n",
      "('neutral', 706)\n",
      "('never', 707)\n",
      "('next', 708)\n",
      "('no', 709)\n",
      "('none', 710)\n",
      "('not', 711)\n",
      "('note', 712)\n",
      "('nothing', 713)\n",
      "('now', 714)\n",
      "('nymphs', 715)\n",
      "('oak', 716)\n",
      "('obituary', 717)\n",
      "('object', 718)\n",
      "('objects', 719)\n",
      "('occurred', 720)\n",
      "('oddly', 721)\n",
      "('of', 722)\n",
      "('off', 723)\n",
      "('often', 724)\n",
      "('oh', 725)\n",
      "('old', 726)\n",
      "('on', 727)\n",
      "('once', 728)\n",
      "('one', 729)\n",
      "('ones', 730)\n",
      "('only', 731)\n",
      "('onto', 732)\n",
      "('open', 733)\n",
      "('or', 734)\n",
      "('other', 735)\n",
      "('our', 736)\n",
      "('ourselves', 737)\n",
      "('out', 738)\n",
      "('outline', 739)\n",
      "('oval', 740)\n",
      "('over', 741)\n",
      "('own', 742)\n",
      "('packed', 743)\n",
      "('paid', 744)\n",
      "('paint', 745)\n",
      "('painted', 746)\n",
      "('painter', 747)\n",
      "('painting', 748)\n",
      "('pale', 749)\n",
      "('paled', 750)\n",
      "('palm-trees', 751)\n",
      "('panel', 752)\n",
      "('panelling', 753)\n",
      "('pardonable', 754)\n",
      "('pardoned', 755)\n",
      "('part', 756)\n",
      "('passages', 757)\n",
      "('passing', 758)\n",
      "('past', 759)\n",
      "('pastels', 760)\n",
      "('pathos', 761)\n",
      "('patient', 762)\n",
      "('people', 763)\n",
      "('perceptible', 764)\n",
      "('perfect', 765)\n",
      "('persistence', 766)\n",
      "('persuasively', 767)\n",
      "('phrase', 768)\n",
      "('picture', 769)\n",
      "('pictures', 770)\n",
      "('pines', 771)\n",
      "('pink', 772)\n",
      "('place', 773)\n",
      "('placed', 774)\n",
      "('plain', 775)\n",
      "('platitudes', 776)\n",
      "('pleased', 777)\n",
      "('pockets', 778)\n",
      "('point', 779)\n",
      "('poised', 780)\n",
      "('poor', 781)\n",
      "('portrait', 782)\n",
      "('posing', 783)\n",
      "('possessed', 784)\n",
      "('poverty', 785)\n",
      "('predicted', 786)\n",
      "('preliminary', 787)\n",
      "('presenting', 788)\n",
      "('prestidigitation', 789)\n",
      "('pretty', 790)\n",
      "('previous', 791)\n",
      "('price', 792)\n",
      "('pride', 793)\n",
      "('princely', 794)\n",
      "('prism', 795)\n",
      "('problem', 796)\n",
      "('proclaiming', 797)\n",
      "('prodigious', 798)\n",
      "('profusion', 799)\n",
      "('protest', 800)\n",
      "('prove', 801)\n",
      "('public', 802)\n",
      "('purblind', 803)\n",
      "('purely', 804)\n",
      "('pushed', 805)\n",
      "('put', 806)\n",
      "('qualities', 807)\n",
      "('quality', 808)\n",
      "('queerly', 809)\n",
      "('question', 810)\n",
      "('quickly', 811)\n",
      "('quietly', 812)\n",
      "('quite', 813)\n",
      "('quote', 814)\n",
      "('rain', 815)\n",
      "('raised', 816)\n",
      "('random', 817)\n",
      "('rather', 818)\n",
      "('re', 819)\n",
      "('real', 820)\n",
      "('really', 821)\n",
      "('reared', 822)\n",
      "('reason', 823)\n",
      "('reassurance', 824)\n",
      "('recovering', 825)\n",
      "('recreated', 826)\n",
      "('reflected', 827)\n",
      "('reflection', 828)\n",
      "('regrets', 829)\n",
      "('relatively', 830)\n",
      "('remained', 831)\n",
      "('remember', 832)\n",
      "('reminded', 833)\n",
      "('repeating', 834)\n",
      "('represented', 835)\n",
      "('reproduction', 836)\n",
      "('resented', 837)\n",
      "('resolve', 838)\n",
      "('resources', 839)\n",
      "('rest', 840)\n",
      "('rich', 841)\n",
      "('ridiculous', 842)\n",
      "('robbed', 843)\n",
      "('romantic', 844)\n",
      "('room', 845)\n",
      "('rose', 846)\n",
      "('rs', 847)\n",
      "('rule', 848)\n",
      "('run', 849)\n",
      "('s', 850)\n",
      "('said', 851)\n",
      "('same', 852)\n",
      "('satisfaction', 853)\n",
      "('savour', 854)\n",
      "('saw', 855)\n",
      "('say', 856)\n",
      "('saying', 857)\n",
      "('says', 858)\n",
      "('scorn', 859)\n",
      "('scornful', 860)\n",
      "('secret', 861)\n",
      "('see', 862)\n",
      "('seemed', 863)\n",
      "('seen', 864)\n",
      "('self-confident', 865)\n",
      "('send', 866)\n",
      "('sensation', 867)\n",
      "('sensitive', 868)\n",
      "('sent', 869)\n",
      "('serious', 870)\n",
      "('set', 871)\n",
      "('sex', 872)\n",
      "('shade', 873)\n",
      "('shaking', 874)\n",
      "('shall', 875)\n",
      "('she', 876)\n",
      "('shirked', 877)\n",
      "('short', 878)\n",
      "('should', 879)\n",
      "('shoulder', 880)\n",
      "('shoulders', 881)\n",
      "('show', 882)\n",
      "('showed', 883)\n",
      "('showy', 884)\n",
      "('shrug', 885)\n",
      "('shrugged', 886)\n",
      "('sight', 887)\n",
      "('sign', 888)\n",
      "('silent', 889)\n",
      "('silver', 890)\n",
      "('similar', 891)\n",
      "('simpleton', 892)\n",
      "('simplifications', 893)\n",
      "('simply', 894)\n",
      "('since', 895)\n",
      "('single', 896)\n",
      "('sitter', 897)\n",
      "('sitters', 898)\n",
      "('sketch', 899)\n",
      "('skill', 900)\n",
      "('slight', 901)\n",
      "('slightly', 902)\n",
      "('slowly', 903)\n",
      "('small', 904)\n",
      "('smile', 905)\n",
      "('smiling', 906)\n",
      "('sneer', 907)\n",
      "('so', 908)\n",
      "('solace', 909)\n",
      "('some', 910)\n",
      "('somebody', 911)\n",
      "('something', 912)\n",
      "('spacious', 913)\n",
      "('spaniel', 914)\n",
      "('speaking-tubes', 915)\n",
      "('speculations', 916)\n",
      "('spite', 917)\n",
      "('splash', 918)\n",
      "('square', 919)\n",
      "('stairs', 920)\n",
      "('stammer', 921)\n",
      "('stand', 922)\n",
      "('standing', 923)\n",
      "('started', 924)\n",
      "('stay', 925)\n",
      "('still', 926)\n",
      "('stocked', 927)\n",
      "('stood', 928)\n",
      "('stopped', 929)\n",
      "('stopping', 930)\n",
      "('straddling', 931)\n",
      "('straight', 932)\n",
      "('strain', 933)\n",
      "('straining', 934)\n",
      "('strange', 935)\n",
      "('straw', 936)\n",
      "('stream', 937)\n",
      "('stroke', 938)\n",
      "('strokes', 939)\n",
      "('strolled', 940)\n",
      "('strongest', 941)\n",
      "('strongly', 942)\n",
      "('struck', 943)\n",
      "('studio', 944)\n",
      "('stuff', 945)\n",
      "('subject', 946)\n",
      "('substantial', 947)\n",
      "('suburban', 948)\n",
      "('such', 949)\n",
      "('suddenly', 950)\n",
      "('suffered', 951)\n",
      "('sugar', 952)\n",
      "('suggested', 953)\n",
      "('sunburn', 954)\n",
      "('sunburnt', 955)\n",
      "('sunlit', 956)\n",
      "('superb', 957)\n",
      "('sure', 958)\n",
      "('surest', 959)\n",
      "('surface', 960)\n",
      "('surprise', 961)\n",
      "('surprised', 962)\n",
      "('surrounded', 963)\n",
      "('suspected', 964)\n",
      "('sweetly', 965)\n",
      "('sweetness', 966)\n",
      "('swelling', 967)\n",
      "('swept', 968)\n",
      "('swum', 969)\n",
      "('t', 970)\n",
      "('table', 971)\n",
      "('take', 972)\n",
      "('taken', 973)\n",
      "('talking', 974)\n",
      "('tea', 975)\n",
      "('tears', 976)\n",
      "('technicalities', 977)\n",
      "('technique', 978)\n",
      "('tell', 979)\n",
      "('tells', 980)\n",
      "('tempting', 981)\n",
      "('terra-cotta', 982)\n",
      "('terrace', 983)\n",
      "('terraces', 984)\n",
      "('terribly', 985)\n",
      "('than', 986)\n",
      "('that', 987)\n",
      "('the', 988)\n",
      "('their', 989)\n",
      "('them', 990)\n",
      "('then', 991)\n",
      "('there', 992)\n",
      "('therefore', 993)\n",
      "('they', 994)\n",
      "('thin', 995)\n",
      "('thing', 996)\n",
      "('things', 997)\n",
      "('think', 998)\n",
      "('this', 999)\n",
      "('thither', 1000)\n",
      "('those', 1001)\n",
      "('though', 1002)\n",
      "('thought', 1003)\n",
      "('three', 1004)\n",
      "('threshold', 1005)\n",
      "('threw', 1006)\n",
      "('through', 1007)\n",
      "('throwing', 1008)\n",
      "('tie', 1009)\n",
      "('till', 1010)\n",
      "('time', 1011)\n",
      "('timorously', 1012)\n",
      "('tinge', 1013)\n",
      "('tips', 1014)\n",
      "('tired', 1015)\n",
      "('to', 1016)\n",
      "('told', 1017)\n",
      "('tone', 1018)\n",
      "('tones', 1019)\n",
      "('too', 1020)\n",
      "('took', 1021)\n",
      "('tottering', 1022)\n",
      "('touched', 1023)\n",
      "('toward', 1024)\n",
      "('trace', 1025)\n",
      "('trade', 1026)\n",
      "('transmute', 1027)\n",
      "('traps', 1028)\n",
      "('travelled', 1029)\n",
      "('tribute', 1030)\n",
      "('tributes', 1031)\n",
      "('tricks', 1032)\n",
      "('tried', 1033)\n",
      "('trouser-presses', 1034)\n",
      "('true', 1035)\n",
      "('truth', 1036)\n",
      "('turned', 1037)\n",
      "('twenty', 1038)\n",
      "('twenty-four', 1039)\n",
      "('twice', 1040)\n",
      "('twirling', 1041)\n",
      "('unaccountable', 1042)\n",
      "('uncertain', 1043)\n",
      "('under', 1044)\n",
      "('underlay', 1045)\n",
      "('underneath', 1046)\n",
      "('understand', 1047)\n",
      "('unexpected', 1048)\n",
      "('untouched', 1049)\n",
      "('unusual', 1050)\n",
      "('up', 1051)\n",
      "('up-stream', 1052)\n",
      "('upon', 1053)\n",
      "('upset', 1054)\n",
      "('upstairs', 1055)\n",
      "('us', 1056)\n",
      "('used', 1057)\n",
      "('usual', 1058)\n",
      "('value', 1059)\n",
      "('varnishing', 1060)\n",
      "('vases', 1061)\n",
      "('ve', 1062)\n",
      "('veins', 1063)\n",
      "('velveteen', 1064)\n",
      "('very', 1065)\n",
      "('villa', 1066)\n",
      "('vindicated', 1067)\n",
      "('virtuosity', 1068)\n",
      "('vista', 1069)\n",
      "('vocation', 1070)\n",
      "('voice', 1071)\n",
      "('wall', 1072)\n",
      "('wander', 1073)\n",
      "('want', 1074)\n",
      "('wanted', 1075)\n",
      "('wants', 1076)\n",
      "('was', 1077)\n",
      "('wasn', 1078)\n",
      "('watched', 1079)\n",
      "('watching', 1080)\n",
      "('water-colour', 1081)\n",
      "('waves', 1082)\n",
      "('way', 1083)\n",
      "('weekly', 1084)\n",
      "('weeks', 1085)\n",
      "('welcome', 1086)\n",
      "('went', 1087)\n",
      "('were', 1088)\n",
      "('what', 1089)\n",
      "('when', 1090)\n",
      "('whenever', 1091)\n",
      "('where', 1092)\n",
      "('which', 1093)\n",
      "('while', 1094)\n",
      "('white', 1095)\n",
      "('white-panelled', 1096)\n",
      "('who', 1097)\n",
      "('whole', 1098)\n",
      "('whom', 1099)\n",
      "('why', 1100)\n",
      "('wide', 1101)\n",
      "('widow', 1102)\n",
      "('wife', 1103)\n",
      "('wild', 1104)\n",
      "('wincing', 1105)\n",
      "('window-curtains', 1106)\n",
      "('wish', 1107)\n",
      "('with', 1108)\n",
      "('without', 1109)\n",
      "('wits', 1110)\n",
      "('woman', 1111)\n",
      "('women', 1112)\n",
      "('won', 1113)\n",
      "('wonder', 1114)\n",
      "('wondered', 1115)\n",
      "('word', 1116)\n",
      "('work', 1117)\n",
      "('working', 1118)\n",
      "('worth', 1119)\n",
      "('would', 1120)\n",
      "('wouldn', 1121)\n",
      "('year', 1122)\n",
      "('years', 1123)\n",
      "('yellow', 1124)\n",
      "('yet', 1125)\n",
      "('you', 1126)\n",
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|endoftext|>', 1130)\n",
      "('<|unk|>', 1131)\n"
     ]
    }
   ],
   "source": [
    "print(vocab)\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e537d324-36e8-4d80-97d8-a651c9cc0ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131]\n"
     ]
    }
   ],
   "source": [
    "ids = [vocab[s] for s in vocab]\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09a67895-cea7-40d1-ad05-f36c29dbd459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! \" ' ( ) , -- . : ; ? A Ah Among And Are Arrt As At Be Begin Burlington But By Carlo Chicago Claude Come Croft Destroyed Devonshire Don Dubarry Emperors Florence For Gallery Gideon Gisburn Gisburns Grafton Greek Grindle Grindles HAD Had Hang Has He Her Hermia His How I If In It Jack Jove Just Lord Made Miss Money Monte Moon-dancers Mr Mrs My Never No Now Nutley Of Oh On Once Only Or Perhaps Poor Professional Renaissance Rickham Riviera Rome Russian Sevres She Stroud Strouds Suddenly That The Then There They This Those Though Thwing Thwings To Usually Venetian Victor Was We Well What When Why Yes You _ a abdication able about above abruptly absolute absorbed absurdity academic accuse accustomed across activity add added admirers adopted adulation advance aesthetic affect afraid after afterward again ago ah air alive all almost alone along always am amazement amid among amplest amusing an and another answer answered any anything anywhere apparent apparently appearance appeared appointed are arm arm-chair arm-chairs arms art articles artist as aside asked at atmosphere atom attack attention attitude audacities away awful axioms azaleas back background balance balancing balustraded basking bath-rooms be beaming bean-stalk bear beard beauty became because becoming bed been before began begun behind being believed beneath bespoke better between big bits bitterness blocked born borne boudoir bravura break breaking breathing bric-a-brac briefly brings bronzes brought brown brush bull business but buying by called came can canvas canvases cards care career caught central chair chap characteristic charming cheap check cheeks chest chimney-piece chucked cigar cigarette cigars circulation circumstance circus-clown claimed clasping clear cleverer close clue coat collapsed colour come comfortable coming companion compared complex confident congesting conjugal constraint consummate contended continued corner corrected could couldn count countenance couple course covered craft cried crossed crowned crumbled cry cured curiosity curious current curtains d dabble damask dark dashed day days dead deadening dear deep deerhound degree delicate demand denied deploring deprecating deprecatingly desire destroyed destruction desultory detail diagnosis did didn died dim dimmest dingy dining-room disarming discovery discrimination discussion disdain disdained disease disguised display dissatisfied distinguished distract divert do doesn doing domestic don done donkey down dozen dragged drawing-room drawing-rooms drawn dress-closets drew dropped each earth ease easel easy echoed economy effect effects efforts egregious eighteenth-century elbow elegant else embarrassed enabled end endless enjoy enlightenment enough ensuing equally equanimity escape established etching even event ever everlasting every exasperated except excuse excusing existed expected exquisite exquisitely extenuation exterminating extracting eye eyebrows eyes face faces fact faded failed failure fair faith false familiar famille-verte fancy fashionable fate feather feet fell fellow felt few fewer finality find fingers first fit fitting five flash flashed florid flowers fluently flung follow followed fond footstep for forced forcing forehead foreign foreseen forgive forgotten form formed forming forward fostered found foundations fragment fragments frame frames frequently friend from full fullest furiously furrowed garlanded garlands gave genial genius gesture get getting give given glad glanced glimpse gloried glory go going gone good good-breeding good-humoured got grace gradually gray grayish great greatest greatness grew groping growing had hadn hair half half-light half-mechanically hall hand hands handsome hanging happen happened hard hardly has have haven having he head hear heard heart height her here hermit herself hesitations hide high him himself hint his history holding home honour hooded hostess hot-house hour hours house how hung husband idea idle idling if immediately in incense indifferent inevitable inevitably inflexible insensible insignificant instinctively instructive interesting into ironic irony irrelevance irrevocable is it its itself jardiniere jealousy just keep kept kind knees knew know known laid lair landing language last late later latter laugh laughed lay leading lean learned least leathery leave led left leisure lends lent let lies life life-likeness lift lifted light lightly like liked line lines lingered lips lit little live ll loathing long longed longer look looked looking lose loss lounging lovely lucky lump luncheon-table luxury lying made make man manage managed mantel-piece marble married may me meant mediocrity medium mentioned mere merely met might mighty millionaire mine minute minutes mirrors modest modesty moment money monumental mood morbidly more most mourn mourned moustache moved much muddling multiplied murmur muscles must my myself mysterious naive near nearly negatived nervous nervousness neutral never next no none not note nothing now nymphs oak obituary object objects occurred oddly of off often oh old on once one ones only onto open or other our ourselves out outline oval over own packed paid paint painted painter painting pale paled palm-trees panel panelling pardonable pardoned part passages passing past pastels pathos patient people perceptible perfect persistence persuasively phrase picture pictures pines pink place placed plain platitudes pleased pockets point poised poor portrait posing possessed poverty predicted preliminary presenting prestidigitation pretty previous price pride princely prism problem proclaiming prodigious profusion protest prove public purblind purely pushed put qualities quality queerly question quickly quietly quite quote rain raised random rather re real really reared reason reassurance recovering recreated reflected reflection regrets relatively remained remember reminded repeating represented reproduction resented resolve resources rest rich ridiculous robbed romantic room rose rs rule run s said same satisfaction savour saw say saying says scorn scornful secret see seemed seen self-confident send sensation sensitive sent serious set sex shade shaking shall she shirked short should shoulder shoulders show showed showy shrug shrugged sight sign silent silver similar simpleton simplifications simply since single sitter sitters sketch skill slight slightly slowly small smile smiling sneer so solace some somebody something spacious spaniel speaking-tubes speculations spite splash square stairs stammer stand standing started stay still stocked stood stopped stopping straddling straight strain straining strange straw stream stroke strokes strolled strongest strongly struck studio stuff subject substantial suburban such suddenly suffered sugar suggested sunburn sunburnt sunlit superb sure surest surface surprise surprised surrounded suspected sweetly sweetness swelling swept swum t table take taken talking tea tears technicalities technique tell tells tempting terra-cotta terrace terraces terribly than that the their them then there therefore they thin thing things think this thither those though thought three threshold threw through throwing tie till time timorously tinge tips tired to told tone tones too took tottering touched toward trace trade transmute traps travelled tribute tributes tricks tried trouser-presses true truth turned twenty twenty-four twice twirling unaccountable uncertain under underlay underneath understand unexpected untouched unusual up up-stream upon upset upstairs us used usual value varnishing vases ve veins velveteen very villa vindicated virtuosity vista vocation voice wall wander want wanted wants was wasn watched watching water-colour waves way weekly weeks welcome went were what when whenever where which while white white-panelled who whole whom why wide widow wife wild wincing window-curtains wish with without wits woman women won wonder wondered word work working worth would wouldn year years yellow yet you younger your yourself <|endoftext|> <|unk|>\n"
     ]
    }
   ],
   "source": [
    "id_to_token = {integer: token for token, integer in vocab.items()}\n",
    "integer_to_string = [id_to_token[i] for i in ids]\n",
    "text = \" \".join(integer_to_string)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "582bbcfc-96d0-4a36-a821-4ec2fa8f77bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)                  \n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int \n",
    "            else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0345c68-922f-4e6d-ae20-e4f9ce9918e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!': 0, '\"': 1, \"'\": 2, '(': 3, ')': 4, ',': 5, '--': 6, '.': 7, ':': 8, ';': 9, '?': 10, 'A': 11, 'Ah': 12, 'Among': 13, 'And': 14, 'Are': 15, 'Arrt': 16, 'As': 17, 'At': 18, 'Be': 19, 'Begin': 20, 'Burlington': 21, 'But': 22, 'By': 23, 'Carlo': 24, 'Chicago': 25, 'Claude': 26, 'Come': 27, 'Croft': 28, 'Destroyed': 29, 'Devonshire': 30, 'Don': 31, 'Dubarry': 32, 'Emperors': 33, 'Florence': 34, 'For': 35, 'Gallery': 36, 'Gideon': 37, 'Gisburn': 38, 'Gisburns': 39, 'Grafton': 40, 'Greek': 41, 'Grindle': 42, 'Grindles': 43, 'HAD': 44, 'Had': 45, 'Hang': 46, 'Has': 47, 'He': 48, 'Her': 49, 'Hermia': 50, 'His': 51, 'How': 52, 'I': 53, 'If': 54, 'In': 55, 'It': 56, 'Jack': 57, 'Jove': 58, 'Just': 59, 'Lord': 60, 'Made': 61, 'Miss': 62, 'Money': 63, 'Monte': 64, 'Moon-dancers': 65, 'Mr': 66, 'Mrs': 67, 'My': 68, 'Never': 69, 'No': 70, 'Now': 71, 'Nutley': 72, 'Of': 73, 'Oh': 74, 'On': 75, 'Once': 76, 'Only': 77, 'Or': 78, 'Perhaps': 79, 'Poor': 80, 'Professional': 81, 'Renaissance': 82, 'Rickham': 83, 'Riviera': 84, 'Rome': 85, 'Russian': 86, 'Sevres': 87, 'She': 88, 'Stroud': 89, 'Strouds': 90, 'Suddenly': 91, 'That': 92, 'The': 93, 'Then': 94, 'There': 95, 'They': 96, 'This': 97, 'Those': 98, 'Though': 99, 'Thwing': 100, 'Thwings': 101, 'To': 102, 'Usually': 103, 'Venetian': 104, 'Victor': 105, 'Was': 106, 'We': 107, 'Well': 108, 'What': 109, 'When': 110, 'Why': 111, 'Yes': 112, 'You': 113, '_': 114, 'a': 115, 'abdication': 116, 'able': 117, 'about': 118, 'above': 119, 'abruptly': 120, 'absolute': 121, 'absorbed': 122, 'absurdity': 123, 'academic': 124, 'accuse': 125, 'accustomed': 126, 'across': 127, 'activity': 128, 'add': 129, 'added': 130, 'admirers': 131, 'adopted': 132, 'adulation': 133, 'advance': 134, 'aesthetic': 135, 'affect': 136, 'afraid': 137, 'after': 138, 'afterward': 139, 'again': 140, 'ago': 141, 'ah': 142, 'air': 143, 'alive': 144, 'all': 145, 'almost': 146, 'alone': 147, 'along': 148, 'always': 149, 'am': 150, 'amazement': 151, 'amid': 152, 'among': 153, 'amplest': 154, 'amusing': 155, 'an': 156, 'and': 157, 'another': 158, 'answer': 159, 'answered': 160, 'any': 161, 'anything': 162, 'anywhere': 163, 'apparent': 164, 'apparently': 165, 'appearance': 166, 'appeared': 167, 'appointed': 168, 'are': 169, 'arm': 170, 'arm-chair': 171, 'arm-chairs': 172, 'arms': 173, 'art': 174, 'articles': 175, 'artist': 176, 'as': 177, 'aside': 178, 'asked': 179, 'at': 180, 'atmosphere': 181, 'atom': 182, 'attack': 183, 'attention': 184, 'attitude': 185, 'audacities': 186, 'away': 187, 'awful': 188, 'axioms': 189, 'azaleas': 190, 'back': 191, 'background': 192, 'balance': 193, 'balancing': 194, 'balustraded': 195, 'basking': 196, 'bath-rooms': 197, 'be': 198, 'beaming': 199, 'bean-stalk': 200, 'bear': 201, 'beard': 202, 'beauty': 203, 'became': 204, 'because': 205, 'becoming': 206, 'bed': 207, 'been': 208, 'before': 209, 'began': 210, 'begun': 211, 'behind': 212, 'being': 213, 'believed': 214, 'beneath': 215, 'bespoke': 216, 'better': 217, 'between': 218, 'big': 219, 'bits': 220, 'bitterness': 221, 'blocked': 222, 'born': 223, 'borne': 224, 'boudoir': 225, 'bravura': 226, 'break': 227, 'breaking': 228, 'breathing': 229, 'bric-a-brac': 230, 'briefly': 231, 'brings': 232, 'bronzes': 233, 'brought': 234, 'brown': 235, 'brush': 236, 'bull': 237, 'business': 238, 'but': 239, 'buying': 240, 'by': 241, 'called': 242, 'came': 243, 'can': 244, 'canvas': 245, 'canvases': 246, 'cards': 247, 'care': 248, 'career': 249, 'caught': 250, 'central': 251, 'chair': 252, 'chap': 253, 'characteristic': 254, 'charming': 255, 'cheap': 256, 'check': 257, 'cheeks': 258, 'chest': 259, 'chimney-piece': 260, 'chucked': 261, 'cigar': 262, 'cigarette': 263, 'cigars': 264, 'circulation': 265, 'circumstance': 266, 'circus-clown': 267, 'claimed': 268, 'clasping': 269, 'clear': 270, 'cleverer': 271, 'close': 272, 'clue': 273, 'coat': 274, 'collapsed': 275, 'colour': 276, 'come': 277, 'comfortable': 278, 'coming': 279, 'companion': 280, 'compared': 281, 'complex': 282, 'confident': 283, 'congesting': 284, 'conjugal': 285, 'constraint': 286, 'consummate': 287, 'contended': 288, 'continued': 289, 'corner': 290, 'corrected': 291, 'could': 292, 'couldn': 293, 'count': 294, 'countenance': 295, 'couple': 296, 'course': 297, 'covered': 298, 'craft': 299, 'cried': 300, 'crossed': 301, 'crowned': 302, 'crumbled': 303, 'cry': 304, 'cured': 305, 'curiosity': 306, 'curious': 307, 'current': 308, 'curtains': 309, 'd': 310, 'dabble': 311, 'damask': 312, 'dark': 313, 'dashed': 314, 'day': 315, 'days': 316, 'dead': 317, 'deadening': 318, 'dear': 319, 'deep': 320, 'deerhound': 321, 'degree': 322, 'delicate': 323, 'demand': 324, 'denied': 325, 'deploring': 326, 'deprecating': 327, 'deprecatingly': 328, 'desire': 329, 'destroyed': 330, 'destruction': 331, 'desultory': 332, 'detail': 333, 'diagnosis': 334, 'did': 335, 'didn': 336, 'died': 337, 'dim': 338, 'dimmest': 339, 'dingy': 340, 'dining-room': 341, 'disarming': 342, 'discovery': 343, 'discrimination': 344, 'discussion': 345, 'disdain': 346, 'disdained': 347, 'disease': 348, 'disguised': 349, 'display': 350, 'dissatisfied': 351, 'distinguished': 352, 'distract': 353, 'divert': 354, 'do': 355, 'doesn': 356, 'doing': 357, 'domestic': 358, 'don': 359, 'done': 360, 'donkey': 361, 'down': 362, 'dozen': 363, 'dragged': 364, 'drawing-room': 365, 'drawing-rooms': 366, 'drawn': 367, 'dress-closets': 368, 'drew': 369, 'dropped': 370, 'each': 371, 'earth': 372, 'ease': 373, 'easel': 374, 'easy': 375, 'echoed': 376, 'economy': 377, 'effect': 378, 'effects': 379, 'efforts': 380, 'egregious': 381, 'eighteenth-century': 382, 'elbow': 383, 'elegant': 384, 'else': 385, 'embarrassed': 386, 'enabled': 387, 'end': 388, 'endless': 389, 'enjoy': 390, 'enlightenment': 391, 'enough': 392, 'ensuing': 393, 'equally': 394, 'equanimity': 395, 'escape': 396, 'established': 397, 'etching': 398, 'even': 399, 'event': 400, 'ever': 401, 'everlasting': 402, 'every': 403, 'exasperated': 404, 'except': 405, 'excuse': 406, 'excusing': 407, 'existed': 408, 'expected': 409, 'exquisite': 410, 'exquisitely': 411, 'extenuation': 412, 'exterminating': 413, 'extracting': 414, 'eye': 415, 'eyebrows': 416, 'eyes': 417, 'face': 418, 'faces': 419, 'fact': 420, 'faded': 421, 'failed': 422, 'failure': 423, 'fair': 424, 'faith': 425, 'false': 426, 'familiar': 427, 'famille-verte': 428, 'fancy': 429, 'fashionable': 430, 'fate': 431, 'feather': 432, 'feet': 433, 'fell': 434, 'fellow': 435, 'felt': 436, 'few': 437, 'fewer': 438, 'finality': 439, 'find': 440, 'fingers': 441, 'first': 442, 'fit': 443, 'fitting': 444, 'five': 445, 'flash': 446, 'flashed': 447, 'florid': 448, 'flowers': 449, 'fluently': 450, 'flung': 451, 'follow': 452, 'followed': 453, 'fond': 454, 'footstep': 455, 'for': 456, 'forced': 457, 'forcing': 458, 'forehead': 459, 'foreign': 460, 'foreseen': 461, 'forgive': 462, 'forgotten': 463, 'form': 464, 'formed': 465, 'forming': 466, 'forward': 467, 'fostered': 468, 'found': 469, 'foundations': 470, 'fragment': 471, 'fragments': 472, 'frame': 473, 'frames': 474, 'frequently': 475, 'friend': 476, 'from': 477, 'full': 478, 'fullest': 479, 'furiously': 480, 'furrowed': 481, 'garlanded': 482, 'garlands': 483, 'gave': 484, 'genial': 485, 'genius': 486, 'gesture': 487, 'get': 488, 'getting': 489, 'give': 490, 'given': 491, 'glad': 492, 'glanced': 493, 'glimpse': 494, 'gloried': 495, 'glory': 496, 'go': 497, 'going': 498, 'gone': 499, 'good': 500, 'good-breeding': 501, 'good-humoured': 502, 'got': 503, 'grace': 504, 'gradually': 505, 'gray': 506, 'grayish': 507, 'great': 508, 'greatest': 509, 'greatness': 510, 'grew': 511, 'groping': 512, 'growing': 513, 'had': 514, 'hadn': 515, 'hair': 516, 'half': 517, 'half-light': 518, 'half-mechanically': 519, 'hall': 520, 'hand': 521, 'hands': 522, 'handsome': 523, 'hanging': 524, 'happen': 525, 'happened': 526, 'hard': 527, 'hardly': 528, 'has': 529, 'have': 530, 'haven': 531, 'having': 532, 'he': 533, 'head': 534, 'hear': 535, 'heard': 536, 'heart': 537, 'height': 538, 'her': 539, 'here': 540, 'hermit': 541, 'herself': 542, 'hesitations': 543, 'hide': 544, 'high': 545, 'him': 546, 'himself': 547, 'hint': 548, 'his': 549, 'history': 550, 'holding': 551, 'home': 552, 'honour': 553, 'hooded': 554, 'hostess': 555, 'hot-house': 556, 'hour': 557, 'hours': 558, 'house': 559, 'how': 560, 'hung': 561, 'husband': 562, 'idea': 563, 'idle': 564, 'idling': 565, 'if': 566, 'immediately': 567, 'in': 568, 'incense': 569, 'indifferent': 570, 'inevitable': 571, 'inevitably': 572, 'inflexible': 573, 'insensible': 574, 'insignificant': 575, 'instinctively': 576, 'instructive': 577, 'interesting': 578, 'into': 579, 'ironic': 580, 'irony': 581, 'irrelevance': 582, 'irrevocable': 583, 'is': 584, 'it': 585, 'its': 586, 'itself': 587, 'jardiniere': 588, 'jealousy': 589, 'just': 590, 'keep': 591, 'kept': 592, 'kind': 593, 'knees': 594, 'knew': 595, 'know': 596, 'known': 597, 'laid': 598, 'lair': 599, 'landing': 600, 'language': 601, 'last': 602, 'late': 603, 'later': 604, 'latter': 605, 'laugh': 606, 'laughed': 607, 'lay': 608, 'leading': 609, 'lean': 610, 'learned': 611, 'least': 612, 'leathery': 613, 'leave': 614, 'led': 615, 'left': 616, 'leisure': 617, 'lends': 618, 'lent': 619, 'let': 620, 'lies': 621, 'life': 622, 'life-likeness': 623, 'lift': 624, 'lifted': 625, 'light': 626, 'lightly': 627, 'like': 628, 'liked': 629, 'line': 630, 'lines': 631, 'lingered': 632, 'lips': 633, 'lit': 634, 'little': 635, 'live': 636, 'll': 637, 'loathing': 638, 'long': 639, 'longed': 640, 'longer': 641, 'look': 642, 'looked': 643, 'looking': 644, 'lose': 645, 'loss': 646, 'lounging': 647, 'lovely': 648, 'lucky': 649, 'lump': 650, 'luncheon-table': 651, 'luxury': 652, 'lying': 653, 'made': 654, 'make': 655, 'man': 656, 'manage': 657, 'managed': 658, 'mantel-piece': 659, 'marble': 660, 'married': 661, 'may': 662, 'me': 663, 'meant': 664, 'mediocrity': 665, 'medium': 666, 'mentioned': 667, 'mere': 668, 'merely': 669, 'met': 670, 'might': 671, 'mighty': 672, 'millionaire': 673, 'mine': 674, 'minute': 675, 'minutes': 676, 'mirrors': 677, 'modest': 678, 'modesty': 679, 'moment': 680, 'money': 681, 'monumental': 682, 'mood': 683, 'morbidly': 684, 'more': 685, 'most': 686, 'mourn': 687, 'mourned': 688, 'moustache': 689, 'moved': 690, 'much': 691, 'muddling': 692, 'multiplied': 693, 'murmur': 694, 'muscles': 695, 'must': 696, 'my': 697, 'myself': 698, 'mysterious': 699, 'naive': 700, 'near': 701, 'nearly': 702, 'negatived': 703, 'nervous': 704, 'nervousness': 705, 'neutral': 706, 'never': 707, 'next': 708, 'no': 709, 'none': 710, 'not': 711, 'note': 712, 'nothing': 713, 'now': 714, 'nymphs': 715, 'oak': 716, 'obituary': 717, 'object': 718, 'objects': 719, 'occurred': 720, 'oddly': 721, 'of': 722, 'off': 723, 'often': 724, 'oh': 725, 'old': 726, 'on': 727, 'once': 728, 'one': 729, 'ones': 730, 'only': 731, 'onto': 732, 'open': 733, 'or': 734, 'other': 735, 'our': 736, 'ourselves': 737, 'out': 738, 'outline': 739, 'oval': 740, 'over': 741, 'own': 742, 'packed': 743, 'paid': 744, 'paint': 745, 'painted': 746, 'painter': 747, 'painting': 748, 'pale': 749, 'paled': 750, 'palm-trees': 751, 'panel': 752, 'panelling': 753, 'pardonable': 754, 'pardoned': 755, 'part': 756, 'passages': 757, 'passing': 758, 'past': 759, 'pastels': 760, 'pathos': 761, 'patient': 762, 'people': 763, 'perceptible': 764, 'perfect': 765, 'persistence': 766, 'persuasively': 767, 'phrase': 768, 'picture': 769, 'pictures': 770, 'pines': 771, 'pink': 772, 'place': 773, 'placed': 774, 'plain': 775, 'platitudes': 776, 'pleased': 777, 'pockets': 778, 'point': 779, 'poised': 780, 'poor': 781, 'portrait': 782, 'posing': 783, 'possessed': 784, 'poverty': 785, 'predicted': 786, 'preliminary': 787, 'presenting': 788, 'prestidigitation': 789, 'pretty': 790, 'previous': 791, 'price': 792, 'pride': 793, 'princely': 794, 'prism': 795, 'problem': 796, 'proclaiming': 797, 'prodigious': 798, 'profusion': 799, 'protest': 800, 'prove': 801, 'public': 802, 'purblind': 803, 'purely': 804, 'pushed': 805, 'put': 806, 'qualities': 807, 'quality': 808, 'queerly': 809, 'question': 810, 'quickly': 811, 'quietly': 812, 'quite': 813, 'quote': 814, 'rain': 815, 'raised': 816, 'random': 817, 'rather': 818, 're': 819, 'real': 820, 'really': 821, 'reared': 822, 'reason': 823, 'reassurance': 824, 'recovering': 825, 'recreated': 826, 'reflected': 827, 'reflection': 828, 'regrets': 829, 'relatively': 830, 'remained': 831, 'remember': 832, 'reminded': 833, 'repeating': 834, 'represented': 835, 'reproduction': 836, 'resented': 837, 'resolve': 838, 'resources': 839, 'rest': 840, 'rich': 841, 'ridiculous': 842, 'robbed': 843, 'romantic': 844, 'room': 845, 'rose': 846, 'rs': 847, 'rule': 848, 'run': 849, 's': 850, 'said': 851, 'same': 852, 'satisfaction': 853, 'savour': 854, 'saw': 855, 'say': 856, 'saying': 857, 'says': 858, 'scorn': 859, 'scornful': 860, 'secret': 861, 'see': 862, 'seemed': 863, 'seen': 864, 'self-confident': 865, 'send': 866, 'sensation': 867, 'sensitive': 868, 'sent': 869, 'serious': 870, 'set': 871, 'sex': 872, 'shade': 873, 'shaking': 874, 'shall': 875, 'she': 876, 'shirked': 877, 'short': 878, 'should': 879, 'shoulder': 880, 'shoulders': 881, 'show': 882, 'showed': 883, 'showy': 884, 'shrug': 885, 'shrugged': 886, 'sight': 887, 'sign': 888, 'silent': 889, 'silver': 890, 'similar': 891, 'simpleton': 892, 'simplifications': 893, 'simply': 894, 'since': 895, 'single': 896, 'sitter': 897, 'sitters': 898, 'sketch': 899, 'skill': 900, 'slight': 901, 'slightly': 902, 'slowly': 903, 'small': 904, 'smile': 905, 'smiling': 906, 'sneer': 907, 'so': 908, 'solace': 909, 'some': 910, 'somebody': 911, 'something': 912, 'spacious': 913, 'spaniel': 914, 'speaking-tubes': 915, 'speculations': 916, 'spite': 917, 'splash': 918, 'square': 919, 'stairs': 920, 'stammer': 921, 'stand': 922, 'standing': 923, 'started': 924, 'stay': 925, 'still': 926, 'stocked': 927, 'stood': 928, 'stopped': 929, 'stopping': 930, 'straddling': 931, 'straight': 932, 'strain': 933, 'straining': 934, 'strange': 935, 'straw': 936, 'stream': 937, 'stroke': 938, 'strokes': 939, 'strolled': 940, 'strongest': 941, 'strongly': 942, 'struck': 943, 'studio': 944, 'stuff': 945, 'subject': 946, 'substantial': 947, 'suburban': 948, 'such': 949, 'suddenly': 950, 'suffered': 951, 'sugar': 952, 'suggested': 953, 'sunburn': 954, 'sunburnt': 955, 'sunlit': 956, 'superb': 957, 'sure': 958, 'surest': 959, 'surface': 960, 'surprise': 961, 'surprised': 962, 'surrounded': 963, 'suspected': 964, 'sweetly': 965, 'sweetness': 966, 'swelling': 967, 'swept': 968, 'swum': 969, 't': 970, 'table': 971, 'take': 972, 'taken': 973, 'talking': 974, 'tea': 975, 'tears': 976, 'technicalities': 977, 'technique': 978, 'tell': 979, 'tells': 980, 'tempting': 981, 'terra-cotta': 982, 'terrace': 983, 'terraces': 984, 'terribly': 985, 'than': 986, 'that': 987, 'the': 988, 'their': 989, 'them': 990, 'then': 991, 'there': 992, 'therefore': 993, 'they': 994, 'thin': 995, 'thing': 996, 'things': 997, 'think': 998, 'this': 999, 'thither': 1000, 'those': 1001, 'though': 1002, 'thought': 1003, 'three': 1004, 'threshold': 1005, 'threw': 1006, 'through': 1007, 'throwing': 1008, 'tie': 1009, 'till': 1010, 'time': 1011, 'timorously': 1012, 'tinge': 1013, 'tips': 1014, 'tired': 1015, 'to': 1016, 'told': 1017, 'tone': 1018, 'tones': 1019, 'too': 1020, 'took': 1021, 'tottering': 1022, 'touched': 1023, 'toward': 1024, 'trace': 1025, 'trade': 1026, 'transmute': 1027, 'traps': 1028, 'travelled': 1029, 'tribute': 1030, 'tributes': 1031, 'tricks': 1032, 'tried': 1033, 'trouser-presses': 1034, 'true': 1035, 'truth': 1036, 'turned': 1037, 'twenty': 1038, 'twenty-four': 1039, 'twice': 1040, 'twirling': 1041, 'unaccountable': 1042, 'uncertain': 1043, 'under': 1044, 'underlay': 1045, 'underneath': 1046, 'understand': 1047, 'unexpected': 1048, 'untouched': 1049, 'unusual': 1050, 'up': 1051, 'up-stream': 1052, 'upon': 1053, 'upset': 1054, 'upstairs': 1055, 'us': 1056, 'used': 1057, 'usual': 1058, 'value': 1059, 'varnishing': 1060, 'vases': 1061, 've': 1062, 'veins': 1063, 'velveteen': 1064, 'very': 1065, 'villa': 1066, 'vindicated': 1067, 'virtuosity': 1068, 'vista': 1069, 'vocation': 1070, 'voice': 1071, 'wall': 1072, 'wander': 1073, 'want': 1074, 'wanted': 1075, 'wants': 1076, 'was': 1077, 'wasn': 1078, 'watched': 1079, 'watching': 1080, 'water-colour': 1081, 'waves': 1082, 'way': 1083, 'weekly': 1084, 'weeks': 1085, 'welcome': 1086, 'went': 1087, 'were': 1088, 'what': 1089, 'when': 1090, 'whenever': 1091, 'where': 1092, 'which': 1093, 'while': 1094, 'white': 1095, 'white-panelled': 1096, 'who': 1097, 'whole': 1098, 'whom': 1099, 'why': 1100, 'wide': 1101, 'widow': 1102, 'wife': 1103, 'wild': 1104, 'wincing': 1105, 'window-curtains': 1106, 'wish': 1107, 'with': 1108, 'without': 1109, 'wits': 1110, 'woman': 1111, 'women': 1112, 'won': 1113, 'wonder': 1114, 'wondered': 1115, 'word': 1116, 'work': 1117, 'working': 1118, 'worth': 1119, 'would': 1120, 'wouldn': 1121, 'year': 1122, 'years': 1123, 'yellow': 1124, 'yet': 1125, 'you': 1126, 'younger': 1127, 'your': 1128, 'yourself': 1129, '<|endoftext|>': 1130, '<|unk|>': 1131}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)\n",
    "tokenizer = SimpleTokenizerV1(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aae24c7b-7b39-49ed-bde8-b7cd628643bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129]\n"
     ]
    }
   ],
   "source": [
    "ids = tokenizer.encode(\"wish with without wits woman women won wonder wondered word work working worth would wouldn year years yellow yet you younger your yourself\")\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca9d286c-d9d6-49e9-a9d7-a41479807176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wish with without wits woman women won wonder wondered word work working worth would wouldn year years yellow yet you younger your yourself\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a3a1b18-887a-4e70-b8d4-b850e0f27ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1131, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129]\n"
     ]
    }
   ],
   "source": [
    "ids = tokenizer.encode(\"Hello wish with without wits woman women won wonder wondered word work working worth would wouldn year years yellow yet you younger your yourself\")\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e144da47-4b71-413d-a55b-ce396b83275a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53, 44, 149, 1003, 57, 38, 818, 115, 256, 486, 6, 1002, 115, 500, 435, 392, 6, 908, 585, 1077, 709, 508, 961, 1016, 663, 1016, 535, 987, 5, 568, 988, 538, 722, 549, 496, 5, 533, 514, 370, 549, 748, 5, 661, 115, 841, 1102, 5, 157, 397, 547, 568, 115, 1066, 727, 988, 84, 7, 3, 99, 53, 818, 1003, 585, 1120, 530, 208, 85, 734, 34, 7, 4, 1, 93, 538, 722, 549, 496, 1, 6, 987, 1077, 1089, 988, 1112, 242, 585, 7, 53, 244, 535, 67, 7, 37, 100, 6, 549, 602, 25, 897, 6, 326, 549, 1042, 116, 7, 1, 73, 297, 585, 2, 850, 498, 1016, 866, 988, 1059, 722, 697, 769, 2, 1083, 1051, 9, 239, 53, 359, 2, 970, 998, 722, 987, 5, 66, 7, 83, 6, 988, 646, 1016, 16, 584, 145, 53, 998, 722, 7, 1, 93, 1116, 5, 727, 67, 7, 100, 2, 850, 633, 5, 693, 586, 114, 847, 114, 177, 1002, 994, 1088, 827, 568, 156, 389, 1069, 722, 677, 7, 14, 585, 1077, 711, 731, 988, 67, 7, 101, 1097, 688, 7, 45, 711, 988, 410, 50, 28, 5, 180, 988, 602, 40, 36, 882, 5, 929, 663, 209, 38, 2, 850, 1, 65, 1, 1016, 856, 5, 1108, 976, 568, 539, 417, 8, 1, 107, 875, 711, 642, 1053, 586, 628, 140, 1, 10, 108, 0, 6, 399, 1007, 988, 795, 722, 50, 2, 850, 976, 53, 436, 117, 1016, 418, 988, 420, 1108, 395, 7, 80, 57, 38, 0, 93, 1112, 514, 654, 546, 6, 585, 1077, 444, 987, 994, 879, 687, 546, 7, 13, 549, 742, 872, 438, 829, 1088, 536, 5, 157, 568, 549, 742, 1026, 528, 115, 694, 7, 81, 589, 10, 79, 7, 54, 585, 1088, 5, 988, 553, 722, 988, 299, 1077, 1067, 241, 635, 26, 72, 5, 1097, 5, 568, 145, 500, 425, 5, 234, 738, 568, 988, 21, 115, 1065, 523, 1, 717, 1, 727, 57, 6, 729, 722, 1001, 884, 175, 927, 1108, 817, 977, 987, 53, 530, 536, 3, 53, 1113, 2, 970, 856, 241, 1099, 4, 281, 1016, 38, 2, 850, 748, 7, 14, 908, 6, 549, 838, 213, 165, 583, 6, 988, 345, 505, 337, 738, 5, 157, 5, 177, 67, 7, 100, 514, 786, 5, 988, 792, 722, 1, 39, 1, 1087, 1051, 7, 56, 1077, 711, 1010, 1004, 1123, 604, 987, 5, 568, 988, 297, 722, 115, 437, 1085, 2, 565, 727, 988, 84, 5, 585, 950, 720, 1016, 663, 1016, 1114, 1100, 38, 514, 491, 1051, 549, 748, 7, 75, 828, 5, 585, 821, 1077, 115, 981, 796, 7, 102, 125, 549, 1103, 1120, 530, 208, 1020, 375, 6, 549, 424, 898, 514, 208, 325, 988, 909, 722, 857, 987, 67, 7, 38, 514, 1, 364, 546, 362, 7, 1, 35, 67, 7, 38, 6, 177, 949, 6, 514, 711, 408, 1010, 702, 115, 1122, 138, 57, 2, 850, 838, 514, 208, 973, 7, 56, 671, 198, 987, 533, 514, 661, 539, 6, 895, 533, 629, 549, 373, 6, 205, 533, 336, 2, 970, 1074, 1016, 497, 727, 748, 9, 239, 585, 1120, 530, 208, 527, 1016, 801, 987, 533, 514, 491, 1051, 549, 748, 205, 533, 514, 661, 539, 7, 73, 297, 5, 566, 876, 514, 711, 364, 546, 362, 5, 876, 514, 394, 5, 177, 62, 28, 288, 5, 422, 1016, 1, 624, 546, 1051, 1, 6, 876, 514, 711, 615, 546, 191, 1016, 988, 374, 7, 102, 806, 988, 236, 579, 549, 521, 140, 6, 1089, 115, 1070, 456, 115, 1103, 0, 22, 67, 7, 38, 167, 1016, 530, 347, 585, 6, 157, 53, 436, 585, 671, 198, 578, 1016, 440, 738, 1100, 7, 93, 332, 622, 722, 988, 84, 618, 587, 1016, 949, 804, 124, 916, 9, 157, 532, 5, 727, 697, 1083, 1016, 64, 24, 5, 250, 115, 494, 722, 57, 2, 850, 195, 984, 218, 988, 771, 5, 53, 514, 698, 224, 1000, 988, 708, 315, 7, 53, 469, 988, 296, 180, 975, 215, 989, 751, 9, 157, 67, 7, 38, 2, 850, 1086, 1077, 908, 485, 987, 5, 568, 988, 393, 1085, 5, 53, 268, 585, 475, 7, 56, 1077, 711, 987, 697, 555, 1077, 1, 578, 1, 8, 727, 987, 779, 53, 292, 530, 491, 62, 28, 988, 479, 824, 7, 56, 1077, 590, 205, 876, 1077, 114, 711, 114, 578, 6, 566, 53, 662, 198, 755, 988, 237, 6, 987, 53, 469, 539, 908, 7, 35, 57, 5, 145, 549, 622, 5, 514, 208, 963, 241, 578, 1112, 8, 994, 514, 468, 549, 174, 5, 585, 514, 208, 822, 568, 988, 556, 722, 989, 133, 7, 14, 585, 1077, 993, 577, 1016, 712, 1089, 378, 988, 1, 318, 181, 722, 665, 1, 3, 53, 814, 62, 28, 4, 1077, 532, 727, 546, 7, 53, 530, 667, 987, 67, 7, 38, 1077, 841, 9, 157, 585, 1077, 567, 764, 987, 539, 562, 1077, 414, 477, 999, 266, 115, 323, 239, 947, 853, 7, 56, 584, 5, 177, 115, 848, 5, 988, 763, 1097, 859, 681, 1097, 488, 686, 738, 722, 585, 9, 157, 57, 2, 850, 384, 346, 722, 549, 1103, 2, 850, 219, 193, 387, 546, 5, 1108, 156, 166, 722, 765, 501, 5, 1016, 1027, 585, 579, 719, 722, 174, 157, 652, 7, 102, 988, 605, 5, 53, 696, 129, 5, 533, 831, 830, 570, 9, 239, 533, 1077, 240, 82, 233, 157, 382, 770, 1108, 115, 344, 987, 216, 988, 154, 839, 7, 1, 63, 2, 850, 731, 406, 584, 1016, 806, 203, 579, 265, 5, 1, 1077, 729, 722, 988, 189, 533, 598, 362, 127, 988, 87, 157, 890, 722, 156, 411, 168, 651, 5, 1090, 5, 727, 115, 604, 315, 5, 53, 514, 140, 849, 741, 477, 64, 24, 9, 157, 67, 7, 38, 5, 199, 727, 546, 5, 130, 456, 697, 391, 8, 1, 57, 584, 908, 684, 868, 1016, 403, 464, 722, 203, 7, 1, 80, 57, 0, 56, 514, 149, 208, 549, 431, 1016, 530, 1112, 856, 949, 997, 722, 546, 8, 988, 420, 879, 198, 871, 362, 568, 412, 7, 109, 943, 663, 714, 1077, 987, 5, 456, 988, 442, 1011, 5, 533, 837, 988, 1018, 7, 53, 514, 864, 546, 5, 908, 724, 5, 196, 1044, 891, 1031, 6, 1077, 585, 988, 285, 712, 987, 843, 990, 722, 989, 854, 10, 70, 6, 456, 5, 721, 392, 5, 585, 204, 164, 987, 533, 1077, 454, 722, 67, 7, 38, 6, 454, 392, 711, 1016, 862, 539, 123, 7, 56, 1077, 549, 742, 123, 533, 863, 1016, 198, 1105, 1044, 6, 549, 742, 185, 177, 156, 718, 456, 483, 157, 569, 7, 1, 68, 319, 5, 895, 53, 2, 1062, 261, 748, 763, 359, 2, 970, 856, 987, 945, 118, 663, 6, 994, 856, 585, 118, 105, 42, 5, 1, 1077, 549, 731, 800, 5, 177, 533, 846, 477, 988, 971, 157, 940, 738, 732, 988, 956, 983, 7, 53, 493, 138, 546, 5, 943, 241, 549, 602, 1116, 7, 105, 42, 1077, 5, 568, 420, 5, 206, 988, 656, 722, 988, 680, 6, 177, 57, 547, 5, 729, 671, 806, 585, 5, 514, 208, 988, 656, 722, 988, 557, 7, 93, 1127, 176, 1077, 851, 1016, 530, 465, 547, 180, 697, 476, 2, 850, 433, 5, 157, 53, 1115, 566, 115, 1013, 722, 589, 1045, 988, 605, 2, 850, 699, 116, 7, 22, 709, 6, 456, 585, 1077, 711, 1010, 138, 987, 400, 987, 988, 114, 846, 32, 114, 366, 514, 211, 1016, 350, 989, 1, 43, 7, 1, 53, 1037, 1016, 67, 7, 38, 5, 1097, 514, 632, 1016, 490, 115, 650, 722, 952, 1016, 539, 914, 568, 988, 341, 7, 1, 111, 114, 529, 114, 533, 261, 748, 10, 1, 53, 179, 120, 7, 88, 816, 539, 416, 1108, 115, 548, 722, 502, 961, 7, 1, 74, 5, 533, 356, 2, 970, 114, 530, 114, 1016, 714, 5, 1126, 596, 9, 157, 53, 1074, 546, 1016, 390, 547, 5, 1, 876, 851, 813, 894, 7, 53, 643, 118, 988, 913, 1096, 845, 5, 1108, 586, 114, 428, 114, 1061, 834, 988, 1019, 722, 988, 749, 312, 309, 5, 157, 586, 382, 760, 568, 323, 421, 474, 7, 1, 47, 533, 261, 549, 770, 1020, 10, 53, 531, 2, 970, 864, 115, 896, 729, 568, 988, 559, 7, 1, 11, 901, 873, 722, 286, 301, 67, 7, 38, 2, 850, 733, 295, 7, 1, 56, 2, 850, 549, 842, 679, 5, 1126, 596, 7, 48, 858, 994, 2, 819, 711, 443, 1016, 530, 118, 9, 533, 2, 850, 869, 990, 145, 187, 405, 729, 6, 697, 782, 6, 157, 987, 53, 530, 1016, 591, 1055, 7, 1, 51, 842, 679, 6, 57, 2, 850, 679, 118, 549, 770, 10, 68, 306, 1077, 513, 628, 988, 200, 7, 53, 851, 767, 1016, 697, 555, 8, 1, 53, 696, 821, 862, 1128, 782, 5, 1126, 596, 7, 1, 88, 493, 738, 146, 1012, 180, 988, 983, 1092, 539, 562, 5, 647, 568, 115, 554, 252, 5, 514, 634, 115, 262, 157, 367, 988, 86, 321, 2, 850, 534, 218, 549, 594, 7, 1, 108, 5, 277, 1094, 533, 2, 850, 711, 644, 5, 1, 876, 851, 5, 1108, 115, 606, 987, 1033, 1016, 544, 539, 705, 9, 157, 53, 453, 539, 218, 988, 660, 33, 722, 988, 520, 5, 157, 1051, 988, 1101, 920, 1108, 982, 715, 780, 153, 449, 180, 371, 600, 7, 55, 988, 339, 290, 722, 539, 225, 5, 152, 115, 799, 722, 323, 157, 352, 719, 5, 561, 729, 722, 988, 427, 740, 246, 5, 568, 988, 571, 482, 473, 7, 93, 668, 739, 722, 988, 473, 242, 1051, 145, 38, 2, 850, 759, 0, 67, 7, 38, 369, 191, 988, 1106, 5, 690, 178, 115, 114, 588, 114, 478, 722, 772, 190, 5, 805, 156, 171, 187, 5, 157, 851, 8, 1, 54, 1126, 922, 540, 1126, 244, 590, 657, 1016, 862, 585, 7, 53, 514, 585, 741, 988, 659, 5, 239, 533, 1121, 2, 970, 620, 585, 925, 7, 1, 112, 6, 53, 292, 590, 657, 1016, 862, 585, 6, 988, 442, 782, 722, 57, 2, 850, 53, 514, 401, 514, 1016, 933, 697, 417, 741, 0, 103, 994, 514, 988, 773, 722, 553, 6, 856, 988, 251, 752, 568, 115, 749, 1124, 734, 114, 846, 32, 114, 365, 5, 734, 115, 682, 374, 774, 908, 987, 585, 1021, 988, 626, 1007, 309, 722, 726, 104, 779, 7, 93, 685, 678, 773, 204, 988, 769, 217, 9, 1125, 5, 177, 697, 417, 511, 126, 1016, 988, 518, 5, 145, 988, 254, 807, 243, 738, 6, 145, 988, 543, 349, 177, 186, 5, 988, 1032, 722, 789, 241, 1093, 5, 1108, 949, 287, 900, 5, 533, 658, 1016, 354, 184, 477, 988, 820, 238, 722, 988, 769, 1016, 910, 790, 582, 722, 333, 7, 67, 7, 38, 5, 788, 115, 706, 960, 1016, 1117, 727, 6, 466, 5, 177, 585, 1088, 5, 908, 572, 988, 192, 722, 539, 742, 769, 6, 514, 619, 542, 568, 156, 1050, 322, 1016, 988, 350, 722, 999, 426, 1068, 7, 93, 769, 1077, 729, 722, 57, 2, 850, 1, 941, 5, 1, 177, 549, 131, 1120, 530, 806, 585, 6, 585, 835, 5, 727, 549, 756, 5, 115, 967, 722, 695, 5, 115, 284, 722, 1063, 5, 115, 194, 5, 931, 157, 934, 5, 987, 833, 729, 722, 988, 267, 2, 850, 580, 380, 1016, 624, 115, 432, 7, 56, 670, 5, 568, 878, 5, 180, 403, 779, 988, 324, 722, 648, 1111, 1016, 198, 746, 1, 942, 1, 205, 876, 1077, 1015, 722, 213, 746, 1, 965, 1, 6, 157, 1125, 711, 1016, 645, 156, 182, 722, 988, 966, 7, 1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7, 1, 93, 602, 239, 729, 5, 1, 876, 291, 542, 6, 1, 239, 988, 735, 356, 2, 970, 294, 5, 205, 533, 330, 585, 7, 1, 1, 29, 585, 10, 1, 53, 1077, 118, 1016, 452, 1051, 999, 273, 1090, 53, 536, 115, 455, 157, 855, 57, 547, 727, 988, 1005, 7, 17, 533, 928, 992, 5, 549, 522, 568, 988, 778, 722, 549, 1064, 274, 5, 988, 995, 235, 1082, 722, 516, 805, 191, 477, 549, 1095, 459, 5, 549, 610, 955, 258, 481, 241, 115, 905, 987, 625, 988, 1014, 722, 115, 865, 689, 5, 53, 436, 1016, 1089, 115, 322, 533, 514, 988, 852, 808, 177, 549, 770, 6, 988, 808, 722, 644, 271, 986, 533, 1077, 7, 51, 1103, 493, 180, 546, 328, 5, 239, 549, 417, 1029, 759, 539, 1016, 988, 782, 7, 1, 66, 7, 83, 1075, 1016, 862, 585, 5, 1, 876, 210, 5, 177, 566, 407, 542, 7, 48, 886, 549, 881, 5, 926, 906, 7, 1, 74, 5, 83, 469, 663, 738, 639, 141, 5, 1, 533, 851, 627, 9, 991, 5, 758, 549, 170, 1007, 674, 8, 1, 27, 157, 862, 988, 840, 722, 988, 559, 7, 1, 48, 883, 585, 1016, 663, 1108, 115, 593, 722, 700, 948, 793, 8, 988, 197, 5, 988, 915, 5, 988, 368, 5, 988, 1034, 6, 145, 988, 282, 893, 722, 988, 673, 2, 850, 358, 377, 7, 14, 1091, 697, 1114, 744, 988, 409, 1030, 533, 851, 5, 1008, 738, 549, 259, 115, 635, 8, 1, 112, 5, 53, 821, 359, 2, 970, 862, 560, 763, 657, 1016, 636, 1109, 987, 7, 1, 108, 6, 585, 1077, 590, 988, 388, 729, 671, 530, 461, 456, 546, 7, 77, 533, 1077, 5, 1007, 585, 145, 157, 568, 917, 722, 585, 145, 6, 177, 533, 514, 208, 1007, 5, 157, 568, 917, 722, 5, 549, 770, 6, 908, 523, 5, 908, 255, 5, 908, 342, 5, 987, 729, 640, 1016, 304, 738, 8, 1, 19, 351, 1108, 1128, 617, 0, 1, 177, 728, 729, 514, 640, 1016, 856, 8, 1, 19, 351, 1108, 1128, 1117, 0, 1, 22, 5, 1108, 988, 304, 727, 697, 633, 5, 697, 334, 951, 156, 1048, 257, 7, 1, 97, 584, 697, 742, 599, 5, 1, 533, 851, 5, 609, 663, 579, 115, 313, 775, 845, 180, 988, 388, 722, 988, 448, 1069, 7, 56, 1077, 919, 157, 235, 157, 613, 8, 709, 1, 379, 1, 9, 709, 230, 5, 710, 722, 988, 143, 722, 783, 456, 836, 568, 115, 769, 1084, 6, 119, 145, 5, 709, 612, 888, 722, 401, 532, 208, 1057, 177, 115, 944, 7, 93, 420, 234, 552, 1016, 663, 988, 121, 439, 722, 57, 2, 850, 227, 1108, 549, 726, 622, 7, 1, 31, 2, 970, 1126, 401, 311, 1108, 745, 161, 685, 10, 1, 53, 179, 5, 926, 644, 118, 456, 115, 1025, 722, 949, 128, 7, 1, 69, 5, 1, 533, 851, 231, 7, 1, 78, 1081, 6, 734, 398, 10, 1, 51, 283, 417, 511, 338, 5, 157, 549, 258, 750, 115, 635, 1044, 989, 523, 954, 7, 1, 69, 998, 722, 585, 5, 697, 319, 435, 6, 161, 685, 986, 566, 53, 2, 310, 707, 1023, 115, 236, 7, 1, 14, 549, 1018, 1017, 663, 568, 115, 446, 987, 533, 707, 1003, 722, 162, 385, 7, 53, 690, 187, 5, 576, 386, 241, 697, 1048, 343, 9, 157, 177, 53, 1037, 5, 697, 415, 434, 727, 115, 904, 769, 119, 988, 659, 6, 988, 731, 718, 228, 988, 775, 716, 753, 722, 988, 845, 7, 1, 74, 5, 241, 58, 0, 1, 53, 851, 7, 56, 1077, 115, 899, 722, 115, 361, 6, 156, 726, 1015, 361, 5, 923, 568, 988, 815, 1044, 115, 1072, 7, 1, 23, 58, 6, 115, 89, 0, 1, 53, 300, 7, 48, 1077, 889, 9, 239, 53, 436, 546, 272, 212, 663, 5, 229, 115, 635, 811, 7, 1, 109, 115, 1114, 0, 61, 1108, 115, 363, 631, 6, 239, 727, 402, 470, 7, 113, 649, 253, 5, 1092, 335, 1126, 488, 585, 10, 1, 48, 160, 903, 8, 1, 67, 7, 89, 484, 585, 1016, 663, 7, 1, 1, 12, 6, 53, 336, 2, 970, 596, 1126, 399, 595, 988, 90, 7, 48, 1077, 949, 156, 573, 541, 7, 1, 1, 53, 336, 2, 970, 6, 1010, 138, 7, 7, 7, 7, 88, 869, 456, 663, 1016, 745, 546, 1090, 533, 1077, 317, 7, 1, 1, 110, 533, 1077, 317, 10, 113, 10, 1, 53, 696, 530, 620, 115, 635, 1020, 691, 151, 396, 1007, 697, 961, 5, 456, 533, 160, 1108, 115, 327, 606, 8, 1, 112, 6, 876, 2, 850, 156, 188, 892, 5, 1126, 596, 5, 67, 7, 89, 7, 49, 731, 563, 1077, 1016, 530, 546, 360, 241, 115, 430, 747, 6, 142, 5, 781, 89, 0, 88, 1003, 585, 988, 959, 1083, 722, 797, 549, 510, 6, 722, 458, 585, 727, 115, 803, 802, 7, 14, 180, 988, 680, 53, 1077, 114, 988, 114, 430, 747, 7, 1, 1, 12, 5, 781, 89, 6, 177, 1126, 856, 7, 106, 114, 987, 114, 549, 550, 10, 1, 1, 92, 1077, 549, 550, 7, 88, 214, 568, 546, 5, 495, 568, 546, 6, 734, 1003, 876, 335, 7, 22, 876, 293, 2, 970, 201, 711, 1016, 530, 145, 988, 366, 1108, 539, 7, 88, 293, 2, 970, 201, 988, 420, 987, 5, 727, 1060, 316, 5, 729, 292, 149, 488, 701, 392, 1016, 862, 549, 770, 7, 80, 1111, 0, 88, 2, 850, 590, 115, 471, 512, 456, 735, 472, 7, 89, 584, 988, 731, 1098, 53, 401, 595, 7, 1, 1, 113, 401, 595, 10, 22, 1126, 590, 851, 6, 1, 38, 514, 115, 307, 905, 568, 549, 417, 7, 1, 74, 5, 53, 595, 546, 5, 157, 533, 595, 663, 6, 731, 585, 526, 138, 533, 1077, 317, 7, 1, 53, 370, 697, 1071, 576, 7, 1, 110, 876, 869, 456, 1126, 10, 1, 1, 112, 6, 813, 574, 1016, 988, 581, 7, 88, 1075, 546, 1067, 6, 157, 241, 663, 0, 1, 48, 607, 140, 5, 157, 1006, 191, 549, 534, 1016, 642, 1051, 180, 988, 899, 722, 988, 361, 7, 1, 95, 1088, 316, 1090, 53, 293, 2, 970, 642, 180, 987, 996, 6, 293, 2, 970, 418, 585, 7, 22, 53, 457, 698, 1016, 806, 585, 540, 9, 157, 714, 585, 2, 850, 305, 663, 6, 305, 663, 7, 92, 2, 850, 988, 823, 1100, 53, 359, 2, 970, 311, 161, 685, 5, 697, 319, 83, 9, 734, 818, 89, 547, 584, 988, 823, 7, 1, 35, 988, 442, 1011, 697, 564, 306, 118, 697, 280, 1037, 579, 115, 870, 329, 1016, 1047, 546, 217, 7, 1, 53, 1107, 1126, 2, 310, 979, 663, 560, 585, 526, 5, 1, 53, 851, 7, 48, 928, 644, 1051, 180, 988, 899, 5, 157, 1041, 218, 549, 441, 115, 263, 533, 514, 463, 1016, 626, 7, 91, 533, 1037, 1024, 663, 7, 1, 53, 2, 310, 818, 628, 1016, 979, 1126, 6, 205, 53, 2, 1062, 149, 964, 1126, 722, 638, 697, 1117, 7, 1, 53, 654, 115, 327, 487, 5, 1093, 533, 703, 1108, 115, 502, 885, 7, 1, 74, 5, 53, 336, 2, 970, 248, 115, 936, 1090, 53, 214, 568, 698, 6, 157, 714, 585, 2, 850, 156, 130, 1009, 218, 1056, 0, 1, 48, 607, 902, 5, 1109, 221, 5, 157, 805, 729, 722, 988, 320, 172, 467, 7, 1, 95, 8, 655, 1129, 278, 6, 157, 540, 169, 988, 264, 1126, 628, 7, 1, 48, 774, 990, 180, 697, 383, 157, 289, 1016, 1073, 1051, 157, 362, 988, 845, 5, 930, 714, 157, 991, 215, 988, 769, 7, 1, 52, 585, 526, 10, 53, 244, 979, 1126, 568, 445, 676, 6, 157, 585, 336, 2, 970, 972, 691, 641, 1016, 525, 7, 7, 7, 7, 53, 244, 832, 714, 560, 962, 157, 777, 53, 1077, 1090, 53, 503, 67, 7, 89, 2, 850, 712, 7, 73, 297, 5, 320, 362, 5, 53, 514, 149, 114, 436, 114, 992, 1077, 709, 729, 628, 546, 6, 731, 53, 514, 499, 1108, 988, 937, 5, 376, 988, 1058, 776, 118, 546, 5, 1010, 53, 517, 503, 1016, 998, 533, 1077, 115, 423, 5, 729, 722, 988, 593, 987, 169, 616, 212, 7, 23, 58, 5, 157, 533, 114, 1077, 114, 616, 212, 6, 205, 533, 514, 277, 1016, 925, 0, 93, 840, 722, 1056, 514, 1016, 620, 737, 198, 968, 148, 734, 497, 1044, 5, 239, 533, 1077, 545, 119, 988, 308, 6, 727, 402, 470, 5, 177, 1126, 856, 7, 1, 108, 5, 53, 1087, 723, 1016, 988, 559, 568, 697, 686, 381, 683, 6, 818, 690, 5, 60, 462, 663, 5, 180, 988, 761, 722, 781, 89, 2, 850, 249, 722, 423, 213, 302, 241, 988, 496, 722, 697, 748, 546, 0, 73, 297, 53, 664, 1016, 355, 988, 769, 456, 713, 6, 53, 1017, 67, 7, 89, 908, 1090, 876, 210, 1016, 921, 912, 118, 539, 785, 7, 53, 832, 489, 723, 115, 798, 768, 118, 988, 553, 213, 114, 674, 114, 6, 725, 5, 53, 1077, 794, 5, 697, 319, 83, 0, 53, 1077, 783, 1016, 698, 628, 729, 722, 697, 742, 898, 7, 1, 94, 53, 1077, 973, 1051, 157, 616, 147, 1108, 546, 7, 53, 514, 869, 145, 697, 1028, 568, 134, 5, 157, 53, 514, 731, 1016, 871, 1051, 988, 374, 157, 488, 1016, 1117, 7, 48, 514, 208, 317, 731, 1039, 558, 5, 157, 533, 337, 950, 5, 722, 537, 348, 5, 908, 987, 992, 514, 208, 709, 787, 1117, 722, 331, 6, 549, 418, 1077, 270, 157, 1049, 7, 53, 514, 670, 546, 728, 734, 1040, 5, 1123, 209, 5, 157, 1003, 546, 575, 157, 340, 7, 71, 53, 855, 987, 533, 1077, 957, 7, 1, 53, 1077, 492, 180, 442, 5, 1108, 115, 669, 135, 853, 8, 492, 1016, 530, 697, 521, 727, 949, 115, 2, 946, 7, 2, 94, 549, 935, 623, 210, 1016, 136, 663, 809, 6, 177, 53, 222, 988, 534, 568, 53, 436, 177, 566, 533, 1088, 1080, 663, 355, 585, 7, 93, 867, 1077, 453, 241, 988, 1003, 8, 566, 533, 114, 1088, 114, 1080, 663, 5, 1089, 1120, 533, 856, 1016, 697, 1083, 722, 1118, 10, 68, 939, 210, 1016, 497, 115, 635, 1104, 6, 53, 436, 704, 157, 1043, 7, 1, 76, 5, 1090, 53, 643, 1051, 5, 53, 863, 1016, 862, 115, 905, 212, 549, 272, 507, 202, 6, 177, 566, 533, 514, 988, 861, 5, 157, 1088, 155, 547, 241, 551, 585, 191, 477, 663, 7, 92, 404, 663, 926, 685, 7, 93, 861, 10, 111, 5, 53, 514, 115, 861, 1119, 1038, 722, 549, 0, 53, 314, 180, 988, 245, 480, 5, 157, 1033, 910, 722, 697, 226, 1032, 7, 22, 994, 422, 663, 5, 994, 303, 7, 53, 855, 987, 533, 1078, 2, 970, 1080, 988, 884, 220, 6, 53, 293, 2, 970, 353, 549, 184, 9, 533, 590, 592, 549, 417, 727, 988, 527, 757, 218, 7, 98, 1088, 988, 730, 53, 514, 149, 877, 5, 734, 298, 1051, 1108, 910, 653, 745, 7, 14, 560, 533, 855, 1007, 697, 621, 0, 1, 53, 643, 1051, 140, 5, 157, 250, 887, 722, 987, 899, 722, 988, 361, 524, 727, 988, 1072, 701, 549, 207, 7, 51, 1103, 1017, 663, 139, 585, 1077, 988, 602, 996, 533, 514, 360, 6, 590, 115, 712, 973, 1108, 115, 874, 521, 5, 1090, 533, 1077, 362, 568, 30, 825, 477, 115, 791, 537, 183, 7, 59, 115, 712, 0, 22, 585, 980, 549, 1098, 550, 7, 95, 169, 1123, 722, 762, 860, 766, 568, 403, 630, 7, 11, 656, 1097, 514, 969, 1108, 988, 308, 292, 707, 530, 611, 987, 672, 1052, 938, 7, 7, 7, 7, 1, 53, 1037, 191, 1016, 697, 1117, 5, 157, 1087, 727, 512, 157, 692, 9, 991, 53, 643, 180, 988, 361, 140, 7, 53, 855, 987, 5, 1090, 89, 598, 568, 988, 442, 938, 5, 533, 595, 590, 1089, 988, 388, 1120, 198, 7, 48, 514, 784, 549, 946, 5, 122, 585, 5, 826, 585, 7, 110, 514, 53, 360, 987, 1108, 161, 722, 697, 997, 10, 96, 515, 2, 970, 208, 223, 722, 663, 6, 53, 514, 590, 132, 990, 7, 7, 7, 7, 1, 46, 585, 5, 83, 5, 1108, 987, 418, 1080, 663, 53, 293, 2, 970, 355, 158, 938, 7, 93, 775, 1036, 1077, 5, 53, 336, 2, 970, 596, 1092, 1016, 806, 585, 6, 114, 53, 514, 707, 597, 114, 7, 77, 5, 1108, 697, 898, 157, 697, 802, 5, 115, 884, 918, 722, 276, 298, 1051, 988, 420, 6, 53, 590, 1006, 745, 579, 989, 419, 7, 7, 7, 7, 108, 5, 745, 1077, 988, 729, 666, 1001, 317, 417, 292, 862, 1007, 6, 862, 932, 1016, 988, 1022, 470, 1046, 7, 31, 2, 970, 1126, 596, 560, 5, 568, 974, 115, 460, 601, 5, 399, 450, 5, 729, 858, 517, 988, 1011, 711, 1089, 729, 1076, 1016, 239, 1089, 729, 244, 10, 108, 6, 987, 1077, 988, 1083, 53, 746, 9, 157, 177, 533, 608, 992, 157, 1079, 663, 5, 988, 996, 994, 242, 697, 2, 978, 2, 275, 628, 115, 559, 722, 247, 7, 48, 336, 2, 970, 907, 5, 1126, 1047, 5, 781, 89, 6, 533, 590, 608, 992, 812, 1080, 5, 157, 727, 549, 633, 5, 1007, 988, 506, 202, 5, 53, 863, 1016, 535, 988, 810, 8, 2, 15, 1126, 958, 1126, 596, 1092, 1126, 2, 819, 279, 738, 10, 2, 1, 54, 53, 292, 530, 746, 987, 418, 5, 1108, 987, 810, 727, 585, 5, 53, 879, 530, 360, 115, 508, 996, 7, 93, 708, 509, 996, 1077, 1016, 862, 987, 53, 293, 2, 970, 6, 157, 987, 504, 1077, 491, 663, 7, 22, 5, 725, 5, 180, 987, 675, 5, 83, 5, 1077, 992, 162, 727, 372, 53, 1121, 2, 970, 530, 491, 1016, 530, 89, 144, 209, 663, 5, 157, 1016, 535, 546, 856, 8, 2, 56, 2, 850, 711, 1020, 603, 6, 53, 2, 637, 882, 1126, 560, 2, 10, 1, 56, 114, 1077, 114, 1020, 603, 6, 585, 1120, 530, 208, 5, 399, 566, 533, 2, 310, 208, 144, 7, 53, 743, 1051, 697, 1028, 5, 157, 1087, 362, 157, 1017, 67, 7, 89, 7, 73, 297, 53, 336, 2, 970, 979, 539, 114, 987, 114, 6, 585, 1120, 530, 208, 41, 1016, 539, 7, 53, 894, 851, 53, 293, 2, 970, 745, 546, 5, 987, 53, 1077, 1020, 690, 7, 88, 818, 629, 988, 563, 6, 876, 2, 850, 908, 844, 0, 56, 1077, 987, 987, 654, 539, 490, 663, 988, 361, 7, 22, 876, 1077, 985, 1054, 180, 711, 489, 988, 782, 6, 876, 335, 908, 1074, 546, 2, 360, 2, 241, 910, 729, 884, 0, 18, 442, 53, 1077, 137, 876, 1121, 2, 970, 620, 663, 723, 6, 157, 180, 697, 1110, 2, 388, 53, 953, 42, 7, 112, 5, 585, 1077, 53, 1097, 924, 42, 8, 53, 1017, 67, 7, 89, 533, 1077, 988, 2, 279, 2, 656, 5, 157, 876, 1017, 911, 385, 5, 157, 908, 585, 503, 1016, 198, 1035, 7, 7, 7, 7, 14, 533, 746, 89, 1109, 1105, 9, 157, 876, 561, 988, 769, 153, 539, 562, 2, 850, 997, 7, 7, 7, 7, 1, 48, 451, 547, 362, 568, 988, 171, 701, 674, 5, 598, 191, 549, 534, 5, 157, 269, 549, 173, 215, 585, 5, 643, 1051, 180, 988, 769, 119, 988, 260, 7, 1, 53, 628, 1016, 429, 987, 89, 547, 1120, 530, 491, 585, 1016, 663, 5, 566, 533, 2, 310, 208, 117, 1016, 856, 1089, 533, 1003, 987, 315, 7, 1, 14, 5, 568, 159, 1016, 115, 810, 53, 806, 519, 6, 1, 20, 140, 10, 1, 533, 447, 738, 7, 1, 110, 988, 729, 996, 987, 232, 663, 163, 701, 546, 584, 987, 53, 595, 392, 1016, 614, 723, 10, 1, 48, 928, 1051, 157, 598, 549, 521, 727, 697, 880, 1108, 115, 606, 7, 1, 77, 988, 581, 722, 585, 584, 987, 53, 114, 150, 114, 926, 748, 6, 895, 42, 2, 850, 357, 585, 456, 663, 0, 93, 90, 922, 147, 5, 157, 525, 728, 6, 239, 992, 2, 850, 709, 413, 736, 593, 722, 174, 7, 1]\n"
     ]
    }
   ],
   "source": [
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(enc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cb8ff09-d42e-403f-a1cf-9c0ddaee59d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [53, 44, 149, 1003]\n",
      "y:      [44, 149, 1003, 57]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4 #length of the input\n",
    "#The context_size of 4 means that the model is trained to look at a sequence of 4 words (or tokens) \n",
    "#to predict the next word in the sequence. \n",
    "#The input x is the first 4 tokens [1, 2, 3, 4], and the target y is the next 4 tokens [2, 3, 4, 5]\n",
    "\n",
    "x = enc_text[:context_size]\n",
    "y = enc_text[1:context_size+1]\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "918f6f99-bb89-44c0-9ee8-e1d0ef030ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53] ----> 44\n",
      "[53, 44] ----> 149\n",
      "[53, 44, 149] ----> 1003\n",
      "[53, 44, 149, 1003] ----> 57\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_text[:i]\n",
    "    desired = enc_text[i]\n",
    "\n",
    "    print(context, \"---->\", desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a34ab3c0-2fb2-4037-894b-601f57a95e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ----> HAD\n",
      "I HAD ----> always\n",
      "I HAD always ----> thought\n",
      "I HAD always thought ----> Jack\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_text[:i]\n",
    "    desired = enc_text[i]\n",
    "\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28291265-0320-4ff2-84b7-5c9b7ab894ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.12.0)\n",
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.20.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tiktoken) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (6.33.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.3.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.4)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken tensorflow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1569f3ce-2734-4c62-a9a3-34732440f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "tokenizer  = tiktoken.get_encoding(\"o200k_harmony\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eae7b40a-380f-4d96-b3dc-345f13a822f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12194, 357, 939, 23967, 368]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode((\"Hi I am Vinod\"), allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35030f22-98c5-45e0-8fad-9d0ecf7cebfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt2',\n",
       " 'r50k_base',\n",
       " 'p50k_base',\n",
       " 'p50k_edit',\n",
       " 'cl100k_base',\n",
       " 'o200k_base',\n",
       " 'o200k_harmony']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiktoken.list_encoding_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1d25f23-2bbd-4870-b105-0b90b4791b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d12e1711-b9cd-4437-bf98-82cb3f9a7081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1aeea965-ddf5-4f65-a2d9-8b64fc9cbbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset): \n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        #Using a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i+max_length]\n",
    "            target_chunk = token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8eb3f96-7c30-422f-bec2-f5849e961ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a764127-7b4a-4181-816b-e281ddfee463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0\n",
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=4, stride=1, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43d06b56-7dca-4d91-8454-7ce60c797650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f672e29d-53bf-469a-9026-4e84e0444fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5be7c8e-90e7-4165-84a5-fe06ac90dc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.4.0)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gensim) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gensim) (1.16.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gensim) (7.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9fbf877-1b5e-43ef-9e64-199fb7d66643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gensim) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gensim) (1.16.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gensim) (7.5.0)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ba4d95a-dea8-4a66-8f13-effa31b5572e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2025.11.12)\n",
      "Collecting certifi\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: certifi\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2025.11.12\n",
      "    Uninstalling certifi-2025.11.12:\n",
      "      Successfully uninstalled certifi-2025.11.12\n",
      "Successfully installed certifi-2026.1.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade certifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b47a5e4c-bac2-4e30-9dbf-899420855ab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "model = api.load(\"word2vec-google-news-300\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79371639-abda-47ee-8a99-468227ce9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f286c848-090e-4075-9603-7fe6916a9c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.07421875e-01 -2.01171875e-01  1.23046875e-01  2.11914062e-01\n",
      " -9.13085938e-02  2.16796875e-01 -1.31835938e-01  8.30078125e-02\n",
      "  2.02148438e-01  4.78515625e-02  3.66210938e-02 -2.45361328e-02\n",
      "  2.39257812e-02 -1.60156250e-01 -2.61230469e-02  9.71679688e-02\n",
      " -6.34765625e-02  1.84570312e-01  1.70898438e-01 -1.63085938e-01\n",
      " -1.09375000e-01  1.49414062e-01 -4.65393066e-04  9.61914062e-02\n",
      "  1.68945312e-01  2.60925293e-03  8.93554688e-02  6.49414062e-02\n",
      "  3.56445312e-02 -6.93359375e-02 -1.46484375e-01 -1.21093750e-01\n",
      " -2.27539062e-01  2.45361328e-02 -1.24511719e-01 -3.18359375e-01\n",
      " -2.20703125e-01  1.30859375e-01  3.66210938e-02 -3.63769531e-02\n",
      " -1.13281250e-01  1.95312500e-01  9.76562500e-02  1.26953125e-01\n",
      "  6.59179688e-02  6.93359375e-02  1.02539062e-02  1.75781250e-01\n",
      " -1.68945312e-01  1.21307373e-03 -2.98828125e-01 -1.15234375e-01\n",
      "  5.66406250e-02 -1.77734375e-01 -2.08984375e-01  1.76757812e-01\n",
      "  2.38037109e-02 -2.57812500e-01 -4.46777344e-02  1.88476562e-01\n",
      "  5.51757812e-02  5.02929688e-02 -1.06933594e-01  1.89453125e-01\n",
      " -1.16210938e-01  8.49609375e-02 -1.71875000e-01  2.45117188e-01\n",
      " -1.73828125e-01 -8.30078125e-03  4.56542969e-02 -1.61132812e-02\n",
      "  1.86523438e-01 -6.05468750e-02 -4.17480469e-02  1.82617188e-01\n",
      "  2.20703125e-01 -1.22558594e-01 -2.55126953e-02 -3.08593750e-01\n",
      "  9.13085938e-02  1.60156250e-01  1.70898438e-01  1.19628906e-01\n",
      "  7.08007812e-02 -2.64892578e-02 -3.08837891e-02  4.06250000e-01\n",
      " -1.01562500e-01  5.71289062e-02 -7.26318359e-03 -9.17968750e-02\n",
      " -1.50390625e-01 -2.55859375e-01  2.16796875e-01 -3.63769531e-02\n",
      "  2.24609375e-01  8.00781250e-02  1.56250000e-01  5.27343750e-02\n",
      "  1.50390625e-01 -1.14746094e-01 -8.64257812e-02  1.19140625e-01\n",
      " -7.17773438e-02  2.73437500e-01 -1.64062500e-01  7.29370117e-03\n",
      "  4.21875000e-01 -1.12792969e-01 -1.35742188e-01 -1.31835938e-01\n",
      " -1.37695312e-01 -7.66601562e-02  6.25000000e-02  4.98046875e-02\n",
      " -1.91406250e-01 -6.03027344e-02  2.27539062e-01  5.88378906e-02\n",
      " -3.24218750e-01  5.41992188e-02 -1.35742188e-01  8.17871094e-03\n",
      " -5.24902344e-02 -1.74713135e-03 -9.81445312e-02 -2.86865234e-02\n",
      "  3.61328125e-02  2.15820312e-01  5.98144531e-02 -3.08593750e-01\n",
      " -2.27539062e-01  2.61718750e-01  9.86328125e-02 -5.07812500e-02\n",
      "  1.78222656e-02  1.31835938e-01 -5.35156250e-01 -1.81640625e-01\n",
      "  1.38671875e-01 -3.10546875e-01 -9.71679688e-02  1.31835938e-01\n",
      " -1.16210938e-01  7.03125000e-02  2.85156250e-01  3.51562500e-02\n",
      " -1.01562500e-01 -3.75976562e-02  1.41601562e-01  1.42578125e-01\n",
      " -5.68847656e-02  2.65625000e-01 -2.09960938e-01  9.64355469e-03\n",
      " -6.68945312e-02 -4.83398438e-02 -6.10351562e-02  2.45117188e-01\n",
      " -9.66796875e-02  1.78222656e-02 -1.27929688e-01 -4.78515625e-02\n",
      " -7.26318359e-03  1.79687500e-01  2.78320312e-02 -2.10937500e-01\n",
      " -1.43554688e-01 -1.27929688e-01  1.73339844e-02 -3.60107422e-03\n",
      " -2.04101562e-01  3.63159180e-03 -1.19628906e-01 -6.15234375e-02\n",
      "  5.93261719e-02 -3.23486328e-03 -1.70898438e-01 -3.14941406e-02\n",
      " -8.88671875e-02 -2.89062500e-01  3.44238281e-02 -1.87500000e-01\n",
      "  2.94921875e-01  1.58203125e-01 -1.19628906e-01  7.61718750e-02\n",
      "  6.39648438e-02 -4.68750000e-02 -6.83593750e-02  1.21459961e-02\n",
      " -1.44531250e-01  4.54101562e-02  3.68652344e-02  3.88671875e-01\n",
      "  1.45507812e-01 -2.55859375e-01 -4.46777344e-02 -1.33789062e-01\n",
      " -1.38671875e-01  6.59179688e-02  1.37695312e-01  1.14746094e-01\n",
      "  2.03125000e-01 -4.78515625e-02  1.80664062e-02 -8.54492188e-02\n",
      " -2.48046875e-01 -3.39843750e-01 -2.83203125e-02  1.05468750e-01\n",
      " -2.14843750e-01 -8.74023438e-02  7.12890625e-02  1.87500000e-01\n",
      " -1.12304688e-01  2.73437500e-01 -3.26171875e-01 -1.77734375e-01\n",
      " -4.24804688e-02 -2.69531250e-01  6.64062500e-02 -6.88476562e-02\n",
      " -1.99218750e-01 -7.03125000e-02 -2.43164062e-01 -3.66210938e-02\n",
      " -7.37304688e-02 -1.77734375e-01  9.17968750e-02 -1.25000000e-01\n",
      " -1.65039062e-01 -3.57421875e-01 -2.85156250e-01 -1.66992188e-01\n",
      "  1.97265625e-01 -1.53320312e-01  2.31933594e-02  2.06054688e-01\n",
      "  1.80664062e-01 -2.74658203e-02 -1.92382812e-01 -9.61914062e-02\n",
      " -1.06811523e-02 -4.73632812e-02  6.54296875e-02 -1.25732422e-02\n",
      "  1.78222656e-02 -8.00781250e-02 -2.59765625e-01  9.37500000e-02\n",
      " -7.81250000e-02  4.68750000e-02 -2.22167969e-02  1.86767578e-02\n",
      "  3.11279297e-02  1.04980469e-02 -1.69921875e-01  2.58789062e-02\n",
      " -3.41796875e-02 -1.44042969e-02 -5.46875000e-02 -8.78906250e-02\n",
      "  1.96838379e-03  2.23632812e-01 -1.36718750e-01  1.75781250e-01\n",
      " -1.63085938e-01  1.87500000e-01  3.44238281e-02 -5.63964844e-02\n",
      " -2.27689743e-05  4.27246094e-02  5.81054688e-02 -1.07910156e-01\n",
      " -3.88183594e-02 -2.69531250e-01  3.34472656e-02  9.81445312e-02\n",
      "  5.63964844e-02  2.23632812e-01 -5.49316406e-02  1.46484375e-01\n",
      "  5.93261719e-02 -2.19726562e-01  6.39648438e-02  1.66015625e-02\n",
      "  4.56542969e-02  3.26171875e-01 -3.80859375e-01  1.70898438e-01\n",
      "  5.66406250e-02 -1.04492188e-01  1.38671875e-01 -1.57226562e-01\n",
      "  3.23486328e-03 -4.80957031e-02 -2.48046875e-01 -6.20117188e-02]\n"
     ]
    }
   ],
   "source": [
    "print(word_vector['computer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d78c8b83-006b-4b5a-a512-bd29411d2416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(word_vector['cat'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9bf88a1a-5f4e-45b6-91f8-4f41139c4412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.4827326238155365), ('queens', 0.466781347990036), ('kumaris', 0.4653734564781189), ('kings', 0.4558638036251068), ('womens', 0.422832190990448), ('princes', 0.4176960587501526), ('Al_Anqari', 0.41725507378578186), ('concubines', 0.4011078476905823), ('monarch', 0.3962482810020447), ('monarchy', 0.39430147409439087)]\n"
     ]
    }
   ],
   "source": [
    "# King + Women - Man = ?\n",
    "print(word_vector.most_similar(positive=['king', 'women'], negative=['man'], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72b2fcf2-e4c2-486b-9437-ad6489fb8982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76640123\n",
      "0.6510956\n",
      "0.76434743\n",
      "0.8543272\n",
      "0.7594367\n",
      "0.11408083\n"
     ]
    }
   ],
   "source": [
    "print(word_vector.similarity('woman', 'man'))\n",
    "print(word_vector.similarity('king', 'queen'))\n",
    "print(word_vector.similarity('uncle', 'aunt'))\n",
    "print(word_vector.similarity('boy', 'girl'))\n",
    "print(word_vector.similarity('nephew', 'niece'))\n",
    "print(word_vector.similarity('paper', 'water'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "424e2a19-3d9d-406e-9434-6ed12db5c70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tome', 0.7485831379890442), ('books', 0.7379178404808044), ('memoir', 0.7302927374839783), ('paperback_edition', 0.6868364810943604), ('autobiography', 0.6741527915000916)]\n"
     ]
    }
   ],
   "source": [
    "print(word_vector.most_similar(\"book\", topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf661020-a471-40d8-9dbe-17e09ccbcaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The magnitude of the difference between 'man' and 'woman' is 1.73\n",
      "The magnitude of the difference between 'semiconductor' and 'earthworm' is 5.67\n",
      "The magnitude of the difference between 'nephew' and 'niece' is 1.96\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Words to compare\n",
    "word1 = 'man'\n",
    "word2 = 'woman'\n",
    "\n",
    "word3 = 'semiconductor'\n",
    "word4 = 'earthworm'\n",
    "\n",
    "word5 = 'nephew'\n",
    "word6 = 'niece'\n",
    "\n",
    "# Calculate the vector difference\n",
    "vector_difference1 = model[word1] - model[word2]\n",
    "vector_difference2 = model[word3] - model[word4]\n",
    "vector_difference3 = model[word5] - model[word6]\n",
    "\n",
    "# Calculate the magnitude of the vector difference\n",
    "magnitude_of_difference1 = np.linalg.norm(vector_difference1)\n",
    "magnitude_of_difference2 = np.linalg.norm(vector_difference2)\n",
    "magnitude_of_difference3 = np.linalg.norm(vector_difference3)\n",
    "\n",
    "\n",
    "# Print the magnitude of the difference\n",
    "print(\"The magnitude of the difference between '{}' and '{}' is {:.2f}\".format(word1, word2, magnitude_of_difference1))\n",
    "print(\"The magnitude of the difference between '{}' and '{}' is {:.2f}\".format(word3, word4, magnitude_of_difference2))\n",
    "print(\"The magnitude of the difference between '{}' and '{}' is {:.2f}\".format(word5, word6, magnitude_of_difference3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "212eb9b0-3c3a-43a4-ae77-cacf3bfadbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "input_ids = torch.tensor([2,3,5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc3bf282-e3bf-44d0-9be1-bd8a47165edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42668230-723b-4064-b68a-2dae41818ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "057c62d6-a107-4a0d-86cf-ca25650ba854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3723900-1985-48ae-a54e-60e30c21cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f012c37-1e6a-412c-b6f8-be6f6d8851e7",
   "metadata": {},
   "source": [
    " IMPLEMENTING A SIMPLIFIED ATTENTION MECHANISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff2b46d7-8acd-4b99-bc06-a1a1ebbadfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd51db3c-b3e1-4341-bfed-81b8374d7dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5500, 0.8700, 0.6600])\n"
     ]
    }
   ],
   "source": [
    "x_2 = inputs[1] #A\n",
    "print(x_2)\n",
    "d_in = inputs.shape[1] #B\n",
    "d_out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "88b72e4f-951c-411b-8055-e60eecc56d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.2961, 0.5166],\n",
      "        [0.2517, 0.6886],\n",
      "        [0.0740, 0.8665]])\n",
      "Parameter containing:\n",
      "tensor([[0.1366, 0.1025],\n",
      "        [0.1841, 0.7264],\n",
      "        [0.3153, 0.6871]])\n",
      "Parameter containing:\n",
      "tensor([[0.0756, 0.1966],\n",
      "        [0.3164, 0.4017],\n",
      "        [0.1186, 0.8274]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "\n",
    "print(W_query)\n",
    "print(W_key)\n",
    "print(W_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b0e8b23-2959-4fc6-9eeb-b55d2ae6657a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n",
      "tensor([0.4433, 1.1419])\n",
      "tensor([0.3951, 1.0037])\n"
     ]
    }
   ],
   "source": [
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "print(query_2)\n",
    "print(key_2)\n",
    "print(value_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ac1ab9fb-1c4e-4750-8f55-7b2ab32e61b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys.shape torch.Size([6, 2])\n",
      "Values.shape torch.Size([6, 2])\n",
      "Queries.shape torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "queries = inputs @ W_query\n",
    "\n",
    "print(\"Keys.shape\", keys.shape)\n",
    "print(\"Values.shape\", values.shape)\n",
    "print(\"Queries.shape\", queries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4704582-75d6-4522-8793-f9f4f2205bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance before scaling (dim=5): 5.097946014146173\n",
      "Variance after scaling (dim=5): 1.0195892028292348\n",
      "Variance before scaling (dim=1000): 994.3555172046067\n",
      "Variance after scaling (dim=1000): 0.9943555172046067\n"
     ]
    }
   ],
   "source": [
    "#But why sqrt\n",
    "import numpy as np\n",
    "\n",
    "# Function to compute variance before and after scaling\n",
    "def compute_variance(dim, num_trials=1000): \n",
    "    dot_products = []\n",
    "    scaled_dot_products = []\n",
    "\n",
    "    # Generate multiple random vectors and compute dot products\n",
    "    for _ in range(num_trials):\n",
    "        q = np.random.randn(dim)\n",
    "        k = np.random.randn(dim)\n",
    "    \n",
    "        # Compute dot product\n",
    "        dot_product = np.dot(q, k)\n",
    "        dot_products.append(dot_product)\n",
    "    \n",
    "        #Scale the dot product by sqrt(dim)\n",
    "        scaled_dot_product = dot_product/np.sqrt(dim)\n",
    "        scaled_dot_products.append(scaled_dot_product)\n",
    "\n",
    "    variance_before_scaling = np.var(dot_products)\n",
    "    variance_after_scaling = np.var(scaled_dot_products)\n",
    "\n",
    "    return variance_before_scaling, variance_after_scaling\n",
    "\n",
    "# For dimension 5\n",
    "variance_before_5, variance_after_5 = compute_variance(5)\n",
    "print(f\"Variance before scaling (dim=5): {variance_before_5}\")\n",
    "print(f\"Variance after scaling (dim=5): {variance_after_5}\")\n",
    "\n",
    "# For dimension 1000\n",
    "variance_before_1000, variance_after_1000 = compute_variance(1000)\n",
    "print(f\"Variance before scaling (dim=1000): {variance_before_1000}\")\n",
    "print(f\"Variance after scaling (dim=1000): {variance_after_1000}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacfb4a1-2def-4345-9bda-60abe7b96264",
   "metadata": {},
   "source": [
    "HIDING FUTURE WORDS WITH CAUSAL ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0fd9e6fb-544d-4663-a53c-f832b4c31d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0410495e-f385-4253-b850-4d0786a9cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SelfAttention_v2(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac416be1-6d60-42db-9cb8-37338fcc2136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6f765943-ef76-4e1e-b1b4-f2977c1b4b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
      "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
      "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "queries = sa_v2.W_query(inputs)\n",
    "keys = sa_v2.W_key(inputs)\n",
    "attn_scores = queries @ keys.T\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "59cc3580-d62d-4593-9733-3b5a6011bd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "context_length = attn_scores.shape[0]\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "print(mask_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ef886cf4-266c-41cd-89af-75a54578e4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "masked_simple = attn_weights * mask_simple\n",
    "print(masked_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50610a58-0059-411d-9ae4-4ef3e4fd5786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "row_sums = masked_simple.sum(dim=1, keepdim=True)\n",
    "masked_simple_norm = masked_simple/row_sums\n",
    "print(masked_simple_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67053a5-b511-4fb2-a65e-6f4f347744da",
   "metadata": {},
   "source": [
    "Right way of masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a78093e-5d78-4839-bb86-5c91eb3197a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2899,  0.0716,  0.0760, -0.0138,  0.1344, -0.0511],\n",
      "        [ 0.4656,  0.1723,  0.1751,  0.0259,  0.1771,  0.0085],\n",
      "        [ 0.4594,  0.1703,  0.1731,  0.0259,  0.1745,  0.0090],\n",
      "        [ 0.2642,  0.1024,  0.1036,  0.0186,  0.0973,  0.0122],\n",
      "        [ 0.2183,  0.0874,  0.0882,  0.0177,  0.0786,  0.0144],\n",
      "        [ 0.3408,  0.1270,  0.1290,  0.0198,  0.1290,  0.0078]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54d4eb2d-1f13-419f-bf8c-b4d257793e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8ed65a01-1489-4aa5-ab87-731e4670f6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "print(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e420a657-659c-4a81-ba6f-61cdf5640613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(masked/keys.shape[-1]**0.5, dim=1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8c25a7-8481-4f42-8492-5418f6322a59",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">MASKING ADDITIONAL ATTENTION WEIGHTS WITH DROPOUT</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9669bb4b-93ac-46f5-96a7-9fbae8597afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5) #A\n",
    "example = torch.ones(6, 6) #B\n",
    "print(dropout(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "409603c1-95b5-48cd-a67e-1ee6f377d1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.7599, 0.6194, 0.6206, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4921, 0.4925, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3966, 0.0000, 0.3775, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3327, 0.3331, 0.3084, 0.3331, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8ba1e208-0377-4e93-bef2-638ed86a09a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.stack((inputs, inputs), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "777362dd-0c02-4579-8f57-e0a1f91a9974",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length,\n",
    "                 dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout) # New\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1)) # New\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape # New batch dimension b\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1, 2) # Changed transpose\n",
    "        attn_scores.masked_fill_(  # New, _ ops are in-place\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)  # `:num_tokens` to account for cases where the number of tokens in the batch is smaller than the supported context_size\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        attn_weights = self.dropout(attn_weights) # New\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "952b6745-e3ed-4217-b467-4864a1168e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "d_in = 3\n",
    "d_out = 2\n",
    "context_length = 6\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "context_vecs = ca(batch)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57317de8-8929-492c-be13-5bd1845895ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]],\n",
      "\n",
      "        [[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(context_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ff598ca7-5bbe-4b50-b9cb-19fa7758a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([CausalAttention(d_in, d_out, context_length, dropout, qkv_bias) \n",
    "             for _ in range(num_heads)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a6e0165-d810-4b14-b81b-684d157d94c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1] # This is the number of tokens\n",
    "d_in, d_out = 3, 2\n",
    "mha = MultiHeadAttentionWrapper(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ded1a3a4-2733-4e6f-9f33-81ac5e359bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a acausal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dcfbe1c1-3a2c-43e2-855a-c70b9e04fd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2,5) #A\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "36747133-81e5-40eb-979f-52e27aef953a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969],\n",
      "        [ 0.2093, -0.9724, -0.7550,  0.3239, -0.1085]])\n"
     ]
    }
   ],
   "source": [
    "print(batch_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ce1131f6-781a-40d4-89be-d4e5ec8d9e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x-mean)/torch.sqrt(var+self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e5d1be15-53c0-4be2-a2c0-75c870702229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: \n",
      " tensor([[-2.9802e-08],\n",
      "        [ 0.0000e+00]], grad_fn=<MeanBackward1>)\n",
      "Variance \n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean: \\n\", mean)\n",
    "print(\"Variance \\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "53b6adf0-a443-433b-862c-c02c1923392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0/torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "811dc46b-fd89-4ed4-81a4-1dc574a07749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "#SAMPLE DATA\n",
    "x = torch.linspace(-3,3,100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"f{label} (x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d996d432-52e4-41d0-8500-d187ddece073",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bbdced31-26d7-4d9f-91ae-e7da79aa9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), GELU(), nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3ab24b44-941a-4404-91ea-9e66dc1b6efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 50257, 'context_length': 1024, 'emb_dim': 768, 'n_heads': 12, 'n_layers': 12, 'drop_rate': 0.1, 'qkv_bias': False}\n"
     ]
    }
   ],
   "source": [
    "print(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c1d923-e519-455d-94f9-ad5db413b7de",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">GPT ARCHITECTURE PART 4: SHORTCUT CONNECTIONS</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "28985ac2-cbc7-4f78-8a78-13b59e1b4b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # Compute the output of current \n",
    "            layer_output = layer(x)\n",
    "            # Check if shortcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3b5c6577-b4bc-4780-ba47-b73f7933d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3,3,3,3,3,1]\n",
    "simple_input = torch.tensor([[1.,0.,-1.]])\n",
    "torch.manual_seed(123) # specify random seed for the initial weights\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "33d04106-ca57-4017-9137-13d9a4893bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # Calculate loss based on how close the target\n",
    "    # and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "\n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0840f9ff-13f6-40f8-a3fa-56bb47d825b8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">GPT ARCHITECTURE PART 5: coding attention and linear layers block</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4a20f0a8-636e-4ef9-b31a-beb49b8179c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fe9d7b31-b992-4d8d-bb0f-8463b229443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x) # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forwared block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut # Add the original input back\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9dfe7a2c-f146-4980-913b-3ee8de11312e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768) #A\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "388d2e27-f950-4edb-bcf6-d9619b5cf130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds+pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5fcd1af7-7d3a-4d68-9c9a-c8542c127c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c40e61a5-1e0f-4035-b10b-f2ad8cce1163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.7955e-01,  2.8515e-01, -7.6131e-01,  ..., -4.8374e-01,\n",
      "          -4.2503e-01, -1.7187e-01],\n",
      "         [-6.2581e-01, -3.7480e-01, -9.7020e-01,  ...,  1.9168e-01,\n",
      "          -1.3234e+00, -2.7643e-01],\n",
      "         [ 5.1744e-01,  1.3866e-01,  2.4886e-01,  ...,  3.5054e-01,\n",
      "          -7.7531e-02, -8.0041e-02],\n",
      "         [-2.5664e-01, -6.9693e-01, -9.9479e-01,  ..., -4.4732e-02,\n",
      "           6.1772e-02,  1.3467e-01]],\n",
      "\n",
      "        [[-2.2379e-01,  1.1651e-01, -9.9836e-01,  ..., -1.5730e-01,\n",
      "          -4.4800e-01, -2.8646e-02],\n",
      "         [-8.7227e-01, -3.9389e-01, -1.1099e+00,  ...,  3.3035e-01,\n",
      "          -9.2395e-02, -1.8492e-05],\n",
      "         [ 4.5988e-01, -1.4274e-01, -1.2227e-01,  ...,  2.7490e-01,\n",
      "           5.8297e-02, -8.9931e-02],\n",
      "         [-6.2163e-01, -4.4854e-01, -4.7675e-01,  ..., -3.6519e-01,\n",
      "           3.4402e-01, -3.8154e-01]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6b1ddc11-a5bf-4ae2-a52b-6c5669a26ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 162,419,712\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0b1bc29a-bfcf-4558-b4d4-9e33105a9b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9757befe-87d0-4e01-a551-5e836afd739b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight : 123,822,336\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Number of trainable parameters considering weight : {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9bcd18fb-b520-41be-bdbd-6db65c8b19ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 619.58 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4 #A\n",
    "total_size_mb = total_size_bytes / (1024 * 1024) #B\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "994d8729-2829-4597-babe-7651692b3617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:,-1,:]\n",
    "    \n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1) #(batch, vocab_size)\n",
    "    \n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True) # (batch, 1)\n",
    "    \n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1) #(batch, n_tokens+1)\n",
    "    return idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3050e473-238f-466e-9791-50961bd0521a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded:  [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded: \", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #A\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ae78a2f5-b190-426c-8449-095f9d9c6176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  tensor([[15496,    11,   314,   716, 13240, 11381,  4307,  7640, 16620, 34991]])\n",
      "Output length:  10\n"
     ]
    }
   ],
   "source": [
    "model.eval() #A\n",
    "out = generate_text_simple(model=model, idx=encoded_tensor, max_new_tokens=6, context_size=GPT_CONFIG_124M[\"context_length\"])\n",
    "print(\"Output \", out)\n",
    "print(\"Output length: \", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "96b9e4b8-cc81-419a-9fbb-ec8128e0fcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Laur inhab DistrinetalkQueue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3808cf53-9eb3-4029-b114-127ccce32485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasn refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6456d5ef-77d4-4049-8ca6-bd269bfff03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[16833,  3626,  6100]])\n",
      "tensor([[  40, 1107,  588]])\n"
     ]
    }
   ],
   "source": [
    "print(text_to_token_ids(\"every effort moves\", tokenizer))\n",
    "print(text_to_token_ids(\"I really like\", tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "86025434-9238-4a12-b559-7e019d026903",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c2e7b595-575b-4059-a2f4-f4a51ef448fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b2dfb314-dc22-4a0f-9dcb-5fcf9c243770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDS:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDS:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9724bd8b-4d49-499c-830a-2aecbffdfb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d7490dc6-76db-4c26-9d72-cc8b02c52fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1:  tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2:  tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0,1,2], targets[text_idx]]\n",
    "print(\"Text 1: \", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2: \", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "747c7eb7-5606-44a0-8d08-042995f68e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "652b6e17-7e11-4a8a-b067-9ecd7ee5c3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n",
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "96c6c04c-d934-4539-be5c-a2ba4d9d2949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b7c55d7e-8bc2-4450-9c2f-40146383090b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3bd91e31-af6e-49ef-b89d-dbf812ead096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6bb8cd13-3ff8-40a4-bca5-20f7b4d9fe88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a3a0f031-936c-4ecb-82d0-11b0eddcf2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1a47e96d-6e19-4571-90a9-f69ec0b9734e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# First 100 characters\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5ad548ef-b658-411c-9c23-a55e06784a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20481\n",
      "Tokens: 5146\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ceda4082-4251-4db7-9b23-4b732e494292",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5feafd17-8986-4682-ba15-4781a3088188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7d1db154-6b50-4f44-a36c-344d412c5b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the GPT_CONFIG_124 context_length or increase the training ration\")\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the GPT_CONFIG_124 context_length or increase the training ration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f1fff976-3250-49eb-ad9a-c06d839a5d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "9\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e1fdb484-30cb-4c79-a2d9-70b6d86ed044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "17de2465-2875-40e0-87c4-93c82204913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1a552378-2cb8-45cf-8199-a51c075951c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "dd22a104-c4c3-4a9a-90cf-acd66107520e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758347829183\n",
      "Validation loss: 10.983159065246582\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#\n",
    "# print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "18e1ab0f-70ad-45a2-95d9-93f87e2bb40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0: \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4a5ad11b-ea5e-4d10-a814-997d42c1f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "60e2ad4d-ef97-4529-9fa0-7a33f946d409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "358c051a-c083-45c3-8dd9-c58b09aea86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.781, Val loss 9.932\n",
      "Ep 1 (Step 000005): Train loss 8.111, Val loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.661, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 5.961, Val loss 6.616\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Ep 3 (Step 000020): Train loss 5.726, Val loss 6.629\n",
      "Ep 3 (Step 000025): Train loss 5.201, Val loss 6.348\n",
      "Every effort moves you, and I had been.                                            \n",
      "Ep 4 (Step 000030): Train loss 4.417, Val loss 6.278\n",
      "Ep 4 (Step 000035): Train loss 4.069, Val loss 6.225\n",
      "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step 000040): Train loss 3.732, Val loss 6.158\n",
      "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
      "Ep 6 (Step 000045): Train loss 2.850, Val loss 6.178\n",
      "Ep 6 (Step 000050): Train loss 2.427, Val loss 6.140\n",
      "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
      "Ep 7 (Step 000055): Train loss 2.104, Val loss 6.133\n",
      "Ep 7 (Step 000060): Train loss 1.882, Val loss 6.232\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Ep 8 (Step 000065): Train loss 1.320, Val loss 6.236\n",
      "Ep 8 (Step 000070): Train loss 0.985, Val loss 6.240\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000075): Train loss 0.717, Val loss 6.291\n",
      "Ep 9 (Step 000080): Train loss 0.541, Val loss 6.391\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.391, Val loss 6.449\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Training completed in 1.67 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c6f2fb16-b177-423f-b9dc-fd8778c3fcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAATsNJREFUeJzt3QdYlWUbB/A/G0FAAUUQEdy4cJuoWennyHJUmmXmKC23DTMrSxuaaWaZ2frSr2GW29zmTHPvhRuciKgMQfb5rvs5vIcDogICZ/D/XdcrnP2e18O53+d+xm2j0+l0ICIiIrNka+odICIiortjoCYiIjJjDNRERERmjIGaiIjIjDFQExERmTEGaiIiIjPGQE1ERGTGGKiJiIjMGAM1ERGRGWOgJrIC4eHhsLGxwYEDB0y9K0RUyBioicyEBNp7bePHjzf1LhKRCdib4kWJ6E5Xrlwx/P7HH3/g/fffx4kTJwzXlS5dmoeNqARii5rITFSoUMGweXh4qFa0drl8+fKYNm0a/P394eTkhAYNGmD16tV3fa709HQMGDAAtWrVwvnz59V1S5cuRaNGjeDs7IwqVapgwoQJSEtLMzxGXu/HH39E9+7d4eLigurVq2PZsmWG22/evInevXujXLlyKFWqlLp99uzZd92HBQsWoF69euq+Xl5eaNeuHRISEgy3y2sFBwer/ZH9/Oabb7I9/sKFC+jZsyfKlCkDT09PdO3aVaX4Nf369UO3bt0wdepU+Pr6qtcYOnQoUlNTC3D0icyYVM8iIvMye/ZsnYeHh+HytGnTdO7u7rrff/9dFxYWpnvrrbd0Dg4OupMnT6rbz507J1XwdPv379clJSXpunfvrmvYsKEuKipK3b5lyxb1+Dlz5ujOnDmjW7t2rS4wMFA3fvx4w2vI4/39/XVz587VnTp1SjdixAhd6dKlddevX1e3Dx06VNegQQPd7t271eutW7dOt2zZslz3//Llyzp7e3u133LfQ4cO6WbOnKmLj49Xt//66686X19f3cKFC3Vnz55VPz09PdX+iZSUFF1wcLBuwIAB6rHHjh3TPf/887qaNWvqkpOT1X369u2r3tOrr76qO378uO6vv/7Subi46L7//vsi+38hMgUGaiILCNR+fn66Tz75JNt9mjZtqhsyZEi2QP3PP//o2rZtq2vVqpUuJibGcF+5buLEidke/8svv6hgqZHHv/fee4bLt27dUtetWrVKXX7yySd1/fv3z9P+7927Vz02PDw819urVq2qTgiMffTRR7oWLVoY9k2CckZGhuF2CdClSpXSrVmzxhCoK1eurEtLSzPcp0ePHrpnn302T/tIZCnYR01k5uLi4nD58mW0bNky2/Vy+eDBg9mue+6551R6fMOGDSrlrJH7bdu2DZ988km29HhSUhISExNVqlvUr1/fcLurqyvc3d0RFRWlLg8ePBhPP/009u3bh/bt26u0c2hoaK77HBISgrZt26rUd4cOHdT9n3nmGZQtW1alv8+cOYOXXnoJAwcONDxG0vCS8tf29/Tp03Bzc8v2vLK/8lhNnTp1YGdnZ7gsKfDDhw/n+dgSWQIGaiIr8vjjj+PXX3/F9u3b8dhjjxmuv3XrluqTfuqpp+54jPQRaxwcHLLdJv3WGRkZ6vdOnTohIiICK1euxLp161Qglj5h6SPOSYKn3Offf//F2rVrMWPGDLz77rvYuXOn4aTghx9+QPPmze94nLa/jRs3xm+//XbHc0sfeV72l8haMFATmTlp1fr5+akWcZs2bQzXy+VmzZplu6+0euvWrYsuXbpgxYoVhvvLIDIZQV6tWrUH2hcJkn379lVb69atMXr06FwDtRY0pdUvm4xgr1y5MhYvXozXX39dvZ+zZ8+qwWm5kf2Vke8yiE7eP1FJxkBNZAEkIH7wwQeoWrWqGvEto61lcZPcWpzDhw9Xae0nnngCq1atQqtWrVSglMsBAQEqBW1ra6vSy0eOHMHHH3+cp32Q55BWrqSbk5OTsXz5cjVqOzfScl6/fr1KeUuwlcvXrl0z3F9a9yNGjFCp7o4dO6rn27NnjxpZLoFcAviUKVPUSO8PP/xQpfOlNb9o0SK89dZb6jJRScFATWQBJKjFxsbijTfeUH3GtWvXVlOnZIpUbkaNGqVSwJIKl2lc0k8sgVWC3uTJk1XKWKZEvfzyy3neB0dHR4wdO1ZNkZL+b2lRz5s3L9f7Sit4y5YtmD59uupjl9b0559/rtLnQl5XUuASjOUkRPrDpT9b9lvIbfL4MWPGqHR9fHw8KlasqNLtbGFTSWMjI8pMvRNERESUOy54QkREZMYYqImIiMwYAzUREZEZY6AmIiIyYwzUREREZoyBmoiIyIwxUN/FzJkzERgYqJZXlGUOd+3aVbz/M2ZK5rY++eSTamUpWXlqyZIl2W6X2X6yMIasuSxzbaW04alTp7Ld58aNG2pBC5kPKyUMZc1nWTLS2KFDh9Q8XTn+lSpVwmeffXbHvsyfP1/NBZb7yBxcWdrSkk2aNAlNmzZV61vLIiGylrZxPWptrWtZtlNKOkp9all7++rVq9nuI2UtO3furOYiy/PIPGXjcpZi06ZNavUvKZkpq5XNmTOnRPwNzJo1S61nLp892Vq0aKEWhdHw+BauTz/9VH1PaPPjeYwLyNRVQczRvHnzdI6OjrqffvpJd/ToUd3AgQN1ZcqU0V29elVX0q1cuVL37rvv6hYtWqSqIy1evDjb7Z9++qmq+rRkyRLdwYMHdV26dNEFBQXpbt++bbhPx44ddSEhIbodO3aoak/VqlXTPffcc4bbY2NjdT4+PrrevXvrjhw5oko7StWk7777znCfbdu26ezs7HSfffaZKoEoVZ+k7OPhw4d1lqpDhw6qapa85wMHDugef/xxXUBAgKpipZGSjpUqVdKtX79et2fPHt1DDz2kCw0NNdwulaTq1q2ra9eunSp5Kf9f3t7eurFjxxruI2UlpRzk66+/ro7djBkz1LFcvXq11f8NSFnOFStWqPKgJ06c0L3zzjvqcyPHXPD4Fp5du3apUqr169fXjRw50nA9j3H+MVDnolmzZqr2riY9PV2VGZw0aVIBDrH1yhmopSRhhQoVdFOmTDFcJ6UWnZycVLAVEhjkcVLTWCNlFG1sbHSXLl1Sl7/55htd2bJlDXWHxZgxY1TZQ03Pnj11nTt3zrY/zZs3173yyis6ayG1pOVYbd682XAsJajMnz/fcB+pwyz32b59u7osgdnW1lYXGRlpuM+sWbNU3WbteEot6zp16mR7LSkNKScKJfFvQD5rP/74I49vIZK649WrV1c1y9u0aWMI1PwMFwxT3zmkpKRg7969KmWrkXWR5bJUJKK7O3fuHCIjI7MdO1nLWdKm2rGTn5LubtKkieE+cn85xrIetHafhx9+WC1ZqZElMCUNLGtBa/cxfh3tPtb0fyRLhgpPT0/1Uz6Xqamp2d63pP5l/W7j4yvdAD4+PtmOiyzjefTo0Twdu5LyNyDrocsSqFJ2U1LgPL6FR7pnpPsl5+eMx7hguNZ3DtHR0eoP2PiLTsjlsLCwAh7mkkGCtMjt2Gm3yU/pNzVmb2+vgpHxfYKCgu54Du02qWksP+/1OpZO1umWfj2pPCXVsIS8Nzl5kROdex3f3I6Ldtu97iPB/Pbt2+pkyJr/BqRetQRm6Y+Wfn6p6CVrp0uREx7fBycnP1KzfPfu3Xfcxs9wwTBQE5lpi0QqW23dutXUu2J1atasqYKyZCwWLFigSnZu3rzZ1LtlFS5cuICRI0eqWuTGdc7pwTD1nYO3t7cqXp9zJK1crlChwgMebuumHZ97HTv5KdWfjMmIZBkJbnyf3J7D+DXudh9r+D8aNmyYqnS1cePGbOUc5b1JWjomJuaex7egx05GQctIfWv/G5BWs4x0l5KdMtI+JCQEX375JY9vIZDUtvx9y4wCyZTJJidBX331lfpdsjL8DOcfA3Uuf8TyByy1dI3TkHJZ0mV0d5Kuli9y42Mn6VTpe9aOnfyUQCN/0JoNGzaoYyx92dp9ZBqY9Mdq5AxdWkKS9tbuY/w62n0s+f9IxudJkJZUrByTnOl/+VxKeUrj9y399jIdy/j4SmrX+GRIjosEYUnv5uXYlbS/AXlvUg+bx/fBSRlS+fxJxkLbZDyKTMfUfudnuAAKOAjNqsnUFBmpPGfOHDVKedCgQWpqivFI2pJKRnPKtB/Z5OMzbdo09XtERIRhepYcq6VLl+oOHTqk69q1a67Tsxo2bKjbuXOnbuvWrWp0qPH0LBkZKtOz+vTpo6bNyP+HTCfKOT3L3t5eN3XqVDXy+YMPPrD46VmDBw9WU9s2bdqku3LlimFLTEzMNrVFpmxt2LBBTc9q0aKF2nJOz2rfvr2a4iVTrsqVK5fr9KzRo0erYzdz5sxcp2dZ49/A22+/rUbRnzt3Tn0+5bLMOFi7dq26nce38BmP+uYxLhgG6ruQuaXyhShzSWWqisz5JZ1u48aNKkDn3Pr27WuYojVu3DgVaOWLvm3btmq+qrHr16+rwFy6dGk1bah///7qBMCYzMFu1aqVeo6KFSuqE4Cc/vzzT12NGjXU/5FMN5L5sZYst+Mqm8yt1sgJz5AhQ9SUIgm23bt3V8HcWHh4uK5Tp05q7rnMoX7jjTd0qampd/w/NmjQQB27KlWqZHsNa/4bGDBggK5y5crqPckJjHw+tSAteHyLPlDzGOefjfxTkJY4ERERFT32URMREZkxBmoiIiIzxkBNRERkxhioiYiIzBgDNRERkRljoCYiIjJjDNT3IKsVjR8/Xv2kwsfjW7R4fIsejzGPb3HgPOp7kOUvpUyjLN4vSzBS4eLxLVo8vkWPx5jHtziwRU1ERGTGGKiJiIjMmNXXo5YSivv371fl1Wxt83deEh8fr35eunRJpbiocPH4Fi0e36LHY8zj+yBV26R0bMOGDVUJ0Hux+j7q3bt3o1mzZqbeDSIiojvs2rULTZs2RYluUUtLWjsYvr6+pt4dIiIiXLlyRTUitRhVogO1lu6WIO3v72/q3SEiIjLIS5esSQeTbdmyBU8++ST8/PxgY2ODJUuWZLtdsvLvv/++CrKlSpVCu3btcOrUKZPtLxERUXEzaaBOSEhASEgIZs6cmevtn332Gb766it8++232LlzJ1xdXdGhQwckJSUV+74SERGZgklT3506dVJbbqQ1PX36dLz33nvo2rWruu7nn39W+Xxpeffq1auY95aIiKj4mW0f9blz5xAZGanS3RpZJax58+bYvn07AzURFYn09HSkpqby6NIDcXBwgJ2dHaw6UEuQFjlHxMll7ba7rb1rvDa3Ns+RiOheJIsn3y0xMTE8UFQoypQpgwoVKqgxWFYZqAtq0qRJmDBhQtE8eXoasH4CENQGqJ7V0iciy6cF6fLly8PFxeWBv1ypZJ/0JSYmIioqSl1+0KnBZhuo5SxEyMotxm9SLjdo0OCujxs7dixef/11w2VZVax27dqFs1O7vgf+/QrY9z9g0CbAs0rhPC8RmTzdrQVpLy8v/m/QA5OZSkKCtXyuHiQNbrZrfQcFBalgvX79esN1soynjP5u0aLFXR/n5OSkKl1pm5ubW6GdIc23aY+zTsFAUiwwrzeQfKtQnpuITEvrk5aWNFFh0T5PDzrmwaSB+tatWzhw4IDatAFk8vv58+dV2mnUqFH4+OOPsWzZMhw+fBgvvviimnPdrVu3Yt/XyLgkjFtxCs/FDkWCgxcQdQxYNkwieLHvCxEVDaa7yRw/TyYN1Hv27FELkssmJGUtv8siJ+Ktt97C8OHDMWjQILUWqgT21atXw9nZudj31dejFD7uVg9X4Ym+CcOQYWMPHF0MbPuy2PeFiIhKDpMG6kceeUSllHNuc+bMMZyNfPjhh2qQhyxy8vfff6NGjRom299nGvvj2SaVsCejJibb9NdfKYPLTmel54mILF1gYKBaxyKvNm3apL6vi3rE/Jw5c9RI6pLGbPuozdWErnUQ7OuO7xIfwfpSHQBdBrBgAHDjrKl3jYhKGAmO99rGjx9f4KqDksnMq9DQUFVkQta6oMLHQJ1Pzg52+KZ3I5R2csDgm8/jkmsdICkGmPcCkJJQBP9FRES5k+CobdIClgG0xte9+eabhvtKtjItLS1Ph7JcuXL5Gljn6OhYKPOFKXcM1AUQ5O2KKc/URwoc8NT1wUh29gaijgJLh3JwGREVGwmO2iatWQmU2uWwsDA162XVqlVo3LixmhGzdetWnDlzRi3LLItHlS5dWo3/kW7Fe6W+5Xl//PFHdO/eXQXw6tWrq0G+d0t9aynqNWvWIDg4WL1Ox44d1cmDRk4aRowYoe4nU+LGjBmDvn375nuw8KxZs1C1alV1slCzZk388ssv2U5OJKsQEBCg3r8MRpbX1HzzzTfqvci4JzkezzzzDMwRA3UBdarniwEtg9TgskFJI6CzzRxcJvOsicg6Fq1ISTPJJq9dWN5++218+umnOH78OOrXr68G5T7++ONq6uv+/ftVAJUqhjLb5l5kIamePXvi0KFD6vG9e/fGjRs37np/WfBj6tSpKnBKpUR5fuMW/uTJk/Hbb79h9uzZ2LZtm5p+m7OC4v0sXrwYI0eOxBtvvIEjR47glVdeQf/+/bFx40Z1+8KFC/HFF1/gu+++U5UX5fnr1atnGMwsQVvGQZ04cUINVH744Ydhjsx2wRNL8HanWth/4SY2n6+Gb70GYnDCLGDzFKDBC4ArF00gsmS3U9NR+/01JnntYx92gItj4Xw9SyD6z3/+Y7js6empqhZqPvroIxXwpIU8bNiwuz5Pv3798Nxzz6nfJ06cqCob7tq1SwX63MjcYal8KK1dIc8t+6KZMWOGWqBKWuni66+/xsqVK/P13qZOnar2a8iQIYaZQzt27FDXP/roo+rkQLILUjNC1t6WlnWzZs3UfeU2qcj4xBNPqMxD5cqVDTOQzA1b1A/A0d4WM59vhLIuDph8vRU2+vQFBqxmkCYis9GkSZNsl6VFLS1bSUlL2lnS0tLavl+LWlrjGglw0h+uLZGZG0mRa0FayAqT2v1jY2PVKpNa0BSycpek6PPj+PHjaNmyZbbr5LJcL3r06IHbt2+jSpUqGDhwoDoh0frp5eRFgrPc1qdPH9W6lyyAOWKL+gH5lSmFL55tgP5zdqN/RAd8GVkWXfWrnxKRBSvlYKdatqZ67cIiQdWYBOl169apVme1atXUUpfSN5uSknLP55EWqTHpk87IyMjX/QszpZ8XlSpVUmlt6YOX9ywt7ylTpmDz5s2qFb1v3z7Vv7527Vq1fof0Z8uId3ObAsYWdSF4pGZ5DHu0mvp97KLDOB0VD5zfCax8i4PLiCyUBBZJP5tiK8rR09IfLOliSTlLf62khsPDw1GcZOCbDN6SoGi83roEzvwIDg5W78eYXDau7yAnItIHL6l6CcpSJllWuhT29vYqLf7ZZ5+pvnc5Dhs2bIC5YYu6kIxqVwN7I27i3zPXMebnTViQ/ApsUhMAnzpA476F9TJERA9ERjkvWrRIBS85IRg3btw9W8ZFRVadlGqH0qqvVauW6rO+efNmvk5SRo8erQa4Sd+yBNy//vpLvTdtFLuMPpcTgObNm6tU/K+//qoCt6S8ly9fjrNnz6oBZGXLllX943IcZOS4uWGLupDY2drgy14NUd7NCXujbbHQcyB0tbsCdZ8urJcgInpg06ZNU4FJFimRYN2hQwc0atSo2I+sTMeSwWlSw0EKLUlfuexLfpaI7tatG7788kuVxq9Tp44a3S2jyGXVSyEp7B9++EH1W0sfuwRwCeYyHUxuk6D+2GOPqZa5DHz7/fff1fOYGxtdcXcaFLOLFy+qfooLFy7A39+/yF9v17kbeO6HHUjPyMDEbvXw/EOVi/w1iejByBLFUhRIqvaZopYAQbVmJWBKC1lGolv75+piPmITW9SFrFmQJ0Z3kNSJDcYvP4Yjl2L1/dT7fgZSzHNEIRFRcYuIiFCt3ZMnT6o+48GDB6ug9vzzz/M/IwcG6iIwqHUVtAsuj5S0DAz+bS+Sl70OLBuu36w7gUFElCe2traqD1lWRpPUtARrSU1Lq5qy42CyImBra4PPezRA5xn/4MKN2/gqsh7etLWHzZEFgF8DIHR4UbwsEZHFkLRvzhHblDu2qIuIh4uDKt7haGeLmed8sL3q6/ob1r0PnNEvb0dERHQ/DNRFqL5/GYx7Uj+fr8/RBoiu+nRWWcybEUX50kREZCUYqIvYC80D0CXED+kZwFPneyDVpwFw+wbwR28OLiMiovtioC5iMnl/0lP1ULWcK87HZ+ANmzehc/EGIg8Df43g4DIiIronBupi4Opkj1kvNFbr9y4Lt8X8Kh8DUhbz8Hxg+8zi2AUiIrJQDNTFpIaPGz7pXlf9PmavO043fEd/w7pxwNnNxbUbRERkYRioi9FTjfzxXLMANZW65/56SAzuoR9cNr8fB5cRkcnIkpujRo0yXA4MDMT06dPv2623ZMmSB37twnqee5GqWA0aNIClYqAuZh88WRt1/NxxIzEVL13vjQzfzMFlC/qzv5qI8kXW6u7YsWOut/3zzz8qCEpVqPySqlaDBg0qlmB55coVdOrUqVBfy9owUBczZwc7Nb/azdke288n4mvvD4DydYD2H8upZXHvDhFZsJdeeknVWZZ1o3OS4hRNmjRRxSjyq1y5cqraVHGQMptOTk7F8lqWioHaBCp7uWLKMyHq92m7b2N16wVA5VBT7AoRWbAnnnhCBVVZitPYrVu3MH/+fBXIr1+/rqpUVaxYUQVfqUEtVaLuJWfq+9SpU6ocpBSWkFrPcnKQWzWsGjVqqNeoUqWKKp+ZmpqqbpP9mzBhAg4ePKha+bJp+5wz9S1LiUpFKylHKVWuBg0apN6PRmppS9UsqZjl6+ur7jN06FDDa+W1AMiHH36oimHISYK09FevXm24PSUlBcOGDVPPL+9ZymJKSU4hdawkOxAQEKAe6+fnhxEjRqAocQlRE+lYtwJebhWEH7eew+gFhxHs56ECOC7tAw7+DnT8FLC1M9XuEZEmJSH/x8LOCbDL/HpNTwPSkwEbW8Ch1P2f19E1zy9jb2+vykRK0Hv33XcNtZwlSEsdZgnQEuQaN26sAqm7uztWrFiBPn36oGrVqmjWrFmegtpTTz0FHx8f7Ny5E7Gxsdn6szVubm5qPyRwSbAdOHCguu6tt97Cs88+iyNHjqhgqNWK9vDwuOM5EhISVKlLKXsp6feoqCi8/PLLKmgan4xs3LhRBVH5efr0afX8EmzlNfNCSmN+/vnnqiym1LL+6aef0KVLFxw9elTV6/7qq6+wbNky/PnnnyogS4Ur2cTChQvxxRdfYN68eaokZmRkpDoBKbGBWj5ocuYixb7lYMgHQM6m3nvvvXwVFzdXYzrVwv4LMdgbcRNDftuHhQPqwfm3Z4DE64CbL9A6c9lRIjKdiX75f0yPOUCd7vrfw/7SDxit3ArovyLrPtPr6f/Wcxofm6+XGjBgAKZMmYLNmzcb6jBL2vvpp59WwVC2N99803D/4cOHY82aNSoI5SVQS2ANCwtTj5HvYDFx4sQ7+pXle9m4RS6vKcFMArW0jqXetJxYSKr7bubOnatKQ/78889wddWfsHz99deqL37y5MnqZEFIPW253s7ODrVq1ULnzp2xfv36PAdqaY3LiUuvXr3UZXluCfqSRZg5cybOnz+vAnarVq1UrJEWtUZuk/fQrl07ODg4qECel+NotalvOXizZs1S/yHHjx9Xlz/77DPMmDED1sDBzhZfP98Qnq6OOHo5DuNWRUD3+FT9H3SzvH3giKhkk0AVGhqqWoVCWpgykEzS3lqDR+o7S8rb09NTBUwJuhJw8kK+e6WAhhakhbR4c/rjjz9UFSwJYvIaErjz+hrGrxUSEmII0qJly5aqVX/ixAnDddKSlSCtkda1tL7zIi4uDpcvX1bPa0wuy+sLaRAeOHAANWvWVGnttWvXGu7Xo0cP3L59W6X35cRg8eLFSEtLQ4ltUf/777/o2rWrOlvSztKkb2XXrl2wFr4epfBlrwbo+9MuzN97EQGe9TC8719SgivrTjKfywoyCEQW6Z3LBUt9a2o9qX8OSX0bG3UYhUWCsrSUpTUorWlJa7dp00bdJq1tSfVKa1GCtQRBSV1LP2xh2b59O3r37q36oSV1La14aU1LerkoODg4ZLssrV4J5oWlUaNGqjb2qlWrVEahZ8+eqgW9YMECddIiJw1yvfTVDxkyxJDRyLlfJaJFLWeJks6QwuJC+gG2bt16z6H8ycnJ6oxJ2+Lj42HuWlcvhwld6qjfP193Egv3G30xbJkKrHyTU7eITEX6jPO7af3TQn6X64z7p+/1vAUggUTqO0vqWNLGkg7XugellKQ0eF544QXVWpWWoPadmhdSH1r6Z2UalWbHjh13NKokPSz95DLSXNLGERHZCw85Ojqq1v39Xku+56WvWrNt2zb13qR1Wxikn16yAzlLbMplGShnfD/p+/7hhx9UtkD6pm/cuKFuk1S+pOOlL3vTpk3qREX65Utki/rtt99WwVZSO5LmkP/kTz75RJ253Y2MzJOzOkvTp0UgLsbcxnebz2LMwkOo4OGMlm5XgQ0fS5Nafzbe6TO2rInoDpJqlqAyduxY9Z0pqVuNBE1pCUowlb7dadOm4erVq9mC0r1IS1JGc/ft21e1HOX5JSAbk9eQNLe0ops2baoGrElK2JhkRKWVKillGW0tA81yTsuS7/YPPvhAvZaMT7p27ZrKFMjgN61/ujCMHj1avY5kHmQQmmQhZL9+++03dbscI0mny0AzOUmQwXmS0i9Tpowa1CaxqHnz5mqEu4yhksBt3I9dolrUMthBDpycJe7btw//+9//1CAA+Xk38kGVUYnaduzYMViKMR1q4ckQP6Rl6PDqL3sRpqsEdP1af+Ou74HVY9myJqK7pr9v3rypUs/G/cnSVyypXLleBptJwJHpTXklgUqCrvTLyqApGYUtDSZjMmL6tddeU6OzJfDJSYFMzzImg9tkcZZHH31UTSnLbYqYBD7pP5eWqwT8Z555Bm3btlXjlAqT9Du//vrreOONN1R3gIxGl1HecsIh5CRCxkNJdkD2Izw8HCtXrlTHQoK1tLKlT1vmqEsK/K+//lLTxIqKjU4mhZkp6QuQVrXMkdN8/PHH6gxGRiHmhSwEIM8jqRs5izN3yWnp6PPfXdh17gYquDtj8dBQ+J7+U19pS7QYxsVRiAqZjDSW1l5QUJCaN0tU1J+r/MQms25RJyYmqjMYY5ICL8xBA+bGyd4OP/RpgmrlSyMyLgn9Z+9GXJ3ngSe+0N9h+9fA3x+wZU1EVEKYdaCWznpJsUh/h6QeJP0ifQfdu2fOT7RSHi4OmNO/Kcq5OSEsMh6Df92LlAb9AJm6JbZ9Caz/kMGaiKgEMOtALfOlpY9Chr/LaECZQP/KK6+oOYHWzr+sC2b3awoXRztsO30dby86BF3Tl/UDysTWacDGiabeTSIiKmJmPepbOvRl7t/9yq1Zq7oVPVQBj5f+tweL9l1CxTKl8Eb7V4CMdGDNWGDLZ4CtPfDIGFPvKhERlcQWNQGP1CyPid3rqkMxY8Np/L7rPNBiiH5Amdg0EdgyhYeKiMhKMVBbgGebBmDEY9XU7+8tOYKNJ6KA0OFAu8z54jLX+kr+a84SUXbWPFCVLPfzZNapb8ry2n9q4FJMEhbuu4ihv+3DH4NaoF6rUYAuHXDxBnzzX3OWiLJWzZIZJrIGtMzxlcvWUPiHTENmPcsSrbJgi3yu5PP0IBioLYR8aUx6qh6uxiVh6+lo9J+zG4uHhKJS6zey3zEtGbBnEXai/JAvU5nrKstkSrAmKgyygItU18o5zTi/GKgtiKO9LWa90Ag9vt2upm31m70LCweHooxL5tlaQjTwvy5Aoz7AQ4NNvbtEFkVaPfKlKpWQ7rcmNdH9yJofUtazMDIzDNQWxs1Z5lg3Q/dvtuHMtQQM+nkvfn6pGZwd7IAjC4Goo8DW6UCD5wHnOwuzE9HdyZeqVEAqqipIRAXBwWQWSAp2zO7fFG5O9tgVfgNvzj+IjAwd0GwQ0G480G8FgzQRkZVgoLZQtSq449s+jeFgZ4Plh65g8uowfWWtVq8B3voR4kp8pCl3k4iIHhADtQVrWc0bk5/Wj/b+bstZ/Lw9PPsdTv8NfNkA2PeLaXaQiIgeGAO1hXuqkT/ebF9D/T5+2VGsPWrUgj67CUi7DSwbDvzcFdj7PyBRX/iciIgsAwO1FRj6aDU816wSpJt6xLz92H/+pv6G/3wEPCQlQnX6oC2lMqdWB359Gtj/G3A7xtS7TkRE98FAbSUjVT/qWheP1iyHpNQMtTZ4eHSCvs+640RgxH6g7fuATz0gI02fEl86RB+05/YCDv0JJMeb+m0QEVEubHSyhIoVy09xbkuXkJyGXt/vwOFLsQj0clFzrL1K51j8JPoUcHQxcGQRcO141vV2TkD1/+jrXpcuX+z7TkRUklzMR2xii9qKuDrZ47/9msC/bCmEX0/Eyz/vwe2UHAs3eFcH2rwFDN0BDNkBPPwW4FUNSE8GwrcCpcpm3TfqOJB6u9jfBxERZWGgtjLl3ZzVgigepRyw/3wMRs7bj3TpvM71zsHAY+8Cw/YAr24FuswA7DIXepBEy9yewJRqwMU9xfoeiIgoCwO1FapWvjR+eLGJWnJ07bGr+Gj5MbVI/F1JX3aFekDtLlnXxV/RB2vZytfOuj5sJXByLZCWUrRvgoiIFC4haqWaBXliWs8QDJu7H3P+DUf49QSM7RSMmhXc8vYE7n7AqMPAzXOAo0vW9esnANfCAOcyQPATgH8z/ajyjHRAl5G1GS6nA7We0KfcxdWj+v7xspWBRi9mPe/f44HkW1mPEd419M8vlcFYaISISigGaiv2RH0/XL+VolrUm05cw5aT19CjcSVVMlOWIb0vaWl7VslemSvoYf1c7IQoYP+v+u1+ygZmBeprJ4B/pgKBrbMHapnjffsuc7ztHAHfEMC/adbm4a/fPyIiK8dR3yXAuegEfLY6DKuO6BdDcXawxcDWVfBKm6oo7VSAczVpLUdsA44uAWIvArZ2gI2tfjP8bpd1uclLgH9j/WOvHNTP4faqCjR/Jes5//kcSE3Kekx6KhB5GLi4G0iMvnMf3HyBbt8AVR8r8HEhIrKEUd8M1CXI3oibmLjyuPopvFwdMapddfRqFgAHOzMdriB95JJ+lwFtErQv7AKuHtHPBx+8HfDJ7D/fMxvYO0ffSm/6kqn3mogsjU6nn+WSmgik3AJSEoAUo9/leunyq9G+2AM1U98lSOPKZbHg1RZYczQSk1efUC3tcUuPYva2cIzpVAvta/sUSu3UQqWl32Wr31N/nfzxXDkAlKuZdb+If/XXJXTKui7+KrB8FODfRN/X7dcQcCpd/O+BiIpOWoq+2ywhGki8rt+SYgCv6kBQa/19kuKAVW/pA27Pn7O6zVa8ARz/Kysgy3ibewloUWiBOj8YqEsYCcQd6/qibbAPft91Hl/+fQpnoxPwyi970TSwLMY+HoxGAUZzqc2RDG6rHJr9unYfADU7Aj51s66TFviJlfpNSFq9fB394DSZL+7klsvmDlSSAXJGZ9nmdvJCZK0yMvRB9vZNffeY5tCf+m4zGR+jgrEWlG8AyXG5P1fDPlmBWhz8Xf8zLQlwKKX/XQaw3rp652MdXABH18yfpfXfOXJZvj9MgKnvEi4+KRXfbT6LH7eeVcuPisfrVcBbHWoh0NsVFu1mOBC2Qp8ul9R53MX7P8a+FPCeUWGTuc8C4dv0K7bV76G/7tI+YOs0fVBXm1Gg1/6o5YvAQf7QS2X+wZfS96sz6JM1yXkiezNCH0BVCjkzjWzYtLRy5u/SgpWALONMtO6qmPPA9HqAvTPwbmTWc//+PHBixd33Q07CXbyyNklRV3kEaD4oa1zN9q/1f4sSwLVZJDfO6lvZ6m/UNSs42xZ9VyBT35Rnbs4OeLNDTfR+KADT1p7Egn0XsfJwJNYdu4rezStjRNvq8HR1tMwjKqPNWwzVbyLusr6VHX1Sv7b5HVucfoS5MUmZpcQDdkbJp5gIfbosv8ZFZy0os2wEcGot8Nh7QMMX9NdFhQEbPsoM8toZvdHvchIgqXt1QqCdHJQG3CvqB+CR6UlAkGI3WgrWeJOgJGMrtAAnJ34VMwdZXj0G7PkvUCYAaDky+7RFVfEuc00D9VM9QdbzZLtNB9R7BqjRQX/79TPAxk8A13JAp8lZz7vuA32Q0j9J5uO1i7rs16en6AOrPK8WUKNPA9+20n8+x5zLeuyyYcC5Lfk7ZqXKAMh8Xgmy2pLG8pra1NCanQCvKtmDsYt35k9PfWC+V3CVvw/j46oxntVixsw+9X3p0iWMGTMGq1atQmJiIqpVq4bZs2ejSZMmpt41q+LrUQpTeoRgQKsgfLoqDJtPXlPzrxfuvYghj1ZD/5aBcHaw8GAgc8Nrd83fY3r9pk/FyZeCpkJ94PGpuQd6bdCJajEY/S6j2LUgLRKu6ReVkes18ZeBsOX5f1+jzwCu3llf7DIaP3QY0PTlrBOUzZMzA727UbDP/CmtCwkgEmTUz8yteoesL0rJSkQe0r93rWtAAsjuH/X3lfeR23PY2utbR/aOmT+dgPq9AHffrC98mZcv8+pl0R0t/Rl9Qn9f9Rhn/QmU+mlf/GlYdbJUKutk6uRqfXYk5Fn9dRLMZjbXT1lUFenyWD5BumC0QC0tSTmWfo2yB5RD8/OWCTImx1EL1HJycGSh/gTAOFBLNT0Z05EfFRtl/S7/n1JCV9Y9MFbaR3/iKCeX2kmmcVbJ+DppwbqUzZ5OltuMT2g1jfqgJDPrQH3z5k20bNkSjz76qArU5cqVw6lTp1C2rJn3oVqwYF93/G9AM2w9Fa1GiB+7EofJq8Pwy/ZwvNG+Jro3rAhb2xLUZytn67IZk74z4/6zvMi5MtzjU4A2Y/RfahpZ4EVS7Co1mLmp341Gn0qfmpwUpGgnB7f0AVcjQVlGycv9Dddd0Y+Iz6/XjmYF6mNL9anDlqOyArUEMWmt5ZekJLVAHfaX/uSiQW/9dDsh7/ubh3J/rEz7kwAugVtNA7TR/4QN8MxPWX2Shxfon7fqo/qlcTXftNCfVOR8rLqcmUKVEyutBSyBqNdcoFZn/eNlxsHfH+jXAdACtTyPdn+NtPDUZ8eoBSjjIlQAyvz7MV7xTz5P8nmQEwBjocP1/8/qIbKfNtl/aq9vfJ3x+A2PSkDHyXcOopSTAdlnw+Nx9+eVYy2fAxmcpXHzA0Ye1AdbY0//iAcir5kzSJN5B+rJkyer4evSgtYEBQWZdJ9KilbVvbF8eCssOXAJU9ecwOXYJLwx/yB+3HoO7zxeC62rlzP1LlqWnH3TsmCLbDmvazLgwV7n0Xf189Y9jE4A3HyAR97JHtxVsM/8KQvZyJejpAelBWzrkPnT6OvBpw4Q3EW/PrzGyQNo3D/rvobHG12WFrYM3pH0qfyU15I0rKZ0BaBS8+wnPnJfCWxyX3mMli4WsmqddhKTkzxOI+8r9gKQkBmMNNLtYfx8eWFct10K2IQ8pz8exnr/mdlC1AJyPr9aZUGgR9+58/qHXsUDkf/73J6j7lMP9rzy/qRriYqFWQ8mq127Njp06KA63Tdv3oyKFStiyJAhGDhwYJ6foySVuSwqSanpKg0+c+NpxCfpv+QerlEOYzvVUi1woiKlgn1yjoCfkpl21WUuO6vTp88llS9kqo6MJZCTCe9qWc8VsT1rmVvjxxou6/QtdkMr2FOf5iUqZFaz4Imzs36Zy9dffx09evTA7t27MXLkSHz77bfo27dvro9JTk5Wm3EftwR8BuoHdyMhBTM2nMKvOyKQmq5TjcS2tcojxL+MCtjBfu7w83A2v7nYRERmxmoCtaOjoxo09u+//xquGzFihArY27dvz/Ux48ePx4QJE+64noG68ERclyVJT2DF4St33CblNYN93fSB29cdtX3dVTUvix+IRkRUiKxmepavr69qDRsLDg7GwoUL7/qYsWPHqhZ4zhY1FZ7KXq6Y2bsRBl+KxfYz13H8SpwadHY66hZib6dix9kbatPY2dqgajlXFbSDjbZybplzGYmIyDIDtYz4PnHiRLbrTp48icqVK9/1MU5OTmrTxMXdZdUaemB1K3qoTZOclq6C9fEr8Sp4awE8JjEVJ6/eUtuSA5cN95dArQ/aboYgXsXbFfbmuu44EZGlBGppqks/pNZc37VrF+bOnataroMGZa4EUwhee+01hIaGYuLEiejZs6d6ne+//15tZH6c7O1Qx89DbRrpWYmMS8oM3PE4dlkfwM9dT8C1+GRci9eX39Q42tuipo8+cP+ntg8erVVetciJiEqqAvVRt27dWgXkPn36IDIyEjVr1kSdOnXUHOfhw4fj/fffL7QdXL58uUpny3PL1CxJa3PUt+VLTEnDiUhpecfj2JVY9TPsShwSUtKz3a9imVJ4vnkAejapxFQ5EVmNIh9MJguO7NixQwXor776Cn/88Qe2bduGtWvX4tVXX8XZs9rSdKbH6VmWIyNDhws3E1WLe3f4TSzcd1GlzYWDnQ061fXFCw9VVsVDOLKciCxZkQ8mS01NNfQD//333+jSpYv6vVatWrhy5c6RwER5ISueyUA12aTC1+gONbHi0BX8ujMC+8/HYNnBy2qT1PgLDwWgW8OKaq1yIiJrVqBRO5LmlrnM//zzD9atW4eOHTuq6y9fvgwvr8xF1YkekEzperqxPxYPaalWSXuuWSWUcrDDiavxqo72QxPX493Fh1ULnIjIWhUo9b1p0yZ0795djaiWhUd++ukndf0777yDsLAwLFq0COaCqW/rItO/Fu+7iF92RODMtQTD9U0ql1Vp8U71KqhBbUREKOkLnqSnp6tAbVwgIzw8HC4uLihfvjzMBQO1dZKPrczVllXS1hyNRFqG/mPs5eqIHk0qoXfzAFTyzCwoQURU0vqob9++rb4otSAdERGBxYsXq8VIZG1uoqImg8laVPVSW1RcEubtvoC5O8+rqWDfbj6D77acwaM1y6u+7DY1OMWLiCxXgVrU7du3x1NPPaVGeMfExKhBZA4ODoiOjsa0adMwePBgmAu2qEuOtPQMrA+LUq3sf05FG673L5s1xcu7NFdDIyLLik0FGky2b98+NZdaLFiwAD4+PqpV/fPPP6vpWkSmICuadahTAb+81Bwb33wEL7cKUmuPX7x5W61NHjppA0bO24+9EVnLmxIRmbsCBerExES4uenLycncaWld29ra4qGHHlIBm8jUgrxd8d4TtbHznbaY8kx9hFQqg5T0DCw9cBlPz9qOoXP34Wpckql3k4ioaAJ1tWrVsGTJEtVkX7NmjUqFi6ioKLi7sz4xmdcULxlctnRoS/w1rBV6NPZXS5LK/Oy2n2/G7G3nVMqciMiqArUsEfrmm28iMDAQzZo1Q4sWLQyt64YNGxb2PhIVinr+HpjSIwTLhrVEg0plcCs5DRP+OoauM7fhwIUYHmUiMksFnp4la3zLKmQhISEq7S2kaIa0qGVwmbngYDK623Klv+8+j8mrwhCXlAYbG6gpXaM71FL92kREFj+P2vjFxP1eyFQYqOleom8lY+KK41i0/5K6LKPC3+scjK4N/LieOBFZ7qjvjIwMfPjhh/Dw8FC1oWUrU6YMPvroI3UbkaWQwDzt2QaYO7A5qpZzVYF71B8H0PvHnThz7Zapd4+IqGCB+t1338XXX3+NTz/9FPv371eb1IyeMWMGxo0bx8NKFie0qjdWjXxYFQJxsrfFv2euo9P0fzBt3UkkpWYvvUlEVJwKlPr28/NTRTm0qlmapUuXYsiQIbh0SZ9GNAdMfVN+nb+eiPeXHcGmE9fU5cpeLviwa120qVGOB5OILCP1fePGjVwHjMl1chuRJQvwcsHsfk0xq3cj+Lg7IeJ6Ivr+tItzr4nIJAoUqGWkt6S+c5Lr6tevXxj7RWTytcQ71fPF+jcewYCWQbC1Qba51+mZRUCIiMwy9b1582Z07twZAQEBhjnU27dvV034lStXGpYXNQdMfVNhOHIpFu8tOWKYb123ojs+6VZPrXhGRGR2qe82bdrg5MmTqia1FOWQTZYRPXr0KH755ZeCPCWRWatb0QOLBofik+514e5sjyOX4tDtm20Yt+SIqpFNRFRUHngetbGDBw+iUaNGqla1uWCLmgrbtfhkTFqZfe71uCeC0SWEc6+JyExa1EQlWTm3rLnXVTLnXo+cdwAv/HcnDl2MUaueEREVFvtCeyaiEjn3ujV+2HIWMzacxrbT19Hl623wLu2IVtW80bp6ObSu7o3y7s6m3lUismAM1EQPwMneDsMeq44uIRUxeU0YNoZFIfpWCpYcuKw2UauCmwrYEribBXmqil5EREUSqGXA2L3IoDKikjr3eubzjZCSloF952/in1PX8M+paBy+FIuwyHi1/fDPOTja26J5kKchcEsQl6lgRESFEqhlbe/73f7iiy/m5ymJrIoE4oeqeKltdAfgRkIKtp2ONgTuK7FJ6qdsQJjq724tafIa3mhVrZy6TERUZKO+i5qsLT527FiMHDkS06dPz9NjOOqbzIX8qUmhjy0n9YF7x9kbuJ1jHfFgX3c8nNnabhJYlmlyIiuVn9hkMX3Uu3fvxnfffceVz8hiSYq7Wnk3tQ1oFYTktHTsjZA0uT5wy9zs41f023dbzsLZQdLkXoY0eQ2f0kyTE5VAFhGob926hd69e+OHH37Axx9/bOrdISq0gWgycly2MR1rqWlekibXWtxR8cnYfPKa2oDjKi0uo8lDq3qhZTVv+JUpxf8JohLAIgL10KFD1ZKl7dq1u2+gTk5OVpsmPj6+GPaQ6MHJwildG1RUm6TJT169pQL2llPR2Hn2ulpoZfH+S2oTMoe7ZVVvFbRbVPGCh4sD/xuIrJDZB+p58+Zh3759KvWdF5MmTcKECROKfL+IijpNXrOCm9pebl1F1cSW0eTS4pb52rKwytlrCWr7ZUeEKhpSr6KHCtrS6m5Umf3bRNbCrAeTSSd7kyZNsG7dOkPf9COPPIIGDRrcdTBZzha11MauXbt2njrsiSyFrC8urWwJ3FtPR+PMtYRstzvZ26JpoKcK3C2reaGOnwfsJJoTkcUNJjPrQL1kyRJV+MPOLmuBCFlHXFobtra2KiAb35YbjvqmkiAyNimztR2NbWeicTUu62RVeJRyUH3boZkt7kAvFw5MIzIhqwnU0r8cERGR7br+/fujVq1aGDNmDOrWrXvf52CgppI6DWzrKQna17HjzHXEJ6dlu0/FMqVU4G5VXR+4vUpz/jZRcbKa6Vlubm53BGNXV1d4eXnlKUgTlfRpYP1aBiEtPQOHLsXi38w0+b6IGFyKuY35ey+qTdLkb3eqhb4tAmHL9DiR2THrQE1ED87ezhaNAsqqTdYlv52Sjt3hN1SaXKZ+yfKmE/46hr+PX8XUHiHw9eC0LyJzYtap78LA1DfR3cmf/687IvDJyuNISs2Au7M9PupWl7W1iYoY61ETUZ7T5H1aBGLliNYIqVQGcUlpqrb2sN/3IyYxhUeRyAzYmnoHiMj0qpQrjYWvtsBr7WqoaVwrDl1B+y+2YNOJKFPvGlGJx0BNRIa+7JHtqmPxkFC16pksYdpv9m6MW3IEiSnZR40TUfFhoCaibOr7l8GK4a3RLzRQXZaVzzp/tRX7z9/kkSIyAQZqIrpDKUc7jO9SB7+81AwV3J1xLjoBz3y7HdPWnkBqegaPGFExYqAmoruS8pprRj2sRoGnZ+jw1YbTeOqbf3E6isVuiIoLAzUR3ZNU5frquYaY8VxDtRTp4UuxKhU+e9s5ZGRY9exOIrPAQE1EefJkiJ9qXbeu7o3ktAy1SMqLP+3CldjbPIJERYiBmojyrIKHM34e0Awfdq0DZwdbtSRphy+2YOmBS2rxFCIqfAzURJTvRVJebBGIFbJIir8HF0khKmIM1ERUIFXLlcaCwaEY1a66YZGUDtO3qPXDiajwMFATUYE52NliVLsaWDRYv0iK1MHu+9MuLpJCVIgYqInogck64bJISt8WlbMtkrLu2FWkpHHeNdGDYJlLIiq0RVImdK2LdrV9MHr+IbVIysCf98DN2R7/qe2DzvV80aq6N5zs7XjEifKBgZqIimSRlK82nMJfBy+rNcMX7bukNjcnfdB+vJ4vWtdg0CbKC9ajJqIiIwui7D1/Uw00W3XkiurD1kjQbqcF7erecHZgS5tKjosXL6JSpUq4cOEC/P3973lfBmoiKragvU+C9uErWHU4EpFxSYbbSkvQDi6vgvbDNcoxaJPVu8hAXbCDQUTFF7T3X5CWdqRqaV+JzR6022YG7TYM2mSlGKgLeDCIyFRBOwYrVUv7Ci4bBW1XRzu0Ddanxx+pyZY2WQ8G6gIeDCIyfdA+cDEGKw9dUYE7Z9B+LFhGj1fAIzXLMz1OFo2BuoAHg4jMh6wdfiCzpb3ycCQuxWQV/yjlYIcmgWXRoqoXWlTxQr2KHrC347IQZJ2xidOziMhs1xRvGFBWbe88HoyDF2NV0JYR5BK0/zkVrTatX7upIXB7o7afu1rWlMgaMFATkUUE7QaVyqhtbKdaOHE1HtvPXFfbznM3EHs7FRtPXFObkEVWmgd54qEqXip4B1dwhy0DN1koBmoisrigXauCu9r6twxCeoYOx6/EYcdZfeDede4G4pPS8PfxKLWJMi4OKnBLmrxFVW/U8CmtnofIEph1oJ40aRIWLVqEsLAwlCpVCqGhoZg8eTJq1qxp6l0jIjMhKe66FT3U9nLrKkhLz8DRy3HYnhm4d4ffQExiKtYcvao24eXqqFrbD2X2cVct58rATWbLrBc86dixI3r16oWmTZsiLS0N77zzDo4cOYJjx47B1dU1T8/BwWREJVtqegYOX4pVQVta3RK4k1KzFwop5+akArYEb+nrDvJ25eA0KlJWO+r72rVrKF++PDZv3oyHH344T49hoCYiY1LN6+DFGEMftyxxmrPCl6OdLaqWL42aPqVRU6XZ3VCjghv8PJzZ8qZCYbWjvmNjY9VPT09PU+8KEVkoR3tbNA30VNuIttWRlJqO/edjVKp8x5nrOHI5Fokp6arfWzbgsuGxMkitpo8+aEvwlt9rVnBDGRdHk74nsm4W06LOyMhAly5dEBMTg61bt971fsnJyWrTXLp0CbVr1+Y8aiLK43eNTk3/CouMx8mr8ernicg4nL2WgLSM3L8ufdydVMvbuAVerXxpLspCJatFPXToUNU/fa8grQ1AmzBhQrHtFxFZF5nGVcnTRW1SklMj6fGz0bdwQgVu/SZBXIK6VAW7GncNW05ey3oeGyDQy1W1uGv4uCHY1w0tq3nDzdnBRO+MLJVFtKiHDRuGpUuXYsuWLQgKCrrnfdmiJqLiFJ+UipNXtQAep+Z4y+83E1PvuK8szNKjiT/6hwYhwMuF/1El2EVraVHLOcTw4cOxePFibNq06b5BWjg5OalNExcnfUxEREVDWsiNK5dVm/F317X4ZEPQlpb33oibOBedgNnbwvG/f8NVa/2lVlXUKHPO6SaLDdSS7p47d65qTbu5uSEyMlJd7+HhoeZVExGZIwm85d2d1da6ejlD8N588hp+2hauUuTavG5Zp/ylVkGqQpgMdCOyqNT33c4yZ8+ejX79+uXpOTg9i4jMjQxSm73tHBbtu4TkzKlhMiDtxRaBeL5ZAMq6chS5tbtorfOoC4KBmojM1fVbyZi78zx+3hGhUuXC2cEWTzXyx4CWQWrkOFknBuoCHgwiIlNITktXVcH+u/WcWv5U80jNciot3qqaN/uxrYzVDCYjIioJnOztVCu6e8OKqhqYBOy/j1/FphPX1CYLqwxoFYiuDSpybnYJxNQ3EZEZCo9OwJx/wzF/zwUkpKQbion0fqgy+jxUWa1PTpaLqe8CHgwiInMjtbb/3H1BBW1ZXEVbi/zJED+VFq/t527qXaQCYKAu4MEgIjJXUr5TpnP9d+tZ7DsfY7heqn71axmI1tW94eLI3kxLwT5qIiIrY29ni871fdW2//xNNR975eEr+rrbZ6/Dwc4GDQPKomVVb7Sq7oX6/mXgYMd52daAfdRERBbqcsxt/G97OJYfvGJIi2tcHe3QvIqXWl+8ZTUvNSCNK6CZD6a+C3gwiIgskSyHcf5GIraejsa/p6/j3zPRd6w17l3aCaFVJXDrg7d/Wa41bkpMfRMRlSDSUq7s5aq23s0rq1Kdx67EqYC97fR17Dp3A9G3krHs4GW1icpeLvrWdlVvtKjqBU+uhma2OPKAiMgKS3XWreihtkEPV1UlOqVfe9vpaGw7cx0HLsQg4noiIq6fVyujyWrNtX3dVeCWVnezIE8OTDMj7KMmIiqBpTmllS2tbQneUuXLmDYwTVZEk6AthUNcndiuK0xMfRMR0T1Lc7YN9lGbiIpPwvYz+qAtwVsGpkkgl03Y2gDVy7shpJIHQiqVQYh/GdSs4MZR5cWEp0hERCVceTdntTypbDIwTdLi287oB6ZJyvxybJK+tvbVePy556J6jJO9rUqtS9CWAN6gUhkEeLpwZHkRYKAmIqJsA9MCvV3VJgPTRFRcEg5ejMXBCzE4eDFG9XHHJ6Vhb8RNtWnKuDhkBu4yaCCtb/8y8CrNpU4fFAM1ERHdU3l3Z/yntmz6VLmMKg+/nqCC9sELsSpwH7sch5jEVGw+eU1tGv+ypfSBOzOA163ozoFq+cRATURE+R5VXqVcabV1b6hfn0JGlodFxqlW94ELsSqIn466hYs3b6tNyniqx9oANXzcVGu7Sjn9lDKZKiYbl0DNHQM1ERE9MEd7W7VsqWx9Wuivi0tKxZGLsTigWt761ndkXBLCIuPVlpMsyhLo5YIACdye+gAe4OWCQC9XlHVxKLH93wzURERUJNydHRAqc7OreRuui4yV/u4YHLkUi/DriTh/PQERNxJV2lwWZZFtj1G/t8bNyV4fwCV4e7pmBXQvV/i6O6tWvrVioCYiomJTwcMZFTwqoEOdCtmuj01MRcSNBDXiXJZDjZAArhZlSVSt8PjkNBy9HKe2nKTsp79nKdXylpHnsvmVKaX6x+WnpbfGGaiJiMjkPFwcUN9FnzrPKSk1HRdU8E5UrW8tiEtAv3gzESnpGTh7LUFtuXF2sFUBu2LmJr8bX5aTB0ndmysGaiIiMmvODnao7uOmtpzSM3Sqipg+iCfg/PVEXLiZiEsxSer6a/HJSEq9dyCXxna50k6omNkCV8Hcw1n/e1n9ZY9SpmuVM1ATEZHFsrO1QSVPF7W1QlZfuCY5LV31i8tqa5du3sblzAB+OVZ/Wa5PTstAVHyy2vafj8n1dVwc7VTgruvnjum9GqI4MVATEZHVcrK3M1QWy42sxHYjIUUFcBXMJYgbbdIylwFuiSnparqZKdY8Z6AmIqISy8bGRq2eJls9f49c7yN95Fdi9S1xUyS/GaiJiIju00ce5O2qNlMw32FuRmbOnInAwEA4OzujefPm2LVrl6l3iYiIqFiYfaD+448/8Prrr+ODDz7Avn37EBISgg4dOiAqKsrUu0ZERFTkzD5QT5s2DQMHDkT//v1Ru3ZtfPvtt3BxccFPP/1k6l0jIiIq2YE6JSUFe/fuRbt27QzX2draqsvbt2/P9THJycmIi4szbPHxd64nS0REZCnMOlBHR0cjPT0dPj760moauRwZGZnrYyZNmgQPDw/DJq1wIiIiS2V1o77Hjh2r+rQ1Fy5cQN26dXHlir7EGhERkalpMSkjI8OyA7W3tzfs7Oxw9erVbNfL5QoVsi/ornFyclKbJjExUf1s1qxZEe8tERFR/kg8CwgIsNxA7ejoiMaNG2P9+vXo1q2b4exDLg8bNixPz9GwYUM1nUvS5dK//SCkv1tS6ceOHYOb251rzhKPWWHg54zHrDjwc2baYyaxTIK0xKj7sdHJ+mlmPj2rb9+++O6771SrePr06fjzzz8RFhZ2R991UZPBadLvHRsbC3d392J9bUvFY8Zjxs+ZeeLfpuUcM7NuUYtnn30W165dw/vvv68GkDVo0ACrV68u9iBNRERkCmYfqIWkufOa6iYiIrImZj09y9zIIDVZIc14sBrxmPFzZnr82+Qxs+bPmdn3URMREZVkbFETERGZMQZqIiIiM8ZATUREZMYYqPOBdbHzTtZcb9q0qVoUoHz58mrBmhMnTuT/E1pCffrpp7CxscGoUaNMvStm7dKlS3jhhRfg5eWFUqVKoV69etizZ4+pd8tsSe2EcePGISgoSB2vqlWr4qOPPgKHKmW3ZcsWPPnkk/Dz81N/h0uWLMl2uxwvmTLs6+urjqMUijp16hSKCgN1HrEudv5s3rwZQ4cOxY4dO7Bu3Tqkpqaiffv2SEhIyP+ntITZvXu3WuCnfv36pt4Vs3bz5k20bNkSDg4OWLVqlVot6vPPP0fZsmVNvWtma/LkyZg1axa+/vprHD9+XF3+7LPPMGPGDFPvmllJSEhASEiIapzlRo7ZV199pcou79y5E66urujQoQOSkpKKZodk1DfdX7NmzXRDhw41XE5PT9f5+fnpJk2axMOXB1FRUTK7QLd582Yer3uIj4/XVa9eXbdu3TpdmzZtdCNHjuTxuosxY8boWrVqxeOTD507d9YNGDAg23VPPfWUrnfv3jyOdyHfW4sXLzZczsjI0FWoUEE3ZcoUw3UxMTE6Jycn3e+//64rCmxRF1FdbMpOltwTnp6ePDT3IFmIzp07Z/usUe6WLVuGJk2aoEePHqp7RdZM/uGHH3i47iE0NFTVSjh58qS6fPDgQWzduhWdOnXiccujc+fOqVUyjf9GZVnR5s2bF1k8sIiVycy5LrasOU73X3xe+lolTSklRyl38+bNw759+1Tqm+7v7NmzKo0rZW3feecdddxGjBihivlIfQC609tvv63Wq65Vq5aqTCjfa5988gl69+7Nw5VHEqRFbvFAu62wMVBTsbQSjxw5os7cKXdSN33kyJGqP9/Z2ZmHKY8ngNKinjhxorosLWr5nEm/IQN17qSg0W+//Ya5c+eiTp06OHDggDqJlkFTPGbmi6nvIqqLTXqyRvvy5cuxceNG+Pv787DchXStREVFoVGjRrC3t1ebDMiTASvyu7R8KDsZcSslB40FBwfj/PnzPFR3MXr0aNWq7tWrlxoh36dPH7z22mtqlgbljfadX5zxgIE6n3WxNVpd7BYtWhTJf4ylkzEYEqQXL16MDRs2qOkgdHdt27bF4cOHVQtH26S1KClJ+V1OFCk76UrJOeVP+l4rV67MQ3UXiYmJanyNMflsyfcZ5Y18l0lANo4H0p0go7+LKh4w9Z1H0g8mqSH58tTqYssQ/v79+xfJf4w1pLslvbZ06VI1l1rru5FBFzLvkLKTY5Sz/16mfMj8YPbr505agjI4SlLfPXv2xK5du/D999+rjXInc4OlTzogIEClvvfv349p06ZhwIABPGRGbt26hdOnT2cbQCYnzDIYVo6ddBd8/PHHqF69ugrcMjddug9kvYgiUSRjya3UjBkzdAEBATpHR0c1XWvHjh2m3iWzJR+t3LbZs2ebetcsBqdn3d9ff/2lq1u3rpoaU6tWLd33339fDP8zlisuLk5N+ZPvMWdnZ12VKlV07777ri45OdnUu2ZWNm7cmOv3V9++fQ1TtMaNG6fz8fFRn722bdvqTpw4UWT7w+pZREREZox91ERERGaMgZqIiMiMMVATERGZMQZqIiIiM8ZATUREZMYYqImIiMwYAzUREZEZY6AmIiIyYwzURFTobGxssGTJEh5ZokLAQE1kZfr166cCZc6tY8eOpt41IioAFuUgskISlGfPnp3tOicnJ5PtDxEVHFvURFZIgrKU4jPeypYtq26T1vWsWbPQqVMnVcmsSpUqWLBgQbbHS8nNxx57TN0uFbwGDRqkKgoZ++mnn1QFJnktqQ0tZU2NRUdHo3v37nBxcVFVhpYtW2a47ebNm6qEZ7ly5dRryO05TyyISI+BmqgEkrJ8Tz/9NA4ePKgCZq9evXD8+HF1m5Rv7dChgwrsu3fvxvz58/H3339nC8QS6KWUqQRwCeoShKtVq5btNSZMmKDKTx46dAiPP/64ep0bN24YXv/YsWNYtWqVel15Pm9v72I+CkQWosjqchGRSUgpPjs7O52rq2u27ZNPPlG3y5/9q6++mu0xzZs31w0ePFj9LqUiy5Ytq7t165bh9hUrVuhsbW11kZGR6rKfn58qj3g38hrvvfee4bI8l1y3atUqdfnJJ5/U9e/fv5DfOZF1Yh81kRV69NFHVSvVmBS917Ro0SLbbXL5wIED6ndp4YaEhMDV1dVwe8uWLZGRkYETJ06o1Pnly5fRtm3be+5D/fr1Db/Lc7m7uyMqKkpdHjx4sGrR79u3D+3bt0e3bt0QGhr6gO+ayDoxUBNZIQmMOVPRhUX6lPPCwcEh22UJ8BLshfSPR0REYOXKlVi3bp0K+pJKnzp1apHsM5ElYx81UQm0Y8eOOy4HBwer3+Wn9F1LX7Vm27ZtsLW1Rc2aNeHm5obAwECsX7/+gfZBBpL17dsXv/76K6ZPn47vv//+gZ6PyFqxRU1khZKTkxEZGZntOnt7e8OALRkg1qRJE7Rq1Qq//fYbdu3ahf/+97/qNhn09cEHH6ggOn78eFy7dg3Dhw9Hnz594OPjo+4j17/66qsoX768ah3Hx8erYC73y4v3338fjRs3VqPGZV+XL19uOFEgouwYqIms0OrVq9WUKWPSGg4LCzOMyJ43bx6GDBmi7vf777+jdu3a6jaZTrVmzRqMHDkSTZs2VZelP3natGmG55IgnpSUhC+++AJvvvmmOgF45pln8rx/jo6OGDt2LMLDw1UqvXXr1mp/iOhONjKiLJfrichKSV/x4sWL1QAuIjJ/7KMmIiIyYwzUREREZox91EQlDHu7iCwLW9RERERmjIGaiIjIjDFQExERmTEGaiIiIjPGQE1ERGTGGKiJiIjMGAM1ERGRGWOgJiIiMmMM1ERERDBf/wfQAmYSYIkcSwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a5f8ee40-6c36-4dd7-a19b-d09af676603b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f8b26481-7b23-45d8-be75-975992868ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed lun\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "562c1cf5-dabc-4858-bae3-6f9eabad72dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cb3d7784-8b44-41cc-a71e-e94fd758585e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'closer': 0, 'every': 1, 'effort': 2, 'forward': 3, 'inches': 4, 'moves': 5, 'pizza': 6, 'toward': 7, 'you': 8}\n",
      "{0: 'closer', 1: 'every', 2: 'effort', 3: 'forward', 4: 'inches', 5: 'moves', 6: 'pizza', 7: 'toward', 8: 'you'}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)\n",
    "print(inverse_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ee9d437b-7b47-4c38-9fc1-e8017ba31bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d8da0906-66c9-4d33-8fec-4d001872347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5da07e9f-a339-495b-8a38-86dc5b883c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9dbbc290-e968-401f-9545-03b397d94582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cb2cdf33-6586-4307-8066-322b1912993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "83ebf79a-68aa-4b3b-a71e-e83ccfdbd3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "87ded1fc-06b5-4c5a-bff3-4ce442bfebfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b443333b-90c3-46a1-be3e-445b3c465e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float(\"-inf\")), \n",
    "    other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4ee44350-3b40-4cc0-bc20-f57036778c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c58ad37e-cac0-4aff-aa2a-fda0e3a9bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d3e8df55-08de-486f-bd78-a6898099a371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you stand to work on surprise, a one of us had gone with random-\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d8d08ecf-8c8b-4ac5-958f-d8ee206dfe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2145de03-1f63-49ee-8cfb-7a4f9e6e4591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6d2af3da-8005-4914-8984-b384b69c0b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1baa9fa9-f92d-4a74-9d3b-92e5cd7bd19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5a26ff57-f4fe-4a33-a5da-2432598163fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: 4.66 not found\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow tensorflow-metal tqdm>=4.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "64d0da2b-c9af-42d4-8a84-704c3efb2db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/bin/python3.11\n",
      "TensorFlow vesibon: 2.20.0\n",
      "tqdm vesion: 4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import sys\n",
    "\n",
    "print(sys.executable)\n",
    "print(\"TensorFlow vesibon:\", tf.__version__)\n",
    "print(\"tqdm vesion:\", tqdm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2b5e7163-c2df-4006-952c-1aa1d6ad8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_download3 import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6044d2ba-bfc4-4366-8274-153f73fc1046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/1558M/checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/1558M/encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/1558M/hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/1558M/model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/1558M/model.ckpt.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/1558M/model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/1558M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"1558M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f10c1082-532f-43c3-b83f-44e2f47ca056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 1600, 'n_head': 25, 'n_layer': 48}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
      "[[ 0.02325445 -0.02463005  0.0184482  ... -0.01090558  0.01040707\n",
      "  -0.03645451]\n",
      " [-0.01581111  0.01653037  0.01214997 ... -0.02070756  0.03373823\n",
      "  -0.01696608]\n",
      " [ 0.06331218  0.05149647  0.05042315 ...  0.00149185  0.0440849\n",
      "  -0.01331342]\n",
      " ...\n",
      " [ 0.06547946 -0.08253232 -0.00527849 ...  0.0379269  -0.0045469\n",
      "  -0.03799901]\n",
      " [-0.01379867 -0.04474732 -0.00245812 ...  0.04096344  0.01283443\n",
      "  -0.01897047]\n",
      " [ 0.00404523 -0.00416177 -0.07961206 ... -0.00897262  0.06238916\n",
      "   0.12092888]]\n",
      "Token embedding weight tensor dimensions: (50257, 1600)\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())\n",
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2c79f832-7ce7-40ec-a6d1-8c88a48214be",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 1024, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "711a4619-93d3-4c39-9ebb-52c62764d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-xl (1558M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "29e927be-b2ed-42ed-ad52-66a13e06c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"context_lenght\": 1600, \"qkv_bias\": True})\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "10557a57-3884-40d2-82c0-a5bd88283c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "af2e4934-7ff5-4bce-b3a7-f6be4d879b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split( (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(gpt.trf_blocks[b].att.out_proj.weight, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(gpt.trf_blocks[b].att.out_proj.bias, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(gpt.trf_blocks[b].ff.layers[0].weight, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(gpt.trf_blocks[b].ff.layers[0].bias, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(gpt.trf_blocks[b].ff.layers[2].weight, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(gpt.trf_blocks[b].ff.layers[2].bias, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(gpt.trf_blocks[b].norm1.scale, params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(gpt.trf_blocks[b].norm1.shift, params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(gpt.trf_blocks[b].norm2.scale, params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(gpt.trf_blocks[b].norm2.shift, params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "88bf2125-ec58-4002-9264-7b808da26b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1600)\n",
       "  (pos_emb): Embedding(1024, 1600)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (24): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (25): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (26): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (27): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (28): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (29): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (30): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (31): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (32): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (33): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (34): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (35): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (36): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (37): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (38): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (39): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (40): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (41): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (42): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (43): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (44): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (45): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (46): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (47): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1600, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ff5f5619-1d91-4b3e-857b-5c7ad221c492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward finding an ideal life. You don't have to accept your current one at once, because if you do you'll never\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "df3e57a3-2120-4c4c-9094-c95e35fbf4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " What is kafka partation re balancing an object instance? Why are balance options only given to an object by its Id and what happens if two instances try to update the same thing? Do multiple users ever try to get updates for a single change at the cost of some database transaction? What do I get out of running a partial update? It should happen when a certain value is being stored or when there already is a value there. How many objects does it take if I do all this once and that takes longer than a single commit time?\n",
      "\n",
      "The first time someone finds such a document, I cannot do much to solve the problem. Most of the time someone who finds a mistake is not interested in the full extent of the structure and not concerned about what else we can find out about the problem. But at some point in the life, something must click for one of them that leads him/her to spend 10 minutes to look at his own code again. Then it works, maybe with some problems. I hope there are no bugs in my code or there never are any bugs in my code yet people in this position feel more assured with it. What I do here is give the general intuition of all those things. I should first warn a little at the risks for these documents if the code they show up is good. So that people, who are not sure, could choose a branch based on a document.\n",
      "\n",
      "The full document, for which many updates should have to happen before we know whether it is in order or out of balance, follows that the document is in balance when the Id changes in the new value if the old values for Id-1 are either not at all and are all negative one, or the value does not increase and is in fact in balance as with new values at Idx, and new values increase without end. For example if Idx=500 and an Idx=7 then the Id will stay at 500, while 7= -1 => 6 and id would now be at 6,7 as would the index at s=0. Let Id1 then be the set-in-set-balance in case if we were to have a list: If id were -1 the top-pair in the sorted set-in had 0 or id could become either 1, a -1 id set. The two sets with any length are the two keys of our hash table: the new key is in the ordered one-by-one way we showed or the new value is in the unordered one-element manner as before. The two sets that are not only in one order but two can be two consecutive objects (like our id array: -1 ==> 11==> 6.5 ==> 1 . Our hash table with all those ordered one-by-many keys is the map in the unordered way we have shown above\n",
      "\n",
      "To avoid ambiguity the ordering must have the simplest, minimum number and possible minimal semantics for every change but every data is in order but could use other semantics. Consider two elements whose Id's compare as equal in the one-one relationship: if a new key is inserted it will not get the exact same value again due to one of the elements (or both) have its key already or the same amount as it was at time-in. There can only be one value in the table at any change. Suppose two new values in that id is the left key value with more- than-1 or has less than 100: a new, different new one is inserted then those other values and could be as different now as before: a different first value, no-value. In our table every object with an older key/value is ordered on older as with every first/first key/value pairs. So there could not be two objects where new is exactly greater that same one of those keys where older keys are not more on that way. And there can be not less than some. There were a number times I had just a bit lost before being made aware this actually existed and even after. What was it. Here it is:\n",
      "\n",
      "\n",
      "Let our hash table be the root on a new object whose hash keys is its class instance's Id field; all the existing keys has just been removed.\n",
      "\n",
      "First look at Idiomatic Use and then at the other two articles\n",
      "\n",
      "So here a HashMap has two fields to hold values or Id if we see, and is sorted one by-many to have sorted keys (with not a single id) that might use more than 1 as not one but have more than some or some, one from each side where id goes first. I don't know, though, that one in a new key has zero more at time-in from the beginning and that is also what i tried first. It is really just \"one\" value when this way of ordering might be different. To this a query from such objects could check that the ordering (from my understanding only) with respect to existing values was sorted, maybe with the best way this code can be done right now and will take in time, at which point not a part of the code was even changed as much as a change from order-by was: just this ordering-based comparison was made and this comparison changed on the first write of a field; and this comparison in general depends on an entire object instance, when something really changes but then only the new order has gone through. I suppose this is why I didn't think of the idea that there can be an earlier that one which we did that that could be considered when we use \"all equal\". For how could it in principle exist which changes to the right order in that we must know, is quite what we would rather find. Of course of these things not all values cannot be in the same order that would be a way of an array. Let our object with id say is the list: all elements are equal with old equals new and so the existing keys with an entry of not equal can only equal new because id doesn't are an element or another in that object but also has an array element in order, we need our object that we have already defined what values exist like id, id and id with no the older ones so its sorting is based on old but also also the new values for keys, this is in fact the same as what we have now and that for example what that should always be the order in which such the indices in ordered and as we can assume that ordered contains already old for such that the next element might need changing after a change as such in the ascending case then it will be also, and then after a similar move, sorted as well if we make this one simple, from now there are exactly one. The first \"one\" there, even without an empty string, contains this element from that sorted or order set; that is true if a.length are equal. Therefore a set is empty set if all the elements equal some order set of value objects so as we see our sorting can always get any \"new\" value, that happens not as a part of our query where some values were actually changed. This is where a good test to know if something has been properly modified is if old is the value and newer if newer value should get new or should stay from what it already was (without that its probably not true).\n",
      "\n",
      "\n",
      "I suppose I must explain the way in what such \"id \" has value \"not equal\" , for some reasons all it does, when the new key is created this is quite possible \"none\" of everything in the first field have changed and it always will \"0 not equal everything\", just the \"old-ish\" values. The next is of course equal if all values in these keys will get equal on an old equal equal when newer, and of course that too should also always happen. Therefore id should actually not stay what it is or that we\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"What is kafka partation re-balancing\", tokenizer).to(device),\n",
    "    max_new_tokens=1600,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ff37f334-a451-4978-8e56-dc2ede8f39b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Create an unverified SSL context\n",
    "    ssl_context = ssl._create_unverified_context()\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e1cdbb44-7726-4fb9-9c05-ab10f4c03f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will  b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will  b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e5fb627a-ea95-4d06-978d-29d9aeddc0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "23624030-26f4-48ae-a4f1-c6e6e7975154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "30aa9931-6164-460f-978b-1e45977b4370",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7e3b0e33-d146-42be-8ddd-912059dcb5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "79cb1cdf-0075-4096-b95d-3244702cbc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f8f3e4f2-3377-4cb2-860c-06ef004f3d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045\n",
      "149\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(validation_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9cc38170-d549-44d0-86c1-4c4c6eddfed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4f1cef0d-79ed-4d7f-94eb-05b71c6ba636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [tokenizer.encode(text) for text in self.data[\"Text\"] ]\n",
    "\n",
    "        flag = True\n",
    "        if flag == False:\n",
    "            print(self.encoded_texts)\n",
    "            flag = False\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4d7f02d0-0d06-4334-ba4f-3e46d9e02a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "54baa50d-c0d5-4f8c-96b9-087c7efc1891",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9835c214-b848-4cbd-bfd5-375300aa18af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a76f7859-f3f6-47d1-a57c-a37b18f7629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b42b53ce-3c21-4529-886a-b8c5c7eb52b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5070e63-6182-44b5-9d77-6579c4a783e6",
   "metadata": {},
   "source": [
    "INITIALIZING MODEL WITH PRETRAINED WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "435faeca-1fca-4e5c-bc2a-6075097e94fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT_CONFIG_124M = {\n",
    "#    \"vocab_size\": 50257,   # Vocabulary size\n",
    "#    \"context_length\": 1024, # Shortened context length (orig: 1024)\n",
    "#    \"emb_dim\": 768,        # Embedding dimension\n",
    "#    \"n_heads\": 12,         # Number of attention heads\n",
    "#    \"n_layers\": 12,        # Number of layers\n",
    "#    \"drop_rate\": 0.1,      # Dropout rate\n",
    "#    \"qkv_bias\": False      # Query-key-value bias\n",
    "#}\n",
    "\n",
    "\n",
    "# Define model configurations in a dictionary for compactness\n",
    "#model_configs = {\n",
    "#    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "#    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "#    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "#    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "#}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "#model_name = \"gpt2-xl (1558M)\"  # Example model name\n",
    "#NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "#NEW_CONFIG.update(model_configs[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1dabdd63-ae25-4c41-9f30-d55a554193f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25}\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitilize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7b858665-9e9b-4397-9c73-eadc747f1100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "from gpt_download3 import download_and_load_gpt2\n",
    "\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "20d17a4b-7785-4299-a33d-252248dd2da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[0.0662, 0.7224, 0.9206,  ..., 0.4790, 0.7428, 0.7015],\n",
      "        [0.5745, 0.6241, 0.4410,  ..., 1.1963, 1.2650, 0.2243]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", output[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fadf06dc-9aed-49ec-b103-f3cde4b14a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "98e4ea7f-25ae-4818-88a8-fe2a119a5ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(model=model, idx=text_to_token_ids(text_2, tokenizer), max_new_tokens=23, context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5a1994-4b13-41da-95c8-ffbf9753d4ea",
   "metadata": {},
   "source": [
    "ADDING THE CLASSIFICATION HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4cb8c6fd-c125-4148-92ab-3f525c6e4cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2dde1751-e499-42c0-bc76-ab8828cf4648",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0a2e59f2-45c2-4a75-866c-bd8d7b521ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "82fd032d-f916-4b57-8ad8-ec9041004eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "59a9bb93-37dd-4090-9c50-47ae2528ec15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "712e5e29-50cb-4985-8dbd-c67b7fe1b586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c59a48-bdc0-4b42-aa75-f7d10bfcd29c",
   "metadata": {},
   "source": [
    "CALCULATING THE CLASSIFICATION LOSS AND ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "63c7054a-26a2-44f4-aabe-e60a66738fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4f9fed94-4088-44fe-bb92-73e15b0e5ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4b936ff3-79fc-4871-b9f3-8f97f829bc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "dceb74a5-3c52-4bcd-9533-8937d85a8800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c98bbd6b-8682-40cd-8f49-98933ecf0a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
    "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#print(f\"Running on {device} device.\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "07bfa368-1acc-426e-ae12-1efc49324208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e5c3230c-200e-4703-954e-cc676fbb2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9f84e914-1a32-41c6-8fcb-5dcf5ff5fce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.937\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d107e3a9-b17e-492d-b7bb-bb55e73cf424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "427e9453-bfe9-4ac8-9759-7145ae4b529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "915a6f8d-f5f6-4a80-8fca-936975b88a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 3.64 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "921869ce-5b2c-44e3-a814-181020e6b602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0b681c67-4e36-46fc-a73b-69aa40159de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1c015ec9-2ea3-462c-8542-f2624b53bf16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "71608b1f-43c5-49fe-802b-770378402900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.21%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "787166d2-3626-4e9d-a3a9-5ae52e654773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2e7ba62b-e0c4-4d09-b9bc-4b1172a3b4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d41ddc15-7276-45a0-99ae-94a9829d8a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "0507f25e-870d-4860-9cc4-5b37ece3cbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_3 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? I can give you reward of $1000 Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8bd440ec-3079-4816-9aad-feaef1f27ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8d7417fa-a1ae-45b8-9770-22ce7a820c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424e5495-d041-478c-983e-457e67653368",
   "metadata": {},
   "source": [
    "# INSTRUCTION FINE-TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be5c220-82c6-4679-9653-c0fbf13751ca",
   "metadata": {},
   "source": [
    "## STEP 1: PREPARING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "afa104c4-155e-4640-aa20-4aa5a9f6c737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "import ssl\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    ssl_context = ssl.create_default_context()\n",
    "    ssl_context.check_hostname = False\n",
    "    ssl_context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "0cb019e6-617c-472e-aca7-42aa42b3072b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ee437-a104-44c6-908a-72f55a4ddc53",
   "metadata": {},
   "source": [
    "### CONVERTING INSTRUCTIONS INTO ALPACA FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "18516844-e950-4f50-969b-9a9dff2f3e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a68aaa35-ea9d-44da-bf0d-c264df2215a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f345ea7e-30af-4d71-bf79-53f5496d33e8",
   "metadata": {},
   "source": [
    "### SPLITTING DATASET INTO TRAIN-TEST-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5f0f7d42-ae24-4a74-9216-07ef5212a826",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b8e4f4a4-9997-430b-bf24-34688a5253fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0066ce-91ba-448f-b6ea-57f1196ef3a5",
   "metadata": {},
   "source": [
    "## STEP 2: ORGANIZING DATA INTO TRAINING BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "801da718-ddf7-452a-afc8-e735e720432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "71260b73-42c1-43f0-b17b-9e1fdf68f646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a85de548-6cd6-406f-89e1-e9656c3a8a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    # and increase the max length by +1, which will add one extra\n",
    "    # padding token below\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to batch_max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # Via padded[:-1], we remove the extra padded token\n",
    "        # that has been added via the +1 setting in batch_max_length\n",
    "        # (the extra padding token will be relevant in later codes)\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c10f87f5-2a3e-4dc6-8cab-937e4d3048e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1037a56d-e6c6-413f-8177-31b19990ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"mps\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55339ab-ed9d-47d5-a899-d1fa1d935e17",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "In the following code, we modify our custom collate function to replace tokens with ID\n",
    "50256 with -100 in the target lists.\n",
    "\n",
    "Additionally, we introduce\n",
    "an allowed_max_length parameter to optionally limit the length of the samples. \n",
    "\n",
    "This\n",
    "adjustment will be useful if you plan to work with your own datasets that exceed the 1024-\n",
    "token context size supported by the GPT-2 model. \n",
    "\n",
    "The code for this updated collate function\n",
    "is as follows:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "94ec15ae-ea63-42ed-bb1b-d5e087c1512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"mps\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "13a562c4-e765-43a7-8976-6f6f9b17016d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]], device='mps:0')\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2ac0fda6-4041-4a31-ad97-c96de2a71642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 1st training example\n",
    "     [-0.5, 1.5]]  # 2nd training example\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "9f3b5700-88e7-4c88-bef2-b885a4ccfbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "19f36dad-a9c2-43ad-9936-1fd0d07ff517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e363d00-f49b-4483-90e9-7277a2a34b6e",
   "metadata": {},
   "source": [
    "## STEP 3: CREATING DATALOADERS FROM AN INSTRUCTION DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "55f2ac40-efce-46e9-8bff-4ddd09591051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is much faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1ce4ee8c-93f4-4f2d-b5a8-4139ce5611d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "377a1bf5-76c5-4861-b19a-99ebf831f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "810a0ecb-a96a-4151-9e9a-b9b9a4ffdb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaf5ad0-1429-4485-8e3c-5a8383af1d21",
   "metadata": {},
   "source": [
    "## STEP 4: LOADING A PRETRAINED LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b968f6be-0bb3-4696-b1c7-72df6637b5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "checkpoint: 100%|| 77.0/77.0 [00:00<00:00, 15.9kiB/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "encoder.json: 100%|| 1.04M/1.04M [00:01<00:00, 562kiB/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "hparams.json: 100%|| 91.0/91.0 [00:00<00:00, 39.3kiB/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "model.ckpt.data-00000-of-00001: 100%|| 1.42G/1.42G [32:52<00:00, 720kiB/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "model.ckpt.index: 100%|| 10.4k/10.4k [00:00<00:00, 6.60MiB/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "model.ckpt.meta: 100%|| 927k/927k [00:01<00:00, 600kiB/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "vocab.bpe: 100%|| 456k/456k [00:01<00:00, 303kiB/s]\n"
     ]
    }
   ],
   "source": [
    "from gpt_download3 import download_and_load_gpt2\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "65e3e6e3-74a0-4475-8485-d36e4e106b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d99fb6bc-6618-4615-9ca5-5782c22fa72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e71e4307-7c27-43e3-a956-c40a37ea7ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1449af20-e798-49e6-8193-b30d2d565dd5",
   "metadata": {},
   "source": [
    "## STEP 5: FINETUNING THE LLM ON INSTRUCTION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "5d9c9f2b-4227-4615-a4db-3bc929f03d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0: \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2955895a-7944-4430-8a85-50e60fda936f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.8259099960327148\n",
      "Validation loss: 3.7619343757629395\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a1d7d9bd-2a03-4498-9171-4cb3bf1a21db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
      "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.800, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.809\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
      "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.535, Val loss 0.732\n",
      "Ep 1 (Step 000075): Train loss 0.567, Val loss 0.737\n",
      "Ep 1 (Step 000080): Train loss 0.602, Val loss 0.731\n",
      "Ep 1 (Step 000085): Train loss 0.513, Val loss 0.715\n",
      "Ep 1 (Step 000090): Train loss 0.571, Val loss 0.696\n",
      "Ep 1 (Step 000095): Train loss 0.504, Val loss 0.687\n",
      "Ep 1 (Step 000100): Train loss 0.507, Val loss 0.682\n",
      "Ep 1 (Step 000105): Train loss 0.568, Val loss 0.674\n",
      "Ep 1 (Step 000110): Train loss 0.562, Val loss 0.669\n",
      "Ep 1 (Step 000115): Train loss 0.519, Val loss 0.665\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Training completed in 1.89 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c6a74624-c23a-4e0a-99b9-8d580aef09c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "beee4ad0-0753-4246-b928-fdac28c24e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dbfb49-f9df-4bf6-b876-d5e6b9516f64",
   "metadata": {},
   "source": [
    "## STEP 6: EXTRACTING AND SAVING RESPONSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "cead75fb-045b-4e80-9203-a0d19f714c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> A thunderstorm is a type of storm that typically produces thunderstorms.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1707ff42-f519-49aa-9fd0-d1c2793b5462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
